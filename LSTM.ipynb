{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "hide_input": false,
    "kernelspec": {
      "display_name": "Python 2",
      "language": "python",
      "name": "python2"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.12"
    },
    "colab": {
      "name": "LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TBo-ndUWi9Co"
      },
      "source": [
        "## Deriving Human motion recognition using RNN_LSTM\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x70oDoPFi9Ct"
      },
      "source": [
        "\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf  # Version 1.0.0 (some previous versions are used in past commits)\n",
        "from sklearn import metrics\n",
        "import random\n",
        "from random import randint\n",
        "import time\n",
        "import os"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iAvbQIm_i9Cv"
      },
      "source": [
        "## Preparing dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lkSTFekLjbuT",
        "outputId": "a6856769-1e61-4bd7-ab87-e1e0540c5b76"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HtchpH5Li9Cv"
      },
      "source": [
        "# Useful Constants\n",
        "\n",
        "# Output classes to learn how to classify\n",
        "LABELS = [    \n",
        "    \"JUMPING\",\n",
        "    \"JUMPING_JACKS\",\n",
        "    \"BOXING\",\n",
        "    \"WAVING_2HANDS\",\n",
        "    \"WAVING_1HAND\",\n",
        "    \"CLAPPING_HANDS\"\n",
        "\n",
        "] \n",
        "DATASET_PATH = \"/content/drive/MyDrive/RNN-for-Human-Activity-Recognition-using-2D-Pose-Input-master/data/HAR_pose_activities/database/RNN-HAR-2D-Pose-database/\"\n",
        "\n",
        "X_train_path = DATASET_PATH + \"X_train.txt\"\n",
        "X_test_path = DATASET_PATH + \"X_test.txt\"\n",
        "\n",
        "y_train_path = DATASET_PATH + \"Y_train.txt\"\n",
        "y_test_path = DATASET_PATH + \"Y_test.txt\"\n",
        "\n",
        "n_steps = 32 # 32 timesteps per series"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vrYxa-eei9Cw"
      },
      "source": [
        "\n",
        "# Load the networks inputs\n",
        "\n",
        "def load_X(X_path):\n",
        "    file = open(X_path, 'r')\n",
        "    X_ = np.array(\n",
        "        [elem for elem in [\n",
        "            row.split(',') for row in file\n",
        "        ]], \n",
        "        dtype=np.float32\n",
        "    )\n",
        "    file.close()\n",
        "    blocks = int(len(X_) / n_steps)\n",
        "    \n",
        "    X_ = np.array(np.split(X_,blocks))\n",
        "\n",
        "    return X_ \n",
        "\n",
        "# Load the networks outputs\n",
        "\n",
        "def load_y(y_path):\n",
        "    file = open(y_path, 'r')\n",
        "    y_ = np.array(\n",
        "        [elem for elem in [\n",
        "            row.replace('  ', ' ').strip().split(' ') for row in file\n",
        "        ]], \n",
        "        dtype=np.int32\n",
        "    )\n",
        "    file.close()\n",
        "    \n",
        "    # for 0-based indexing \n",
        "    return y_ - 1\n",
        "\n",
        "X_train = load_X(X_train_path)\n",
        "X_test = load_X(X_test_path)\n",
        "#print X_test\n",
        "\n",
        "y_train = load_y(y_train_path)\n",
        "y_test = load_y(y_test_path)\n",
        "# proof that it actually works for the skeptical: replace labelled classes with random classes to train on\n",
        "#for i in range(len(y_train)):\n",
        "#    y_train[i] = randint(0, 5)\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zgPYdZ6Ci9Cw"
      },
      "source": [
        "## Set Parameters:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90Jg0chKi9Cx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "efdfd579-5e8c-43bf-a1c8-445b46558d26"
      },
      "source": [
        "# Input Data \n",
        "\n",
        "training_data_count = len(X_train)  # 4519 training series (with 50% overlap between each serie)\n",
        "test_data_count = len(X_test)  # 1197 test series\n",
        "n_input = len(X_train[0][0])  # num input parameters per timestep\n",
        "\n",
        "n_hidden = 34 # Hidden layer num of features\n",
        "n_classes = 6 \n",
        "\n",
        "#updated for learning-rate decay\n",
        "# calculated as: decayed_learning_rate = learning_rate * decay_rate ^ (global_step / decay_steps)\n",
        "decaying_learning_rate = True\n",
        "learning_rate = 0.0025 #used if decaying_learning_rate set to False\n",
        "init_learning_rate = 0.005\n",
        "decay_rate = 0.96 #the base of the exponential in the decay\n",
        "decay_steps = 100000 #used in decay every 60000 steps with a base of 0.96\n",
        "\n",
        "global_step = tf.Variable(0, trainable=False)\n",
        "lambda_loss_amount = 0.0015\n",
        "\n",
        "training_iters = training_data_count *300  # Loop 300 times on the dataset, ie 300 epochs\n",
        "batch_size = 512\n",
        "display_iter = batch_size*8  # To show test set accuracy during training\n",
        "\n",
        "print(\"(X shape, y shape, every X's mean, every X's standard deviation)\")\n",
        "print(X_train.shape, y_test.shape, np.mean(X_test), np.std(X_test))\n",
        "print(\"\\nThe dataset has not been preprocessed, is not normalised etc\")\n",
        "\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "(X shape, y shape, every X's mean, every X's standard deviation)\n",
            "((22625, 32, 36), (5751, 1), 251.01117, 126.12204)\n",
            "\n",
            "The dataset has not been preprocessed, is not normalised etc\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZX8tctri9Cy"
      },
      "source": [
        "## Utility functions for training:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D44VJ2HLi9Cz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "265182c7-2528-4280-ac3b-36bffa2d2eeb"
      },
      "source": [
        "!pip install tensorflow==1.13.2\n",
        "def LSTM_RNN(_X, _weights, _biases):\n",
        "    # model architecture based on \"guillaume-chevalier\" and \"aymericdamien\" under the MIT license.\n",
        "\n",
        "    _X = tf.transpose(_X, [1, 0, 2])  # permute n_steps and batch_size\n",
        "    _X = tf.reshape(_X, [-1, n_input])   \n",
        "    # Rectifies Linear Unit activation function used\n",
        "    _X = tf.nn.relu(tf.matmul(_X, _weights['hidden']) + _biases['hidden'])\n",
        "    # Split data because rnn cell needs a list of inputs for the RNN inner loop\n",
        "    _X = tf.split(_X, n_steps, 0) \n",
        "\n",
        "    # Define two stacked LSTM cells (two recurrent layers deep) with tensorflow\n",
        "    lstm_cell_1 = tf.contrib.rnn.BasicLSTMCell(n_hidden, forget_bias=1.0, state_is_tuple=True)\n",
        "    lstm_cell_2 = tf.contrib.rnn.BasicLSTMCell(n_hidden, forget_bias=1.0, state_is_tuple=True)\n",
        "    lstm_cells = tf.contrib.rnn.MultiRNNCell([lstm_cell_1, lstm_cell_2], state_is_tuple=True)\n",
        "    outputs, states = tf.contrib.rnn.static_rnn(lstm_cells, _X, dtype=tf.float32)\n",
        "\n",
        "    # A single output is produced, in style of \"many to one\" classifier, refer to http://karpathy.github.io/2015/05/21/rnn-effectiveness/ for details\n",
        "    lstm_last_output = outputs[-1]\n",
        "    \n",
        "    # Linear activation\n",
        "    return tf.matmul(lstm_last_output, _weights['out']) + _biases['out']\n",
        "\n",
        "\n",
        "def extract_batch_size(_train, _labels, _unsampled, batch_size):\n",
        "    # Fetch a \"batch_size\" amount of data and labels from \"(X|y)_train\" data. \n",
        "    # Elements of each batch are chosen randomly, without replacement, from X_train with corresponding label from Y_train\n",
        "    # unsampled_indices keeps track of sampled data ensuring non-replacement. Resets when remaining datapoints < batch_size    \n",
        "    \n",
        "    shape = list(_train.shape)\n",
        "    shape[0] = batch_size\n",
        "    batch_s = np.empty(shape)\n",
        "    batch_labels = np.empty((batch_size,1)) \n",
        "\n",
        "    for i in range(batch_size):\n",
        "        # Loop index\n",
        "        # index = random sample from _unsampled (indices)\n",
        "        index = random.choice(_unsampled)\n",
        "        batch_s[i] = _train[index] \n",
        "        batch_labels[i] = _labels[index]\n",
        "        _unsampled.remove(index)\n",
        "\n",
        "\n",
        "    return batch_s, batch_labels, _unsampled\n",
        "\n",
        "\n",
        "def one_hot(y_):\n",
        "    # One hot encoding of the network outputs\n",
        "    # e.g.: [[5], [0], [3]] --> [[0, 0, 0, 0, 0, 1], [1, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0]]\n",
        "    \n",
        "    y_ = y_.reshape(len(y_))\n",
        "    n_values = int(np.max(y_)) + 1\n",
        "    return np.eye(n_values)[np.array(y_, dtype=np.int32)]  # Returns FLOATS\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow==1.13.2 in /usr/local/lib/python2.7/dist-packages (1.13.2)\n",
            "Requirement already satisfied: tensorflow-estimator<1.14.0rc0,>=1.13.0 in /usr/local/lib/python2.7/dist-packages (from tensorflow==1.13.2) (1.13.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python2.7/dist-packages (from tensorflow==1.13.2) (1.15.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python2.7/dist-packages (from tensorflow==1.13.2) (1.16.4)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python2.7/dist-packages (from tensorflow==1.13.2) (1.0.8)\n",
            "Requirement already satisfied: enum34>=1.1.6 in /usr/local/lib/python2.7/dist-packages (from tensorflow==1.13.2) (1.1.6)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python2.7/dist-packages (from tensorflow==1.13.2) (3.8.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python2.7/dist-packages (from tensorflow==1.13.2) (1.1.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python2.7/dist-packages (from tensorflow==1.13.2) (0.2.2)\n",
            "Requirement already satisfied: tensorboard<1.14.0,>=1.13.0 in /usr/local/lib/python2.7/dist-packages (from tensorflow==1.13.2) (1.13.1)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python2.7/dist-packages (from tensorflow==1.13.2) (0.36.2)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python2.7/dist-packages (from tensorflow==1.13.2) (0.7.1)\n",
            "Requirement already satisfied: backports.weakref>=1.0rc1 in /usr/local/lib/python2.7/dist-packages (from tensorflow==1.13.2) (1.0.post1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python2.7/dist-packages (from tensorflow==1.13.2) (1.15.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python2.7/dist-packages (from tensorflow==1.13.2) (1.1.0)\n",
            "Requirement already satisfied: mock>=2.0.0 in /usr/local/lib/python2.7/dist-packages (from tensorflow==1.13.2) (2.0.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python2.7/dist-packages (from tensorflow==1.13.2) (0.8.1)\n",
            "Requirement already satisfied: futures>=2.2.0 in /usr/local/lib/python2.7/dist-packages (from grpcio>=1.8.6->tensorflow==1.13.2) (3.2.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python2.7/dist-packages (from keras-applications>=1.0.6->tensorflow==1.13.2) (2.8.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python2.7/dist-packages (from protobuf>=3.6.1->tensorflow==1.13.2) (44.1.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python2.7/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.2) (0.15.5)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python2.7/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.2) (3.1.1)\n",
            "Requirement already satisfied: funcsigs>=1; python_version < \"3.3\" in /usr/local/lib/python2.7/dist-packages (from mock>=2.0.0->tensorflow==1.13.2) (1.0.2)\n",
            "Requirement already satisfied: pbr>=0.11 in /usr/local/lib/python2.7/dist-packages (from mock>=2.0.0->tensorflow==1.13.2) (5.4.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oyAFzPaKi9Cz"
      },
      "source": [
        "## Build the network:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tvh9n37R4t_5"
      },
      "source": [
        ""
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FByjV5luv_Uu"
      },
      "source": [
        " \n",
        "import tensorflow as tf\n",
        "\n",
        "tf.compat.v1.disable_eager_execution()\n",
        "# Graph input/output\n",
        "x = tf.compat.v1.placeholder(tf.float32, [None, n_steps, n_input])\n",
        "y = tf.compat.v1.placeholder(tf.float32, [None, n_classes])\n",
        "\n",
        "# Graph weights"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ksnKu1Gpi9C0"
      },
      "source": [
        "\n",
        "weights = {\n",
        "    'hidden': tf.Variable(tf.random.normal([n_input, n_hidden])), # Hidden layer weights\n",
        "    'out': tf.Variable(tf.random.normal([n_hidden, n_classes], mean=1.0))\n",
        "}\n",
        "biases = {\n",
        "    'hidden': tf.Variable(tf.random.normal([n_hidden])),\n",
        "    'out': tf.Variable(tf.random.normal([n_classes]))\n",
        "}\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "inWDjxt04_Oy",
        "outputId": "01ff4e42-0286-43b1-d3b2-eb553467998f"
      },
      "source": [
        "\n",
        "pred = LSTM_RNN(x, weights, biases)\n",
        "\n",
        "# Loss, optimizer and evaluation\n",
        "l2 = lambda_loss_amount * sum(\n",
        "    tf.nn.l2_loss(tf_var) for tf_var in tf.trainable_variables()\n",
        ") # L2 loss prevents this overkill neural network to overfit the data\n",
        "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=pred)) + l2 # Softmax loss\n",
        "if decaying_learning_rate:\n",
        "    learning_rate = tf.train.exponential_decay(init_learning_rate, global_step*batch_size, decay_steps, decay_rate, staircase=True)\n",
        "\n",
        "\n",
        "#decayed_learning_rate = learning_rate * decay_rate ^ (global_step / decay_steps) #exponentially decayed learning rate\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost,global_step=global_step) # Adam Optimizer\n",
        "\n",
        "correct_pred = tf.equal(tf.argmax(pred,1), tf.argmax(y,1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
        "\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:From <ipython-input-6-2c521cca4918>:13: __init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:From <ipython-input-6-2c521cca4918>:15: __init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:From <ipython-input-6-2c521cca4918>:16: static_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell, unroll=True)`, which is equivalent to this API\n",
            "WARNING:tensorflow:From <ipython-input-9-57d810fd27e2>:8: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PqEDxR31i9C0"
      },
      "source": [
        "## Train the network:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "pECusQ-Si9C1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2bf584d3-e4e0-4b23-a417-2eb8c5b73c51"
      },
      "source": [
        "test_losses = []\n",
        "test_accuracies = []\n",
        "train_losses = []\n",
        "train_accuracies = []\n",
        "sess = tf.InteractiveSession(config=tf.ConfigProto(log_device_placement=True))\n",
        "init = tf.global_variables_initializer()\n",
        "sess.run(init)\n",
        "\n",
        "# Perform Training steps with \"batch_size\" amount of data at each loop. \n",
        "# Elements of each batch are chosen randomly, without replacement, from X_train, \n",
        "# restarting when remaining datapoints < batch_size\n",
        "step = 1\n",
        "time_start = time.time()\n",
        "unsampled_indices = list(range(0,len(X_train)))\n",
        "\n",
        "while step * batch_size <= training_iters:\n",
        "    #print (sess.run(learning_rate)) #decaying learning rate\n",
        "    #print (sess.run(global_step)) # global number of iterations\n",
        "    if len(unsampled_indices) < batch_size:\n",
        "        unsampled_indices = list(range(0,len(X_train))) \n",
        "    batch_xs, raw_labels, unsampled_indicies = extract_batch_size(X_train, y_train, unsampled_indices, batch_size)\n",
        "    batch_ys = one_hot(raw_labels)\n",
        "    # check that encoded output is same length as num_classes, if not, pad it \n",
        "    if len(batch_ys[0]) < n_classes:\n",
        "        temp_ys = np.zeros((batch_size, n_classes))\n",
        "        temp_ys[:batch_ys.shape[0],:batch_ys.shape[1]] = batch_ys\n",
        "        batch_ys = temp_ys\n",
        "       \n",
        "    \n",
        "\n",
        "    # Fit training using batch data\n",
        "    _, loss, acc = sess.run(\n",
        "        [optimizer, cost, accuracy],\n",
        "        feed_dict={\n",
        "            x: batch_xs, \n",
        "            y: batch_ys\n",
        "        }\n",
        "    )\n",
        "    train_losses.append(loss)\n",
        "    train_accuracies.append(acc)\n",
        "    \n",
        "    # Evaluate network only at some steps for faster training: \n",
        "    if (step*batch_size % display_iter == 0) or (step == 1) or (step * batch_size > training_iters):\n",
        "        \n",
        "        # To not spam console, show training accuracy/loss in this \"if\"\n",
        "        print(\"Iter #\" + str(step*batch_size) + \\\n",
        "              \":  Learning rate = \" + \"{:.6f}\".format(sess.run(learning_rate)) + \\\n",
        "              \":   Batch Loss = \" + \"{:.6f}\".format(loss) + \\\n",
        "              \", Accuracy = {}\".format(acc))\n",
        "        \n",
        "        # Evaluation on the test set (no learning made here - just evaluation for diagnosis)\n",
        "        loss, acc = sess.run(\n",
        "            [cost, accuracy], \n",
        "            feed_dict={\n",
        "                x: X_test,\n",
        "                y: one_hot(y_test)\n",
        "            }\n",
        "        )\n",
        "        test_losses.append(loss)\n",
        "        test_accuracies.append(acc)\n",
        "        print(\"PERFORMANCE ON TEST SET:             \" + \\\n",
        "              \"Batch Loss = {}\".format(loss) + \\\n",
        "              \", Accuracy = {}\".format(acc))\n",
        "\n",
        "    step += 1\n",
        "\n",
        "print(\"Optimization Finished!\")\n",
        "\n",
        "# Accuracy for test data\n",
        "\n",
        "one_hot_predictions, accuracy, final_loss = sess.run(\n",
        "    [pred, accuracy, cost],\n",
        "    feed_dict={\n",
        "        x: X_test,\n",
        "        y: one_hot(y_test)\n",
        "    }\n",
        ")\n",
        "\n",
        "test_losses.append(final_loss)\n",
        "test_accuracies.append(accuracy)\n",
        "\n",
        "print(\"FINAL RESULT: \" + \\\n",
        "      \"Batch Loss = {}\".format(final_loss) + \\\n",
        "      \", Accuracy = {}\".format(accuracy))\n",
        "time_stop = time.time()\n",
        "print(\"TOTAL TIME:  {}\".format(time_stop - time_start))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iter #512:  Learning rate = 0.005000:   Batch Loss = 3.721630, Accuracy = 0.19140625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 3.28111386299, Accuracy = 0.235263437033\n",
            "Iter #4096:  Learning rate = 0.005000:   Batch Loss = 2.965229, Accuracy = 0.291015625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 2.99533033371, Accuracy = 0.237697795033\n",
            "Iter #8192:  Learning rate = 0.005000:   Batch Loss = 2.859813, Accuracy = 0.333984375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 2.85081100464, Accuracy = 0.31681445241\n",
            "Iter #12288:  Learning rate = 0.005000:   Batch Loss = 2.837276, Accuracy = 0.314453125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 2.92212438583, Accuracy = 0.179968699813\n",
            "Iter #16384:  Learning rate = 0.005000:   Batch Loss = 2.553624, Accuracy = 0.400390625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 2.59975409508, Accuracy = 0.37489131093\n",
            "Iter #20480:  Learning rate = 0.005000:   Batch Loss = 2.554058, Accuracy = 0.361328125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 2.6392250061, Accuracy = 0.329334020615\n",
            "Iter #24576:  Learning rate = 0.005000:   Batch Loss = 2.460992, Accuracy = 0.416015625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 2.43966841698, Accuracy = 0.406885772943\n",
            "Iter #28672:  Learning rate = 0.005000:   Batch Loss = 2.388553, Accuracy = 0.396484375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 2.37573575974, Accuracy = 0.392627358437\n",
            "Iter #32768:  Learning rate = 0.005000:   Batch Loss = 2.633005, Accuracy = 0.310546875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 2.65354967117, Accuracy = 0.292297005653\n",
            "Iter #36864:  Learning rate = 0.005000:   Batch Loss = 2.802214, Accuracy = 0.2578125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 2.53132247925, Accuracy = 0.381846636534\n",
            "Iter #40960:  Learning rate = 0.005000:   Batch Loss = 2.588152, Accuracy = 0.353515625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 2.58157300949, Accuracy = 0.319074928761\n",
            "Iter #45056:  Learning rate = 0.005000:   Batch Loss = 2.806634, Accuracy = 0.291015625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 2.70252561569, Accuracy = 0.25421667099\n",
            "Iter #49152:  Learning rate = 0.005000:   Batch Loss = 2.694367, Accuracy = 0.28515625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 2.77449703217, Accuracy = 0.193009912968\n",
            "Iter #53248:  Learning rate = 0.005000:   Batch Loss = 2.643411, Accuracy = 0.29296875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 2.65830802917, Accuracy = 0.279081910849\n",
            "Iter #57344:  Learning rate = 0.005000:   Batch Loss = 2.677669, Accuracy = 0.23828125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 2.65126657486, Accuracy = 0.242044866085\n",
            "Iter #61440:  Learning rate = 0.005000:   Batch Loss = 2.619879, Accuracy = 0.25\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 2.6093556881, Accuracy = 0.298904538155\n",
            "Iter #65536:  Learning rate = 0.005000:   Batch Loss = 2.638294, Accuracy = 0.220703125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 2.60377287865, Accuracy = 0.258737623692\n",
            "Iter #69632:  Learning rate = 0.005000:   Batch Loss = 2.600135, Accuracy = 0.25\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 2.54722046852, Accuracy = 0.271604925394\n",
            "Iter #73728:  Learning rate = 0.005000:   Batch Loss = 2.565907, Accuracy = 0.25390625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 2.52286934853, Accuracy = 0.253868877888\n",
            "Iter #77824:  Learning rate = 0.005000:   Batch Loss = 2.572005, Accuracy = 0.244140625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 2.50551724434, Accuracy = 0.319944351912\n",
            "Iter #81920:  Learning rate = 0.005000:   Batch Loss = 2.528749, Accuracy = 0.279296875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 2.47224497795, Accuracy = 0.279429674149\n",
            "Iter #86016:  Learning rate = 0.005000:   Batch Loss = 2.517976, Accuracy = 0.244140625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 2.46378803253, Accuracy = 0.288819342852\n",
            "Iter #90112:  Learning rate = 0.005000:   Batch Loss = 2.479965, Accuracy = 0.265625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 2.45755362511, Accuracy = 0.261519730091\n",
            "Iter #94208:  Learning rate = 0.005000:   Batch Loss = 2.444586, Accuracy = 0.28515625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 2.43977284431, Accuracy = 0.256129354239\n",
            "Iter #98304:  Learning rate = 0.005000:   Batch Loss = 2.460972, Accuracy = 0.279296875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 2.41439914703, Accuracy = 0.255433827639\n",
            "Iter #102400:  Learning rate = 0.004800:   Batch Loss = 2.464220, Accuracy = 0.326171875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 2.3944811821, Accuracy = 0.340288639069\n",
            "Iter #106496:  Learning rate = 0.004800:   Batch Loss = 2.388232, Accuracy = 0.29296875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 2.38069725037, Accuracy = 0.260128676891\n",
            "Iter #110592:  Learning rate = 0.004800:   Batch Loss = 2.398901, Accuracy = 0.3359375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 2.32873344421, Accuracy = 0.370022594929\n",
            "Iter #114688:  Learning rate = 0.004800:   Batch Loss = 2.616621, Accuracy = 0.228515625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 2.25947976112, Accuracy = 0.37158754468\n",
            "Iter #118784:  Learning rate = 0.004800:   Batch Loss = 2.493641, Accuracy = 0.232421875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 2.41554522514, Accuracy = 0.282211780548\n",
            "Iter #122880:  Learning rate = 0.004800:   Batch Loss = 2.462467, Accuracy = 0.26953125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 2.4470705986, Accuracy = 0.239784389734\n",
            "Iter #126976:  Learning rate = 0.004800:   Batch Loss = 2.458929, Accuracy = 0.279296875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 2.49819302559, Accuracy = 0.212484791875\n",
            "Iter #131072:  Learning rate = 0.004800:   Batch Loss = 2.441549, Accuracy = 0.271484375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 2.42959260941, Accuracy = 0.332637816668\n",
            "Iter #135168:  Learning rate = 0.004800:   Batch Loss = 2.365756, Accuracy = 0.33984375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 2.38661289215, Accuracy = 0.351069390774\n",
            "Iter #139264:  Learning rate = 0.004800:   Batch Loss = 2.428912, Accuracy = 0.28125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 2.3044219017, Accuracy = 0.385324299335\n",
            "Iter #143360:  Learning rate = 0.004800:   Batch Loss = 2.401888, Accuracy = 0.33984375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 2.47575378418, Accuracy = 0.259780913591\n",
            "Iter #147456:  Learning rate = 0.004800:   Batch Loss = 2.421603, Accuracy = 0.263671875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 2.42525291443, Accuracy = 0.283776730299\n",
            "Iter #151552:  Learning rate = 0.004800:   Batch Loss = 2.446802, Accuracy = 0.208984375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 2.39493894577, Accuracy = 0.241349324584\n",
            "Iter #155648:  Learning rate = 0.004800:   Batch Loss = 2.458368, Accuracy = 0.1875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 2.41390109062, Accuracy = 0.268648922443\n",
            "Iter #159744:  Learning rate = 0.004800:   Batch Loss = 2.405482, Accuracy = 0.23828125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 2.40462684631, Accuracy = 0.230742484331\n",
            "Iter #163840:  Learning rate = 0.004800:   Batch Loss = 2.400976, Accuracy = 0.259765625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 2.39249897003, Accuracy = 0.264997392893\n",
            "Iter #167936:  Learning rate = 0.004800:   Batch Loss = 2.401310, Accuracy = 0.263671875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 2.37328362465, Accuracy = 0.243088155985\n",
            "Iter #172032:  Learning rate = 0.004800:   Batch Loss = 2.370541, Accuracy = 0.2734375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 2.35060310364, Accuracy = 0.272474348545\n",
            "Iter #176128:  Learning rate = 0.004800:   Batch Loss = 2.351885, Accuracy = 0.28125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 2.33508777618, Accuracy = 0.252825587988\n",
            "Iter #180224:  Learning rate = 0.004800:   Batch Loss = 2.334157, Accuracy = 0.2890625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 2.32460451126, Accuracy = 0.263258576393\n",
            "Iter #184320:  Learning rate = 0.004800:   Batch Loss = 2.337775, Accuracy = 0.275390625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 2.31776380539, Accuracy = 0.268648922443\n",
            "Iter #188416:  Learning rate = 0.004800:   Batch Loss = 2.367207, Accuracy = 0.25\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 2.34311461449, Accuracy = 0.28603720665\n",
            "Iter #192512:  Learning rate = 0.004800:   Batch Loss = 2.326634, Accuracy = 0.275390625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 2.3277118206, Accuracy = 0.291775345802\n",
            "Iter #196608:  Learning rate = 0.004800:   Batch Loss = 2.295450, Accuracy = 0.248046875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 2.30941605568, Accuracy = 0.251956194639\n",
            "Iter #200704:  Learning rate = 0.004608:   Batch Loss = 2.313482, Accuracy = 0.298828125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 2.2977604866, Accuracy = 0.253868877888\n",
            "Iter #204800:  Learning rate = 0.004608:   Batch Loss = 2.405951, Accuracy = 0.216796875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 2.43810224533, Accuracy = 0.166405841708\n",
            "Iter #208896:  Learning rate = 0.004608:   Batch Loss = 2.374030, Accuracy = 0.1875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 2.34440422058, Accuracy = 0.192140504718\n",
            "Iter #212992:  Learning rate = 0.004608:   Batch Loss = 2.317534, Accuracy = 0.255859375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 2.32187128067, Accuracy = 0.19979134202\n",
            "Iter #217088:  Learning rate = 0.004608:   Batch Loss = 2.276671, Accuracy = 0.28125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 2.31020927429, Accuracy = 0.248130753636\n",
            "Iter #221184:  Learning rate = 0.004608:   Batch Loss = 2.223108, Accuracy = 0.3125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 2.27365875244, Accuracy = 0.275082588196\n",
            "Iter #225280:  Learning rate = 0.004608:   Batch Loss = 2.222157, Accuracy = 0.36328125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 2.25697374344, Accuracy = 0.282907307148\n",
            "Iter #229376:  Learning rate = 0.004608:   Batch Loss = 2.132961, Accuracy = 0.341796875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 2.2057390213, Accuracy = 0.298209011555\n",
            "Iter #233472:  Learning rate = 0.004608:   Batch Loss = 2.405022, Accuracy = 0.173828125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 2.32336235046, Accuracy = 0.210745960474\n",
            "Iter #237568:  Learning rate = 0.004608:   Batch Loss = 2.334859, Accuracy = 0.212890625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 2.30421066284, Accuracy = 0.213354200125\n",
            "Iter #241664:  Learning rate = 0.004608:   Batch Loss = 2.288128, Accuracy = 0.2265625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 2.2979221344, Accuracy = 0.198052510619\n",
            "Iter #245760:  Learning rate = 0.004608:   Batch Loss = 2.286582, Accuracy = 0.24609375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 2.30081367493, Accuracy = 0.211093723774\n",
            "Iter #249856:  Learning rate = 0.004608:   Batch Loss = 2.232106, Accuracy = 0.251953125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 2.27269792557, Accuracy = 0.209702655673\n",
            "Iter #253952:  Learning rate = 0.004608:   Batch Loss = 2.237969, Accuracy = 0.232421875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 2.24755811691, Accuracy = 0.265171289444\n",
            "Iter #258048:  Learning rate = 0.004608:   Batch Loss = 2.233559, Accuracy = 0.271484375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 2.23360514641, Accuracy = 0.244131460786\n",
            "Iter #262144:  Learning rate = 0.004608:   Batch Loss = 2.171089, Accuracy = 0.3828125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 2.19644618034, Accuracy = 0.323074251413\n",
            "Iter #266240:  Learning rate = 0.004608:   Batch Loss = 2.108522, Accuracy = 0.345703125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 2.19091463089, Accuracy = 0.299252301455\n",
            "Iter #270336:  Learning rate = 0.004608:   Batch Loss = 2.186949, Accuracy = 0.341796875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 2.28814840317, Accuracy = 0.252303957939\n",
            "Iter #274432:  Learning rate = 0.004608:   Batch Loss = 2.195582, Accuracy = 0.294921875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 2.16391324997, Accuracy = 0.296991825104\n",
            "Iter #278528:  Learning rate = 0.004608:   Batch Loss = 2.152030, Accuracy = 0.33203125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 2.18956661224, Accuracy = 0.309163630009\n",
            "Iter #282624:  Learning rate = 0.004608:   Batch Loss = 2.035889, Accuracy = 0.37890625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 2.12910914421, Accuracy = 0.338723689318\n",
            "Iter #286720:  Learning rate = 0.004608:   Batch Loss = 1.980831, Accuracy = 0.416015625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 2.07703495026, Accuracy = 0.34081029892\n",
            "Iter #290816:  Learning rate = 0.004608:   Batch Loss = 1.907857, Accuracy = 0.453125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 2.04886865616, Accuracy = 0.387584775686\n",
            "Iter #294912:  Learning rate = 0.004608:   Batch Loss = 1.946433, Accuracy = 0.427734375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 2.07848834991, Accuracy = 0.380281686783\n",
            "Iter #299008:  Learning rate = 0.004608:   Batch Loss = 1.995933, Accuracy = 0.375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 2.25714969635, Accuracy = 0.300121724606\n",
            "Iter #303104:  Learning rate = 0.004424:   Batch Loss = 2.060022, Accuracy = 0.3203125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 2.04561924934, Accuracy = 0.326899677515\n",
            "Iter #307200:  Learning rate = 0.004424:   Batch Loss = 2.039755, Accuracy = 0.333984375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 2.00753879547, Accuracy = 0.358198583126\n",
            "Iter #311296:  Learning rate = 0.004424:   Batch Loss = 1.937980, Accuracy = 0.4296875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 2.00472378731, Accuracy = 0.393496781588\n",
            "Iter #315392:  Learning rate = 0.004424:   Batch Loss = 1.924281, Accuracy = 0.41796875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.98924481869, Accuracy = 0.383411586285\n",
            "Iter #319488:  Learning rate = 0.004424:   Batch Loss = 1.880410, Accuracy = 0.41796875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.98828959465, Accuracy = 0.39853939414\n",
            "Iter #323584:  Learning rate = 0.004424:   Batch Loss = 1.861847, Accuracy = 0.435546875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.92012476921, Accuracy = 0.420274734497\n",
            "Iter #327680:  Learning rate = 0.004424:   Batch Loss = 1.820280, Accuracy = 0.439453125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.97295928001, Accuracy = 0.419926971197\n",
            "Iter #331776:  Learning rate = 0.004424:   Batch Loss = 1.837528, Accuracy = 0.466796875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.9010477066, Accuracy = 0.407929062843\n",
            "Iter #335872:  Learning rate = 0.004424:   Batch Loss = 1.808621, Accuracy = 0.48828125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.89457094669, Accuracy = 0.411580592394\n",
            "Iter #339968:  Learning rate = 0.004424:   Batch Loss = 1.895140, Accuracy = 0.43359375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.93937087059, Accuracy = 0.434011489153\n",
            "Iter #344064:  Learning rate = 0.004424:   Batch Loss = 1.874336, Accuracy = 0.4296875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.88257861137, Accuracy = 0.434185355902\n",
            "Iter #348160:  Learning rate = 0.004424:   Batch Loss = 1.750159, Accuracy = 0.48828125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.9651465416, Accuracy = 0.384454876184\n",
            "Iter #352256:  Learning rate = 0.004424:   Batch Loss = 1.897355, Accuracy = 0.416015625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.88573384285, Accuracy = 0.413493305445\n",
            "Iter #356352:  Learning rate = 0.004424:   Batch Loss = 1.757554, Accuracy = 0.484375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.83025968075, Accuracy = 0.45574682951\n",
            "Iter #360448:  Learning rate = 0.004424:   Batch Loss = 1.766090, Accuracy = 0.47265625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.84658312798, Accuracy = 0.431577116251\n",
            "Iter #364544:  Learning rate = 0.004424:   Batch Loss = 1.754162, Accuracy = 0.478515625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.81870102882, Accuracy = 0.424621790648\n",
            "Iter #368640:  Learning rate = 0.004424:   Batch Loss = 1.877769, Accuracy = 0.435546875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.81445658207, Accuracy = 0.4300121665\n",
            "Iter #372736:  Learning rate = 0.004424:   Batch Loss = 1.751828, Accuracy = 0.478515625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.80106985569, Accuracy = 0.442531734705\n",
            "Iter #376832:  Learning rate = 0.004424:   Batch Loss = 1.692024, Accuracy = 0.5\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.86683416367, Accuracy = 0.393844544888\n",
            "Iter #380928:  Learning rate = 0.004424:   Batch Loss = 1.771169, Accuracy = 0.462890625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.8119764328, Accuracy = 0.431924879551\n",
            "Iter #385024:  Learning rate = 0.004424:   Batch Loss = 1.743967, Accuracy = 0.4765625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 2.07796216011, Accuracy = 0.375934630632\n",
            "Iter #389120:  Learning rate = 0.004424:   Batch Loss = 1.734921, Accuracy = 0.4609375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.81821393967, Accuracy = 0.419057548046\n",
            "Iter #393216:  Learning rate = 0.004424:   Batch Loss = 1.684061, Accuracy = 0.4921875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.8510351181, Accuracy = 0.423926264048\n",
            "Iter #397312:  Learning rate = 0.004424:   Batch Loss = 1.624028, Accuracy = 0.537109375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.76877331734, Accuracy = 0.442531734705\n",
            "Iter #401408:  Learning rate = 0.004247:   Batch Loss = 1.691616, Accuracy = 0.47265625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.78466105461, Accuracy = 0.452616930008\n",
            "Iter #405504:  Learning rate = 0.004247:   Batch Loss = 1.680523, Accuracy = 0.4765625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.7797986269, Accuracy = 0.434533119202\n",
            "Iter #409600:  Learning rate = 0.004247:   Batch Loss = 1.663477, Accuracy = 0.521484375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.78580367565, Accuracy = 0.450530350208\n",
            "Iter #413696:  Learning rate = 0.004247:   Batch Loss = 1.643046, Accuracy = 0.50390625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.75977158546, Accuracy = 0.455225169659\n",
            "Iter #417792:  Learning rate = 0.004247:   Batch Loss = 1.624322, Accuracy = 0.53515625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.77808499336, Accuracy = 0.438880205154\n",
            "Iter #421888:  Learning rate = 0.004247:   Batch Loss = 1.642035, Accuracy = 0.51171875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.99074673653, Accuracy = 0.406537979841\n",
            "Iter #425984:  Learning rate = 0.004247:   Batch Loss = 1.667022, Accuracy = 0.490234375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.75682711601, Accuracy = 0.45539906621\n",
            "Iter #430080:  Learning rate = 0.004247:   Batch Loss = 1.750932, Accuracy = 0.451171875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.74909567833, Accuracy = 0.436271965504\n",
            "Iter #434176:  Learning rate = 0.004247:   Batch Loss = 1.716864, Accuracy = 0.46875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.80140662193, Accuracy = 0.461832731962\n",
            "Iter #438272:  Learning rate = 0.004247:   Batch Loss = 1.704399, Accuracy = 0.46875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.74120855331, Accuracy = 0.450530350208\n",
            "Iter #442368:  Learning rate = 0.004247:   Batch Loss = 1.543953, Accuracy = 0.57421875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.73151600361, Accuracy = 0.461484968662\n",
            "Iter #446464:  Learning rate = 0.004247:   Batch Loss = 1.624673, Accuracy = 0.533203125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.76165175438, Accuracy = 0.462876021862\n",
            "Iter #450560:  Learning rate = 0.004247:   Batch Loss = 1.637564, Accuracy = 0.53125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.75335240364, Accuracy = 0.462528258562\n",
            "Iter #454656:  Learning rate = 0.004247:   Batch Loss = 1.642870, Accuracy = 0.51171875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.73116564751, Accuracy = 0.477829933167\n",
            "Iter #458752:  Learning rate = 0.004247:   Batch Loss = 1.571977, Accuracy = 0.544921875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.72299313545, Accuracy = 0.474526166916\n",
            "Iter #462848:  Learning rate = 0.004247:   Batch Loss = 1.615335, Accuracy = 0.50390625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.70599591732, Accuracy = 0.463745445013\n",
            "Iter #466944:  Learning rate = 0.004247:   Batch Loss = 2.065996, Accuracy = 0.408203125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 2.43999242783, Accuracy = 0.34446182847\n",
            "Iter #471040:  Learning rate = 0.004247:   Batch Loss = 1.835812, Accuracy = 0.462890625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.89767241478, Accuracy = 0.398017734289\n",
            "Iter #475136:  Learning rate = 0.004247:   Batch Loss = 1.831456, Accuracy = 0.4140625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.83524131775, Accuracy = 0.426882266998\n",
            "Iter #479232:  Learning rate = 0.004247:   Batch Loss = 1.740587, Accuracy = 0.455078125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.84190106392, Accuracy = 0.392279595137\n",
            "Iter #483328:  Learning rate = 0.004247:   Batch Loss = 1.734617, Accuracy = 0.46484375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.75158703327, Accuracy = 0.466875314713\n",
            "Iter #487424:  Learning rate = 0.004247:   Batch Loss = 1.669916, Accuracy = 0.5\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.74265682697, Accuracy = 0.475917220116\n",
            "Iter #491520:  Learning rate = 0.004247:   Batch Loss = 1.781930, Accuracy = 0.48046875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.77660274506, Accuracy = 0.434359252453\n",
            "Iter #495616:  Learning rate = 0.004247:   Batch Loss = 1.729720, Accuracy = 0.474609375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.76681542397, Accuracy = 0.462702125311\n",
            "Iter #499712:  Learning rate = 0.004247:   Batch Loss = 1.581102, Accuracy = 0.513671875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.74892878532, Accuracy = 0.464267075062\n",
            "Iter #503808:  Learning rate = 0.004077:   Batch Loss = 1.649379, Accuracy = 0.478515625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.72637975216, Accuracy = 0.465484261513\n",
            "Iter #507904:  Learning rate = 0.004077:   Batch Loss = 1.577277, Accuracy = 0.529296875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.71322667599, Accuracy = 0.450008690357\n",
            "Iter #512000:  Learning rate = 0.004077:   Batch Loss = 1.551152, Accuracy = 0.56640625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.73706078529, Accuracy = 0.450530350208\n",
            "Iter #516096:  Learning rate = 0.004077:   Batch Loss = 1.619548, Accuracy = 0.513671875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.72782742977, Accuracy = 0.45939835906\n",
            "Iter #520192:  Learning rate = 0.004077:   Batch Loss = 1.653920, Accuracy = 0.484375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.7325937748, Accuracy = 0.482872545719\n",
            "Iter #524288:  Learning rate = 0.004077:   Batch Loss = 1.542076, Accuracy = 0.548828125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.70539832115, Accuracy = 0.473135113716\n",
            "Iter #528384:  Learning rate = 0.004077:   Batch Loss = 1.945978, Accuracy = 0.373046875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.88202810287, Accuracy = 0.4310554564\n",
            "Iter #532480:  Learning rate = 0.004077:   Batch Loss = 1.827036, Accuracy = 0.4140625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 2.02608585358, Accuracy = 0.384976536036\n",
            "Iter #536576:  Learning rate = 0.004077:   Batch Loss = 1.659310, Accuracy = 0.5078125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.77787554264, Accuracy = 0.462528258562\n",
            "Iter #540672:  Learning rate = 0.004077:   Batch Loss = 1.684786, Accuracy = 0.482421875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.74546837807, Accuracy = 0.437836885452\n",
            "Iter #544768:  Learning rate = 0.004077:   Batch Loss = 1.628816, Accuracy = 0.515625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.75838518143, Accuracy = 0.4289688766\n",
            "Iter #548864:  Learning rate = 0.004077:   Batch Loss = 1.798110, Accuracy = 0.443359375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.78015494347, Accuracy = 0.420622497797\n",
            "Iter #552960:  Learning rate = 0.004077:   Batch Loss = 1.732196, Accuracy = 0.44921875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.82128691673, Accuracy = 0.423926264048\n",
            "Iter #557056:  Learning rate = 0.004077:   Batch Loss = 1.651614, Accuracy = 0.501953125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.71414923668, Accuracy = 0.459572255611\n",
            "Iter #561152:  Learning rate = 0.004077:   Batch Loss = 1.602822, Accuracy = 0.525390625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.71407651901, Accuracy = 0.471396267414\n",
            "Iter #565248:  Learning rate = 0.004077:   Batch Loss = 1.585579, Accuracy = 0.5\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.76743388176, Accuracy = 0.453834116459\n",
            "Iter #569344:  Learning rate = 0.004077:   Batch Loss = 1.612486, Accuracy = 0.47265625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.69298505783, Accuracy = 0.472613453865\n",
            "Iter #573440:  Learning rate = 0.004077:   Batch Loss = 1.690628, Accuracy = 0.4609375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.7486833334, Accuracy = 0.446531027555\n",
            "Iter #577536:  Learning rate = 0.004077:   Batch Loss = 1.668290, Accuracy = 0.494140625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.71476817131, Accuracy = 0.469831347466\n",
            "Iter #581632:  Learning rate = 0.004077:   Batch Loss = 1.611385, Accuracy = 0.537109375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.69501245022, Accuracy = 0.469135791063\n",
            "Iter #585728:  Learning rate = 0.004077:   Batch Loss = 1.502327, Accuracy = 0.576171875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.68432927132, Accuracy = 0.487045735121\n",
            "Iter #589824:  Learning rate = 0.004077:   Batch Loss = 1.589069, Accuracy = 0.53125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.66100370884, Accuracy = 0.492088317871\n",
            "Iter #593920:  Learning rate = 0.004077:   Batch Loss = 1.485836, Accuracy = 0.560546875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.67103600502, Accuracy = 0.489653974771\n",
            "Iter #598016:  Learning rate = 0.004077:   Batch Loss = 1.547774, Accuracy = 0.515625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.64611339569, Accuracy = 0.499913066626\n",
            "Iter #602112:  Learning rate = 0.003914:   Batch Loss = 1.570169, Accuracy = 0.544921875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.66953992844, Accuracy = 0.483915835619\n",
            "Iter #606208:  Learning rate = 0.003914:   Batch Loss = 1.553969, Accuracy = 0.533203125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.6463958025, Accuracy = 0.475569456816\n",
            "Iter #610304:  Learning rate = 0.003914:   Batch Loss = 1.560126, Accuracy = 0.560546875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.64803361893, Accuracy = 0.467049211264\n",
            "Iter #614400:  Learning rate = 0.003914:   Batch Loss = 1.546177, Accuracy = 0.53515625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.64186990261, Accuracy = 0.45939835906\n",
            "Iter #618496:  Learning rate = 0.003914:   Batch Loss = 1.683750, Accuracy = 0.46484375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.62398338318, Accuracy = 0.470005214214\n",
            "Iter #622592:  Learning rate = 0.003914:   Batch Loss = 1.592875, Accuracy = 0.515625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.77792155743, Accuracy = 0.4275778234\n",
            "Iter #626688:  Learning rate = 0.003914:   Batch Loss = 1.558472, Accuracy = 0.541015625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.70224952698, Accuracy = 0.475917220116\n",
            "Iter #630784:  Learning rate = 0.003914:   Batch Loss = 1.513030, Accuracy = 0.53125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.67645120621, Accuracy = 0.457485646009\n",
            "Iter #634880:  Learning rate = 0.003914:   Batch Loss = 1.518160, Accuracy = 0.548828125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.64684033394, Accuracy = 0.470352977514\n",
            "Iter #638976:  Learning rate = 0.003914:   Batch Loss = 1.520642, Accuracy = 0.560546875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.64233255386, Accuracy = 0.488436788321\n",
            "Iter #643072:  Learning rate = 0.003914:   Batch Loss = 1.644767, Accuracy = 0.5078125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.6910752058, Accuracy = 0.465832024813\n",
            "Iter #647168:  Learning rate = 0.003914:   Batch Loss = 1.552541, Accuracy = 0.541015625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.65746247768, Accuracy = 0.496261507273\n",
            "Iter #651264:  Learning rate = 0.003914:   Batch Loss = 1.608151, Accuracy = 0.498046875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.72406733036, Accuracy = 0.450356453657\n",
            "Iter #655360:  Learning rate = 0.003914:   Batch Loss = 1.641357, Accuracy = 0.494140625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.69963121414, Accuracy = 0.490523397923\n",
            "Iter #659456:  Learning rate = 0.003914:   Batch Loss = 1.716476, Accuracy = 0.484375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.77677083015, Accuracy = 0.449660927057\n",
            "Iter #663552:  Learning rate = 0.003914:   Batch Loss = 1.563464, Accuracy = 0.51953125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.6674478054, Accuracy = 0.48443749547\n",
            "Iter #667648:  Learning rate = 0.003914:   Batch Loss = 1.527308, Accuracy = 0.52734375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.64270722866, Accuracy = 0.493305504322\n",
            "Iter #671744:  Learning rate = 0.003914:   Batch Loss = 1.619857, Accuracy = 0.513671875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.71679568291, Accuracy = 0.511563181877\n",
            "Iter #675840:  Learning rate = 0.003914:   Batch Loss = 1.581506, Accuracy = 0.509765625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.65624046326, Accuracy = 0.482872545719\n",
            "Iter #679936:  Learning rate = 0.003914:   Batch Loss = 1.494824, Accuracy = 0.54296875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.4999922514, Accuracy = 0.559380948544\n",
            "Iter #684032:  Learning rate = 0.003914:   Batch Loss = 1.345822, Accuracy = 0.654296875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.37854456902, Accuracy = 0.618674993515\n",
            "Iter #688128:  Learning rate = 0.003914:   Batch Loss = 1.305874, Accuracy = 0.62890625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.37257039547, Accuracy = 0.59833073616\n",
            "Iter #692224:  Learning rate = 0.003914:   Batch Loss = 1.360742, Accuracy = 0.61328125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.3165371418, Accuracy = 0.650669455528\n",
            "Iter #696320:  Learning rate = 0.003914:   Batch Loss = 1.254789, Accuracy = 0.658203125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.55883216858, Accuracy = 0.554686129093\n",
            "Iter #700416:  Learning rate = 0.003757:   Batch Loss = 1.296479, Accuracy = 0.6328125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.28020310402, Accuracy = 0.648061215878\n",
            "Iter #704512:  Learning rate = 0.003757:   Batch Loss = 1.230425, Accuracy = 0.666015625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.24558997154, Accuracy = 0.667014420033\n",
            "Iter #708608:  Learning rate = 0.003757:   Batch Loss = 1.324303, Accuracy = 0.623046875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.26627087593, Accuracy = 0.667536079884\n",
            "Iter #712704:  Learning rate = 0.003757:   Batch Loss = 1.261796, Accuracy = 0.69140625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.27747762203, Accuracy = 0.65449488163\n",
            "Iter #716800:  Learning rate = 0.003757:   Batch Loss = 1.267427, Accuracy = 0.64453125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.18705999851, Accuracy = 0.694140136242\n",
            "Iter #720896:  Learning rate = 0.003757:   Batch Loss = 1.214856, Accuracy = 0.69140625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.19447553158, Accuracy = 0.703182041645\n",
            "Iter #724992:  Learning rate = 0.003757:   Batch Loss = 1.256051, Accuracy = 0.65625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.24422705173, Accuracy = 0.686837077141\n",
            "Iter #729088:  Learning rate = 0.003757:   Batch Loss = 1.227620, Accuracy = 0.669921875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.20413315296, Accuracy = 0.699530541897\n",
            "Iter #733184:  Learning rate = 0.003757:   Batch Loss = 2.156621, Accuracy = 0.255859375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 2.1622467041, Accuracy = 0.246218055487\n",
            "Iter #737280:  Learning rate = 0.003757:   Batch Loss = 2.115894, Accuracy = 0.26171875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 2.11941123009, Accuracy = 0.247261345387\n",
            "Iter #741376:  Learning rate = 0.003757:   Batch Loss = 2.030394, Accuracy = 0.244140625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 2.08870601654, Accuracy = 0.265866816044\n",
            "Iter #745472:  Learning rate = 0.003757:   Batch Loss = 2.007113, Accuracy = 0.271484375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 2.07185769081, Accuracy = 0.271778821945\n",
            "Iter #749568:  Learning rate = 0.003757:   Batch Loss = 2.036385, Accuracy = 0.28125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 2.07769227028, Accuracy = 0.256129354239\n",
            "Iter #753664:  Learning rate = 0.003757:   Batch Loss = 2.019774, Accuracy = 0.279296875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 2.06532645226, Accuracy = 0.255433827639\n",
            "Iter #757760:  Learning rate = 0.003757:   Batch Loss = 2.014239, Accuracy = 0.27734375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 2.06612181664, Accuracy = 0.288471579552\n",
            "Iter #761856:  Learning rate = 0.003757:   Batch Loss = 2.008621, Accuracy = 0.306640625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 2.06185007095, Accuracy = 0.282559543848\n",
            "Iter #765952:  Learning rate = 0.003757:   Batch Loss = 1.990810, Accuracy = 0.28515625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 2.05779004097, Accuracy = 0.233524605632\n",
            "Iter #770048:  Learning rate = 0.003757:   Batch Loss = 1.983975, Accuracy = 0.30078125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 2.05516052246, Accuracy = 0.258042067289\n",
            "Iter #774144:  Learning rate = 0.003757:   Batch Loss = 1.955505, Accuracy = 0.310546875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 2.05511379242, Accuracy = 0.241349324584\n",
            "Iter #778240:  Learning rate = 0.003757:   Batch Loss = 1.979465, Accuracy = 0.283203125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 2.05532598495, Accuracy = 0.290036529303\n",
            "Iter #782336:  Learning rate = 0.003757:   Batch Loss = 1.933220, Accuracy = 0.296875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 2.03833389282, Accuracy = 0.299426198006\n",
            "Iter #786432:  Learning rate = 0.003757:   Batch Loss = 1.958964, Accuracy = 0.345703125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 2.04584169388, Accuracy = 0.242740392685\n",
            "Iter #790528:  Learning rate = 0.003757:   Batch Loss = 1.992645, Accuracy = 0.298828125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 2.03533172607, Accuracy = 0.249869585037\n",
            "Iter #794624:  Learning rate = 0.003757:   Batch Loss = 1.972857, Accuracy = 0.279296875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 2.0348906517, Accuracy = 0.2889932096\n",
            "Iter #798720:  Learning rate = 0.003757:   Batch Loss = 1.987581, Accuracy = 0.3125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 2.02918434143, Accuracy = 0.2889932096\n",
            "Iter #802816:  Learning rate = 0.003607:   Batch Loss = 1.953834, Accuracy = 0.3203125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 2.03010296822, Accuracy = 0.254390537739\n",
            "Iter #806912:  Learning rate = 0.003607:   Batch Loss = 1.964301, Accuracy = 0.26953125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 2.05134105682, Accuracy = 0.278560250998\n",
            "Iter #811008:  Learning rate = 0.003607:   Batch Loss = 1.940353, Accuracy = 0.310546875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 2.02911233902, Accuracy = 0.25925925374\n",
            "Iter #815104:  Learning rate = 0.003607:   Batch Loss = 1.971611, Accuracy = 0.287109375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 2.0206284523, Accuracy = 0.251260638237\n",
            "Iter #819200:  Learning rate = 0.003607:   Batch Loss = 2.012712, Accuracy = 0.24609375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 2.02636790276, Accuracy = 0.237176150084\n",
            "Iter #823296:  Learning rate = 0.003607:   Batch Loss = 1.972278, Accuracy = 0.310546875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 2.01981925964, Accuracy = 0.241523206234\n",
            "Iter #827392:  Learning rate = 0.003607:   Batch Loss = 1.929198, Accuracy = 0.306640625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 2.01929211617, Accuracy = 0.245000869036\n",
            "Iter #831488:  Learning rate = 0.003607:   Batch Loss = 1.937916, Accuracy = 0.294921875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 2.02403187752, Accuracy = 0.242392629385\n",
            "Iter #835584:  Learning rate = 0.003607:   Batch Loss = 1.945382, Accuracy = 0.314453125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 2.02602863312, Accuracy = 0.249347940087\n",
            "Iter #839680:  Learning rate = 0.003607:   Batch Loss = 1.953454, Accuracy = 0.33203125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 2.01231598854, Accuracy = 0.248130753636\n",
            "Iter #843776:  Learning rate = 0.003607:   Batch Loss = 2.023109, Accuracy = 0.255859375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 2.01197957993, Accuracy = 0.242044866085\n",
            "Iter #847872:  Learning rate = 0.003607:   Batch Loss = 1.934675, Accuracy = 0.318359375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 2.01127099991, Accuracy = 0.259433150291\n",
            "Iter #851968:  Learning rate = 0.003607:   Batch Loss = 1.979434, Accuracy = 0.263671875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 2.00621604919, Accuracy = 0.267953395844\n",
            "Iter #856064:  Learning rate = 0.003607:   Batch Loss = 1.913897, Accuracy = 0.306640625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 2.00817203522, Accuracy = 0.263084679842\n",
            "Iter #860160:  Learning rate = 0.003607:   Batch Loss = 1.905254, Accuracy = 0.30859375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.9423636198, Accuracy = 0.25925925374\n",
            "Iter #864256:  Learning rate = 0.003607:   Batch Loss = 1.893104, Accuracy = 0.326171875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.94784092903, Accuracy = 0.265345156193\n",
            "Iter #868352:  Learning rate = 0.003607:   Batch Loss = 1.878534, Accuracy = 0.3515625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.91594743729, Accuracy = 0.279603540897\n",
            "Iter #872448:  Learning rate = 0.003607:   Batch Loss = 1.923240, Accuracy = 0.275390625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.90168595314, Accuracy = 0.322378724813\n",
            "Iter #876544:  Learning rate = 0.003607:   Batch Loss = 1.922080, Accuracy = 0.298828125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.88655543327, Accuracy = 0.277516961098\n",
            "Iter #880640:  Learning rate = 0.003607:   Batch Loss = 1.837978, Accuracy = 0.34765625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.8855175972, Accuracy = 0.31333681941\n",
            "Iter #884736:  Learning rate = 0.003607:   Batch Loss = 1.876230, Accuracy = 0.328125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.89000809193, Accuracy = 0.282211780548\n",
            "Iter #888832:  Learning rate = 0.003607:   Batch Loss = 1.926392, Accuracy = 0.33203125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.91709804535, Accuracy = 0.262736916542\n",
            "Iter #892928:  Learning rate = 0.003607:   Batch Loss = 1.934472, Accuracy = 0.263671875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.91224753857, Accuracy = 0.270561635494\n",
            "Iter #897024:  Learning rate = 0.003607:   Batch Loss = 1.873692, Accuracy = 0.380859375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.87594616413, Accuracy = 0.378195106983\n",
            "Iter #901120:  Learning rate = 0.003463:   Batch Loss = 1.784097, Accuracy = 0.3984375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.86590158939, Accuracy = 0.380803346634\n",
            "Iter #905216:  Learning rate = 0.003463:   Batch Loss = 1.667609, Accuracy = 0.390625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.78292107582, Accuracy = 0.368631541729\n",
            "Iter #909312:  Learning rate = 0.003463:   Batch Loss = 1.654342, Accuracy = 0.40234375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.82144069672, Accuracy = 0.349852204323\n",
            "Iter #913408:  Learning rate = 0.003463:   Batch Loss = 1.694764, Accuracy = 0.390625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.83635723591, Accuracy = 0.320639878511\n",
            "Iter #917504:  Learning rate = 0.003463:   Batch Loss = 1.618190, Accuracy = 0.421875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.65144896507, Accuracy = 0.413667201996\n",
            "Iter #921600:  Learning rate = 0.003463:   Batch Loss = 1.653764, Accuracy = 0.40234375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.69532132149, Accuracy = 0.353503733873\n",
            "Iter #925696:  Learning rate = 0.003463:   Batch Loss = 1.561564, Accuracy = 0.40234375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.74376189709, Accuracy = 0.385498166084\n",
            "Iter #929792:  Learning rate = 0.003463:   Batch Loss = 1.679330, Accuracy = 0.390625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.66083586216, Accuracy = 0.435402542353\n",
            "Iter #933888:  Learning rate = 0.003463:   Batch Loss = 1.672903, Accuracy = 0.388671875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.68604886532, Accuracy = 0.430533826351\n",
            "Iter #937984:  Learning rate = 0.003463:   Batch Loss = 1.738610, Accuracy = 0.373046875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.63911819458, Accuracy = 0.429142743349\n",
            "Iter #942080:  Learning rate = 0.003463:   Batch Loss = 1.633264, Accuracy = 0.400390625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.61474049091, Accuracy = 0.450182586908\n",
            "Iter #946176:  Learning rate = 0.003463:   Batch Loss = 1.605143, Accuracy = 0.42578125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.61097741127, Accuracy = 0.421491920948\n",
            "Iter #950272:  Learning rate = 0.003463:   Batch Loss = 1.837533, Accuracy = 0.35546875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.75508916378, Accuracy = 0.368109881878\n",
            "Iter #954368:  Learning rate = 0.003463:   Batch Loss = 1.649793, Accuracy = 0.373046875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.61010587215, Accuracy = 0.446704924107\n",
            "Iter #958464:  Learning rate = 0.003463:   Batch Loss = 1.597290, Accuracy = 0.447265625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.72386646271, Accuracy = 0.403408110142\n",
            "Iter #962560:  Learning rate = 0.003463:   Batch Loss = 1.725441, Accuracy = 0.373046875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.81611216068, Accuracy = 0.356285870075\n",
            "Iter #966656:  Learning rate = 0.003463:   Batch Loss = 1.693755, Accuracy = 0.384765625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.71810829639, Accuracy = 0.395061731339\n",
            "Iter #970752:  Learning rate = 0.003463:   Batch Loss = 1.606768, Accuracy = 0.388671875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.70150256157, Accuracy = 0.334376633167\n",
            "Iter #974848:  Learning rate = 0.003463:   Batch Loss = 1.610977, Accuracy = 0.396484375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.60400426388, Accuracy = 0.426534503698\n",
            "Iter #978944:  Learning rate = 0.003463:   Batch Loss = 1.592038, Accuracy = 0.38671875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.59119176865, Accuracy = 0.4293166399\n",
            "Iter #983040:  Learning rate = 0.003463:   Batch Loss = 1.574870, Accuracy = 0.44140625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.61845374107, Accuracy = 0.380629450083\n",
            "Iter #987136:  Learning rate = 0.003463:   Batch Loss = 1.567844, Accuracy = 0.421875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.60543382168, Accuracy = 0.406016349792\n",
            "Iter #991232:  Learning rate = 0.003463:   Batch Loss = 1.554563, Accuracy = 0.427734375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.59089648724, Accuracy = 0.419057548046\n",
            "Iter #995328:  Learning rate = 0.003463:   Batch Loss = 1.627511, Accuracy = 0.404296875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.59737420082, Accuracy = 0.4303599298\n",
            "Iter #999424:  Learning rate = 0.003463:   Batch Loss = 1.618585, Accuracy = 0.427734375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.61818063259, Accuracy = 0.391584068537\n",
            "Iter #1003520:  Learning rate = 0.003324:   Batch Loss = 1.538528, Accuracy = 0.390625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.6258867979, Accuracy = 0.406711876392\n",
            "Iter #1007616:  Learning rate = 0.003324:   Batch Loss = 1.533772, Accuracy = 0.43359375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.55729472637, Accuracy = 0.437315255404\n",
            "Iter #1011712:  Learning rate = 0.003324:   Batch Loss = 1.529295, Accuracy = 0.3828125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.56366300583, Accuracy = 0.375760734081\n",
            "Iter #1015808:  Learning rate = 0.003324:   Batch Loss = 1.500287, Accuracy = 0.4296875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.53181874752, Accuracy = 0.438184648752\n",
            "Iter #1019904:  Learning rate = 0.003324:   Batch Loss = 1.523164, Accuracy = 0.400390625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.55010485649, Accuracy = 0.4279255867\n",
            "Iter #1024000:  Learning rate = 0.003324:   Batch Loss = 1.520981, Accuracy = 0.40234375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.53991723061, Accuracy = 0.4314032197\n",
            "Iter #1028096:  Learning rate = 0.003324:   Batch Loss = 1.562407, Accuracy = 0.416015625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.54664731026, Accuracy = 0.436793595552\n",
            "Iter #1032192:  Learning rate = 0.003324:   Batch Loss = 1.534312, Accuracy = 0.400390625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.53786408901, Accuracy = 0.404973059893\n",
            "Iter #1036288:  Learning rate = 0.003324:   Batch Loss = 1.513593, Accuracy = 0.40625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.53148508072, Accuracy = 0.454877406359\n",
            "Iter #1040384:  Learning rate = 0.003324:   Batch Loss = 1.521716, Accuracy = 0.41015625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.54367721081, Accuracy = 0.434185355902\n",
            "Iter #1044480:  Learning rate = 0.003324:   Batch Loss = 1.562771, Accuracy = 0.400390625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.55330348015, Accuracy = 0.412797778845\n",
            "Iter #1048576:  Learning rate = 0.003324:   Batch Loss = 1.523247, Accuracy = 0.423828125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.50790023804, Accuracy = 0.443227261305\n",
            "Iter #1052672:  Learning rate = 0.003324:   Batch Loss = 1.487438, Accuracy = 0.44921875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.51526689529, Accuracy = 0.446009397507\n",
            "Iter #1056768:  Learning rate = 0.003324:   Batch Loss = 1.547660, Accuracy = 0.38671875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.54827857018, Accuracy = 0.417666494846\n",
            "Iter #1060864:  Learning rate = 0.003324:   Batch Loss = 1.510010, Accuracy = 0.4453125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.51294946671, Accuracy = 0.438184648752\n",
            "Iter #1064960:  Learning rate = 0.003324:   Batch Loss = 1.494143, Accuracy = 0.421875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.53728699684, Accuracy = 0.407929062843\n",
            "Iter #1069056:  Learning rate = 0.003324:   Batch Loss = 1.671109, Accuracy = 0.3828125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.61906504631, Accuracy = 0.398365497589\n",
            "Iter #1073152:  Learning rate = 0.003324:   Batch Loss = 1.793699, Accuracy = 0.318359375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.75362050533, Accuracy = 0.337680399418\n",
            "Iter #1077248:  Learning rate = 0.003324:   Batch Loss = 1.630685, Accuracy = 0.3828125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.62108147144, Accuracy = 0.391757965088\n",
            "Iter #1081344:  Learning rate = 0.003324:   Batch Loss = 1.487597, Accuracy = 0.435546875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.55900764465, Accuracy = 0.430533826351\n",
            "Iter #1085440:  Learning rate = 0.003324:   Batch Loss = 1.594690, Accuracy = 0.3984375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.55191588402, Accuracy = 0.423926264048\n",
            "Iter #1089536:  Learning rate = 0.003324:   Batch Loss = 1.524566, Accuracy = 0.421875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.56347024441, Accuracy = 0.40062597394\n",
            "Iter #1093632:  Learning rate = 0.003324:   Batch Loss = 1.513250, Accuracy = 0.408203125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.54650342464, Accuracy = 0.400452107191\n",
            "Iter #1097728:  Learning rate = 0.003324:   Batch Loss = 1.532904, Accuracy = 0.439453125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.51745140553, Accuracy = 0.426534503698\n",
            "Iter #1101824:  Learning rate = 0.003191:   Batch Loss = 1.545621, Accuracy = 0.392578125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.52459418774, Accuracy = 0.442357838154\n",
            "Iter #1105920:  Learning rate = 0.003191:   Batch Loss = 1.704059, Accuracy = 0.39453125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.62403321266, Accuracy = 0.40027821064\n",
            "Iter #1110016:  Learning rate = 0.003191:   Batch Loss = 1.698382, Accuracy = 0.390625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.64885401726, Accuracy = 0.404973059893\n",
            "Iter #1114112:  Learning rate = 0.003191:   Batch Loss = 1.669638, Accuracy = 0.400390625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.67068171501, Accuracy = 0.401495397091\n",
            "Iter #1118208:  Learning rate = 0.003191:   Batch Loss = 1.545907, Accuracy = 0.431640625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.56128752232, Accuracy = 0.423752397299\n",
            "Iter #1122304:  Learning rate = 0.003191:   Batch Loss = 1.555242, Accuracy = 0.40234375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.56644260883, Accuracy = 0.409320116043\n",
            "Iter #1126400:  Learning rate = 0.003191:   Batch Loss = 1.560285, Accuracy = 0.38671875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.51874005795, Accuracy = 0.436271965504\n",
            "Iter #1130496:  Learning rate = 0.003191:   Batch Loss = 1.506859, Accuracy = 0.4296875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.50690698624, Accuracy = 0.421491920948\n",
            "Iter #1134592:  Learning rate = 0.003191:   Batch Loss = 1.491464, Accuracy = 0.408203125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.50237035751, Accuracy = 0.422013550997\n",
            "Iter #1138688:  Learning rate = 0.003191:   Batch Loss = 1.511672, Accuracy = 0.400390625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.50546991825, Accuracy = 0.422882974148\n",
            "Iter #1142784:  Learning rate = 0.003191:   Batch Loss = 1.493592, Accuracy = 0.421875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.48577797413, Accuracy = 0.445139974356\n",
            "Iter #1146880:  Learning rate = 0.003191:   Batch Loss = 1.467077, Accuracy = 0.447265625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.48818612099, Accuracy = 0.443053394556\n",
            "Iter #1150976:  Learning rate = 0.003191:   Batch Loss = 1.748854, Accuracy = 0.47265625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.61769866943, Accuracy = 0.422361314297\n",
            "Iter #1155072:  Learning rate = 0.003191:   Batch Loss = 1.476575, Accuracy = 0.5234375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.63846385479, Accuracy = 0.356285870075\n",
            "Iter #1159168:  Learning rate = 0.003191:   Batch Loss = 1.514060, Accuracy = 0.43359375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.52937698364, Accuracy = 0.510346055031\n",
            "Iter #1163264:  Learning rate = 0.003191:   Batch Loss = 1.509889, Accuracy = 0.419921875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.49754357338, Accuracy = 0.528951466084\n",
            "Iter #1167360:  Learning rate = 0.003191:   Batch Loss = 1.577054, Accuracy = 0.462890625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.57409608364, Accuracy = 0.464267075062\n",
            "Iter #1171456:  Learning rate = 0.003191:   Batch Loss = 1.484231, Accuracy = 0.44921875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.51664674282, Accuracy = 0.458007305861\n",
            "Iter #1175552:  Learning rate = 0.003191:   Batch Loss = 1.494834, Accuracy = 0.474609375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.50404429436, Accuracy = 0.498000353575\n",
            "Iter #1179648:  Learning rate = 0.003191:   Batch Loss = 1.434175, Accuracy = 0.458984375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.51706838608, Accuracy = 0.457485646009\n",
            "Iter #1183744:  Learning rate = 0.003191:   Batch Loss = 1.456244, Accuracy = 0.470703125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.46176576614, Accuracy = 0.486697971821\n",
            "Iter #1187840:  Learning rate = 0.003191:   Batch Loss = 1.495959, Accuracy = 0.4296875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.50682926178, Accuracy = 0.458181172609\n",
            "Iter #1191936:  Learning rate = 0.003191:   Batch Loss = 1.422277, Accuracy = 0.4921875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.43933773041, Accuracy = 0.522865593433\n",
            "Iter #1196032:  Learning rate = 0.003191:   Batch Loss = 1.305368, Accuracy = 0.49609375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.34973526001, Accuracy = 0.499565303326\n",
            "Iter #1200128:  Learning rate = 0.003064:   Batch Loss = 1.362747, Accuracy = 0.5390625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.3026471138, Accuracy = 0.559033215046\n",
            "Iter #1204224:  Learning rate = 0.003064:   Batch Loss = 1.320799, Accuracy = 0.525390625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.29009509087, Accuracy = 0.551730155945\n",
            "Iter #1208320:  Learning rate = 0.003064:   Batch Loss = 1.486666, Accuracy = 0.43359375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.46617090702, Accuracy = 0.45905059576\n",
            "Iter #1212416:  Learning rate = 0.003064:   Batch Loss = 1.368385, Accuracy = 0.546875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.4090679884, Accuracy = 0.519735693932\n",
            "Iter #1216512:  Learning rate = 0.003064:   Batch Loss = 1.324410, Accuracy = 0.50390625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.34779644012, Accuracy = 0.508781075478\n",
            "Iter #1220608:  Learning rate = 0.003064:   Batch Loss = 1.359082, Accuracy = 0.541015625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.31038486958, Accuracy = 0.563206374645\n",
            "Iter #1224704:  Learning rate = 0.003064:   Batch Loss = 1.296909, Accuracy = 0.50390625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.30140161514, Accuracy = 0.54494869709\n",
            "Iter #1228800:  Learning rate = 0.003064:   Batch Loss = 1.310066, Accuracy = 0.5390625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.28442311287, Accuracy = 0.573291599751\n",
            "Iter #1232896:  Learning rate = 0.003064:   Batch Loss = 1.292797, Accuracy = 0.607421875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.22967362404, Accuracy = 0.627716898918\n",
            "Iter #1236992:  Learning rate = 0.003064:   Batch Loss = 1.278723, Accuracy = 0.5703125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.23228812218, Accuracy = 0.600243449211\n",
            "Iter #1241088:  Learning rate = 0.003064:   Batch Loss = 1.208075, Accuracy = 0.59765625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.27454209328, Accuracy = 0.588593304157\n",
            "Iter #1245184:  Learning rate = 0.003064:   Batch Loss = 1.229601, Accuracy = 0.595703125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.18930006027, Accuracy = 0.619544446468\n",
            "Iter #1249280:  Learning rate = 0.003064:   Batch Loss = 1.162123, Accuracy = 0.626953125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.15724086761, Accuracy = 0.647713422775\n",
            "Iter #1253376:  Learning rate = 0.003064:   Batch Loss = 1.217756, Accuracy = 0.58203125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.16722202301, Accuracy = 0.643887996674\n",
            "Iter #1257472:  Learning rate = 0.003064:   Batch Loss = 1.139948, Accuracy = 0.634765625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.17911660671, Accuracy = 0.632063984871\n",
            "Iter #1261568:  Learning rate = 0.003064:   Batch Loss = 1.136604, Accuracy = 0.6484375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.14386296272, Accuracy = 0.63084679842\n",
            "Iter #1265664:  Learning rate = 0.003064:   Batch Loss = 1.153405, Accuracy = 0.64453125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.14885759354, Accuracy = 0.633802831173\n",
            "Iter #1269760:  Learning rate = 0.003064:   Batch Loss = 1.169760, Accuracy = 0.63671875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.15231394768, Accuracy = 0.638149857521\n",
            "Iter #1273856:  Learning rate = 0.003064:   Batch Loss = 1.189111, Accuracy = 0.6015625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.16556715965, Accuracy = 0.619370520115\n",
            "Iter #1277952:  Learning rate = 0.003064:   Batch Loss = 1.122026, Accuracy = 0.6328125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.12625479698, Accuracy = 0.647713422775\n",
            "Iter #1282048:  Learning rate = 0.003064:   Batch Loss = 1.132671, Accuracy = 0.65625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.13203763962, Accuracy = 0.650843322277\n",
            "Iter #1286144:  Learning rate = 0.003064:   Batch Loss = 1.154232, Accuracy = 0.619140625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.14440894127, Accuracy = 0.644931316376\n",
            "Iter #1290240:  Learning rate = 0.003064:   Batch Loss = 1.148332, Accuracy = 0.611328125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.14115452766, Accuracy = 0.639019310474\n",
            "Iter #1294336:  Learning rate = 0.003064:   Batch Loss = 1.115844, Accuracy = 0.66796875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.10985743999, Accuracy = 0.656407594681\n",
            "Iter #1298432:  Learning rate = 0.003064:   Batch Loss = 1.137566, Accuracy = 0.6171875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.11537218094, Accuracy = 0.661450207233\n",
            "Iter #1302528:  Learning rate = 0.002941:   Batch Loss = 1.140820, Accuracy = 0.662109375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.10471785069, Accuracy = 0.661450207233\n",
            "Iter #1306624:  Learning rate = 0.002941:   Batch Loss = 1.115936, Accuracy = 0.662109375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.12246549129, Accuracy = 0.670492112637\n",
            "Iter #1310720:  Learning rate = 0.002941:   Batch Loss = 1.191241, Accuracy = 0.607421875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.10825705528, Accuracy = 0.65849417448\n",
            "Iter #1314816:  Learning rate = 0.002941:   Batch Loss = 1.151172, Accuracy = 0.59765625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.12802422047, Accuracy = 0.645105183125\n",
            "Iter #1318912:  Learning rate = 0.002941:   Batch Loss = 1.160037, Accuracy = 0.61328125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.12924027443, Accuracy = 0.638149857521\n",
            "Iter #1323008:  Learning rate = 0.002941:   Batch Loss = 1.176540, Accuracy = 0.626953125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.10468184948, Accuracy = 0.655364274979\n",
            "Iter #1327104:  Learning rate = 0.002941:   Batch Loss = 1.097129, Accuracy = 0.66015625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.09614539146, Accuracy = 0.678316831589\n",
            "Iter #1331200:  Learning rate = 0.002941:   Batch Loss = 1.101575, Accuracy = 0.640625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.1030267477, Accuracy = 0.652756035328\n",
            "Iter #1335296:  Learning rate = 0.002941:   Batch Loss = 1.093452, Accuracy = 0.650390625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.13922929764, Accuracy = 0.624413132668\n",
            "Iter #1339392:  Learning rate = 0.002941:   Batch Loss = 1.185431, Accuracy = 0.62890625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.18828821182, Accuracy = 0.629803538322\n",
            "Iter #1343488:  Learning rate = 0.002941:   Batch Loss = 1.180277, Accuracy = 0.634765625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.12234640121, Accuracy = 0.648061215878\n",
            "Iter #1347584:  Learning rate = 0.002941:   Batch Loss = 1.209166, Accuracy = 0.599609375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.09932088852, Accuracy = 0.655016541481\n",
            "Iter #1351680:  Learning rate = 0.002941:   Batch Loss = 1.188997, Accuracy = 0.591796875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.11409533024, Accuracy = 0.671187639236\n",
            "Iter #1355776:  Learning rate = 0.002941:   Batch Loss = 1.050269, Accuracy = 0.658203125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.09242916107, Accuracy = 0.648235082626\n",
            "Iter #1359872:  Learning rate = 0.002941:   Batch Loss = 1.130102, Accuracy = 0.634765625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.09536087513, Accuracy = 0.651538848877\n",
            "Iter #1363968:  Learning rate = 0.002941:   Batch Loss = 1.045291, Accuracy = 0.69140625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.108253479, Accuracy = 0.658146381378\n",
            "Iter #1368064:  Learning rate = 0.002941:   Batch Loss = 1.055539, Accuracy = 0.67578125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.1073577404, Accuracy = 0.638497650623\n",
            "Iter #1372160:  Learning rate = 0.002941:   Batch Loss = 1.158520, Accuracy = 0.634765625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.13294529915, Accuracy = 0.639019310474\n",
            "Iter #1376256:  Learning rate = 0.002941:   Batch Loss = 1.457808, Accuracy = 0.515625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.36213850975, Accuracy = 0.576247632504\n",
            "Iter #1380352:  Learning rate = 0.002941:   Batch Loss = 1.286744, Accuracy = 0.603515625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.27201485634, Accuracy = 0.626499712467\n",
            "Iter #1384448:  Learning rate = 0.002941:   Batch Loss = 1.282909, Accuracy = 0.5859375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.24097526073, Accuracy = 0.60650318861\n",
            "Iter #1388544:  Learning rate = 0.002941:   Batch Loss = 1.200750, Accuracy = 0.623046875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.20512962341, Accuracy = 0.620587706566\n",
            "Iter #1392640:  Learning rate = 0.002941:   Batch Loss = 1.130848, Accuracy = 0.634765625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.19083237648, Accuracy = 0.620935499668\n",
            "Iter #1396736:  Learning rate = 0.002941:   Batch Loss = 1.120686, Accuracy = 0.625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.15079295635, Accuracy = 0.630672931671\n",
            "Iter #1400832:  Learning rate = 0.002823:   Batch Loss = 1.362542, Accuracy = 0.568359375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.22243249416, Accuracy = 0.594853043556\n",
            "Iter #1404928:  Learning rate = 0.002823:   Batch Loss = 1.197201, Accuracy = 0.638671875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.17898523808, Accuracy = 0.608242034912\n",
            "Iter #1409024:  Learning rate = 0.002823:   Batch Loss = 1.175263, Accuracy = 0.619140625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.15445804596, Accuracy = 0.616240680218\n",
            "Iter #1413120:  Learning rate = 0.002823:   Batch Loss = 1.133186, Accuracy = 0.640625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.14479982853, Accuracy = 0.639888703823\n",
            "Iter #1417216:  Learning rate = 0.002823:   Batch Loss = 1.147387, Accuracy = 0.626953125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.11514985561, Accuracy = 0.665797233582\n",
            "Iter #1421312:  Learning rate = 0.002823:   Batch Loss = 1.134791, Accuracy = 0.64453125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.10474026203, Accuracy = 0.674839138985\n",
            "Iter #1425408:  Learning rate = 0.002823:   Batch Loss = 1.285480, Accuracy = 0.591796875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.21792244911, Accuracy = 0.613806307316\n",
            "Iter #1429504:  Learning rate = 0.002823:   Batch Loss = 1.048224, Accuracy = 0.685546875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.14980864525, Accuracy = 0.637106597424\n",
            "Iter #1433600:  Learning rate = 0.002823:   Batch Loss = 1.145717, Accuracy = 0.630859375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.13761138916, Accuracy = 0.650321662426\n",
            "Iter #1437696:  Learning rate = 0.002823:   Batch Loss = 1.109718, Accuracy = 0.650390625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.08277201653, Accuracy = 0.665275633335\n",
            "Iter #1441792:  Learning rate = 0.002823:   Batch Loss = 1.126001, Accuracy = 0.646484375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.10473179817, Accuracy = 0.651364982128\n",
            "Iter #1445888:  Learning rate = 0.002823:   Batch Loss = 1.043580, Accuracy = 0.708984375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.15769934654, Accuracy = 0.636758804321\n",
            "Iter #1449984:  Learning rate = 0.002823:   Batch Loss = 1.094488, Accuracy = 0.64453125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.09760558605, Accuracy = 0.643887996674\n",
            "Iter #1454080:  Learning rate = 0.002823:   Batch Loss = 1.073590, Accuracy = 0.654296875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.09003007412, Accuracy = 0.654842615128\n",
            "Iter #1458176:  Learning rate = 0.002823:   Batch Loss = 1.109981, Accuracy = 0.677734375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.08918511868, Accuracy = 0.667362213135\n",
            "Iter #1462272:  Learning rate = 0.002823:   Batch Loss = 1.014982, Accuracy = 0.6875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.08501565456, Accuracy = 0.655016541481\n",
            "Iter #1466368:  Learning rate = 0.002823:   Batch Loss = 1.199447, Accuracy = 0.640625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.30089998245, Accuracy = 0.565119087696\n",
            "Iter #1470464:  Learning rate = 0.002823:   Batch Loss = 1.158844, Accuracy = 0.62890625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.15770530701, Accuracy = 0.636758804321\n",
            "Iter #1474560:  Learning rate = 0.002823:   Batch Loss = 1.141586, Accuracy = 0.623046875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.15796768665, Accuracy = 0.63293337822\n",
            "Iter #1478656:  Learning rate = 0.002823:   Batch Loss = 1.197966, Accuracy = 0.59375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.21046173573, Accuracy = 0.605286061764\n",
            "Iter #1482752:  Learning rate = 0.002823:   Batch Loss = 1.162258, Accuracy = 0.63671875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.10002374649, Accuracy = 0.646322369576\n",
            "Iter #1486848:  Learning rate = 0.002823:   Batch Loss = 1.142164, Accuracy = 0.638671875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.08524823189, Accuracy = 0.671187639236\n",
            "Iter #1490944:  Learning rate = 0.002823:   Batch Loss = 1.101875, Accuracy = 0.640625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.10738396645, Accuracy = 0.637454330921\n",
            "Iter #1495040:  Learning rate = 0.002823:   Batch Loss = 1.052931, Accuracy = 0.658203125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.09963667393, Accuracy = 0.66127628088\n",
            "Iter #1499136:  Learning rate = 0.002823:   Batch Loss = 1.041683, Accuracy = 0.6796875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.06378471851, Accuracy = 0.673448085785\n",
            "Iter #1503232:  Learning rate = 0.002710:   Batch Loss = 1.044100, Accuracy = 0.66015625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.09020853043, Accuracy = 0.656929254532\n",
            "Iter #1507328:  Learning rate = 0.002710:   Batch Loss = 1.067111, Accuracy = 0.6796875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.08175086975, Accuracy = 0.654668748379\n",
            "Iter #1511424:  Learning rate = 0.002710:   Batch Loss = 1.094321, Accuracy = 0.685546875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.04647672176, Accuracy = 0.685967683792\n",
            "Iter #1515520:  Learning rate = 0.002710:   Batch Loss = 1.032907, Accuracy = 0.681640625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.07979786396, Accuracy = 0.667188286781\n",
            "Iter #1519616:  Learning rate = 0.002710:   Batch Loss = 1.061294, Accuracy = 0.66796875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.07691550255, Accuracy = 0.663710653782\n",
            "Iter #1523712:  Learning rate = 0.002710:   Batch Loss = 1.050028, Accuracy = 0.693359375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.05647444725, Accuracy = 0.676404118538\n",
            "Iter #1527808:  Learning rate = 0.002710:   Batch Loss = 1.077232, Accuracy = 0.65234375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.07350623608, Accuracy = 0.670144319534\n",
            "Iter #1531904:  Learning rate = 0.002710:   Batch Loss = 1.093278, Accuracy = 0.67578125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.04380273819, Accuracy = 0.679707884789\n",
            "Iter #1536000:  Learning rate = 0.002710:   Batch Loss = 1.023135, Accuracy = 0.716796875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.07307398319, Accuracy = 0.664580047131\n",
            "Iter #1540096:  Learning rate = 0.002710:   Batch Loss = 1.090736, Accuracy = 0.634765625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.06094777584, Accuracy = 0.659363567829\n",
            "Iter #1544192:  Learning rate = 0.002710:   Batch Loss = 1.163745, Accuracy = 0.65625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.11985933781, Accuracy = 0.650495588779\n",
            "Iter #1548288:  Learning rate = 0.002710:   Batch Loss = 1.054868, Accuracy = 0.703125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.08201670647, Accuracy = 0.657798647881\n",
            "Iter #1552384:  Learning rate = 0.002710:   Batch Loss = 1.093194, Accuracy = 0.642578125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.08929038048, Accuracy = 0.656929254532\n",
            "Iter #1556480:  Learning rate = 0.002710:   Batch Loss = 1.036102, Accuracy = 0.669921875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.07703542709, Accuracy = 0.675360798836\n",
            "Iter #1560576:  Learning rate = 0.002710:   Batch Loss = 1.037158, Accuracy = 0.66796875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.04660725594, Accuracy = 0.671535372734\n",
            "Iter #1564672:  Learning rate = 0.002710:   Batch Loss = 1.041540, Accuracy = 0.66796875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.05041193962, Accuracy = 0.667536079884\n",
            "Iter #1568768:  Learning rate = 0.002710:   Batch Loss = 1.047405, Accuracy = 0.666015625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.05460464954, Accuracy = 0.662145733833\n",
            "Iter #1572864:  Learning rate = 0.002710:   Batch Loss = 1.111064, Accuracy = 0.62890625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.02906608582, Accuracy = 0.695878982544\n",
            "Iter #1576960:  Learning rate = 0.002710:   Batch Loss = 1.047204, Accuracy = 0.693359375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.0346698761, Accuracy = 0.658841967583\n",
            "Iter #1581056:  Learning rate = 0.002710:   Batch Loss = 0.992822, Accuracy = 0.712890625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.02633273602, Accuracy = 0.68283778429\n",
            "Iter #1585152:  Learning rate = 0.002710:   Batch Loss = 0.997052, Accuracy = 0.708984375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.03438401222, Accuracy = 0.68492436409\n",
            "Iter #1589248:  Learning rate = 0.002710:   Batch Loss = 1.013827, Accuracy = 0.7421875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.01896357536, Accuracy = 0.694140136242\n",
            "Iter #1593344:  Learning rate = 0.002710:   Batch Loss = 1.037622, Accuracy = 0.685546875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.04269278049, Accuracy = 0.68422883749\n",
            "Iter #1597440:  Learning rate = 0.002710:   Batch Loss = 1.059286, Accuracy = 0.666015625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.02668952942, Accuracy = 0.666666686535\n",
            "Iter #1601536:  Learning rate = 0.002602:   Batch Loss = 1.014536, Accuracy = 0.697265625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.02529168129, Accuracy = 0.682316124439\n",
            "Iter #1605632:  Learning rate = 0.002602:   Batch Loss = 1.143268, Accuracy = 0.623046875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.10882878304, Accuracy = 0.63293337822\n",
            "Iter #1609728:  Learning rate = 0.002602:   Batch Loss = 1.061872, Accuracy = 0.642578125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.02607607841, Accuracy = 0.665449500084\n",
            "Iter #1613824:  Learning rate = 0.002602:   Batch Loss = 1.013844, Accuracy = 0.6953125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.03213834763, Accuracy = 0.672752559185\n",
            "Iter #1617920:  Learning rate = 0.002602:   Batch Loss = 1.026244, Accuracy = 0.701171875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.04514873028, Accuracy = 0.657624781132\n",
            "Iter #1622016:  Learning rate = 0.002602:   Batch Loss = 1.014318, Accuracy = 0.7265625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.04063379765, Accuracy = 0.675360798836\n",
            "Iter #1626112:  Learning rate = 0.002602:   Batch Loss = 1.040385, Accuracy = 0.703125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.13836121559, Accuracy = 0.616588413715\n",
            "Iter #1630208:  Learning rate = 0.002602:   Batch Loss = 1.006317, Accuracy = 0.697265625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.04587209225, Accuracy = 0.660754680634\n",
            "Iter #1634304:  Learning rate = 0.002602:   Batch Loss = 1.109296, Accuracy = 0.662109375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.0319917202, Accuracy = 0.674317538738\n",
            "Iter #1638400:  Learning rate = 0.002602:   Batch Loss = 1.044670, Accuracy = 0.7109375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.01892995834, Accuracy = 0.694140136242\n",
            "Iter #1642496:  Learning rate = 0.002602:   Batch Loss = 1.034564, Accuracy = 0.701171875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.04093289375, Accuracy = 0.680925071239\n",
            "Iter #1646592:  Learning rate = 0.002602:   Batch Loss = 1.025023, Accuracy = 0.705078125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.00509560108, Accuracy = 0.699704408646\n",
            "Iter #1650688:  Learning rate = 0.002602:   Batch Loss = 0.931414, Accuracy = 0.751953125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.00041735172, Accuracy = 0.684402704239\n",
            "Iter #1654784:  Learning rate = 0.002602:   Batch Loss = 0.987474, Accuracy = 0.681640625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.01810288429, Accuracy = 0.684750497341\n",
            "Iter #1658880:  Learning rate = 0.002602:   Batch Loss = 1.060817, Accuracy = 0.669921875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.04904186726, Accuracy = 0.674143612385\n",
            "Iter #1662976:  Learning rate = 0.002602:   Batch Loss = 0.996034, Accuracy = 0.69140625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.09852790833, Accuracy = 0.653451561928\n",
            "Iter #1667072:  Learning rate = 0.002602:   Batch Loss = 1.118569, Accuracy = 0.669921875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.14167916775, Accuracy = 0.629629611969\n",
            "Iter #1671168:  Learning rate = 0.002602:   Batch Loss = 1.051682, Accuracy = 0.681640625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.09935927391, Accuracy = 0.63554161787\n",
            "Iter #1675264:  Learning rate = 0.002602:   Batch Loss = 1.010493, Accuracy = 0.701171875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.01081347466, Accuracy = 0.690140843391\n",
            "Iter #1679360:  Learning rate = 0.002602:   Batch Loss = 1.028112, Accuracy = 0.658203125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.03396618366, Accuracy = 0.68022954464\n",
            "Iter #1683456:  Learning rate = 0.002602:   Batch Loss = 0.974231, Accuracy = 0.685546875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.996492385864, Accuracy = 0.71396279335\n",
            "Iter #1687552:  Learning rate = 0.002602:   Batch Loss = 1.039681, Accuracy = 0.6875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.00292491913, Accuracy = 0.704920887947\n",
            "Iter #1691648:  Learning rate = 0.002602:   Batch Loss = 0.939844, Accuracy = 0.703125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.01358413696, Accuracy = 0.68022954464\n",
            "Iter #1695744:  Learning rate = 0.002602:   Batch Loss = 0.972995, Accuracy = 0.73046875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.957371354103, Accuracy = 0.708746314049\n",
            "Iter #1699840:  Learning rate = 0.002602:   Batch Loss = 0.971277, Accuracy = 0.673828125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.958163440228, Accuracy = 0.718309879303\n",
            "Iter #1703936:  Learning rate = 0.002498:   Batch Loss = 0.873925, Accuracy = 0.751953125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.909162223339, Accuracy = 0.735176503658\n",
            "Iter #1708032:  Learning rate = 0.002498:   Batch Loss = 1.006336, Accuracy = 0.6875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.963023066521, Accuracy = 0.722309172153\n",
            "Iter #1712128:  Learning rate = 0.002498:   Batch Loss = 1.004459, Accuracy = 0.69921875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.954805135727, Accuracy = 0.721787512302\n",
            "Iter #1716224:  Learning rate = 0.002498:   Batch Loss = 0.886978, Accuracy = 0.70703125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.888828277588, Accuracy = 0.740566849709\n",
            "Iter #1720320:  Learning rate = 0.002498:   Batch Loss = 0.885004, Accuracy = 0.75\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.88424706459, Accuracy = 0.749434888363\n",
            "Iter #1724416:  Learning rate = 0.002498:   Batch Loss = 0.854553, Accuracy = 0.767578125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.910830020905, Accuracy = 0.742653429508\n",
            "Iter #1728512:  Learning rate = 0.002498:   Batch Loss = 0.855873, Accuracy = 0.771484375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.880959391594, Accuracy = 0.750652074814\n",
            "Iter #1732608:  Learning rate = 0.002498:   Batch Loss = 1.221866, Accuracy = 0.626953125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.30666828156, Accuracy = 0.584767878056\n",
            "Iter #1736704:  Learning rate = 0.002498:   Batch Loss = 1.093148, Accuracy = 0.65234375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.10276722908, Accuracy = 0.665797233582\n",
            "Iter #1740800:  Learning rate = 0.002498:   Batch Loss = 1.015489, Accuracy = 0.681640625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.991369009018, Accuracy = 0.680055618286\n",
            "Iter #1744896:  Learning rate = 0.002498:   Batch Loss = 0.970902, Accuracy = 0.68359375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.960961341858, Accuracy = 0.712050080299\n",
            "Iter #1748992:  Learning rate = 0.002498:   Batch Loss = 0.956576, Accuracy = 0.701171875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.943626880646, Accuracy = 0.718831479549\n",
            "Iter #1753088:  Learning rate = 0.002498:   Batch Loss = 0.984894, Accuracy = 0.6796875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.945852518082, Accuracy = 0.71326726675\n",
            "Iter #1757184:  Learning rate = 0.002498:   Batch Loss = 0.877271, Accuracy = 0.736328125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.911809444427, Accuracy = 0.727873384953\n",
            "Iter #1761280:  Learning rate = 0.002498:   Batch Loss = 0.923861, Accuracy = 0.7109375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.886928737164, Accuracy = 0.747522175312\n",
            "Iter #1765376:  Learning rate = 0.002498:   Batch Loss = 0.915811, Accuracy = 0.7265625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.88217318058, Accuracy = 0.746652781963\n",
            "Iter #1769472:  Learning rate = 0.002498:   Batch Loss = 0.856742, Accuracy = 0.736328125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.892179489136, Accuracy = 0.733959317207\n",
            "Iter #1773568:  Learning rate = 0.002498:   Batch Loss = 0.885323, Accuracy = 0.732421875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.922116398811, Accuracy = 0.727525651455\n",
            "Iter #1777664:  Learning rate = 0.002498:   Batch Loss = 0.896557, Accuracy = 0.75390625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.881675302982, Accuracy = 0.759172320366\n",
            "Iter #1781760:  Learning rate = 0.002498:   Batch Loss = 0.849514, Accuracy = 0.7578125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.859886646271, Accuracy = 0.758650660515\n",
            "Iter #1785856:  Learning rate = 0.002498:   Batch Loss = 0.883469, Accuracy = 0.763671875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.882003605366, Accuracy = 0.746304988861\n",
            "Iter #1789952:  Learning rate = 0.002498:   Batch Loss = 0.827463, Accuracy = 0.765625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.874637842178, Accuracy = 0.752390861511\n",
            "Iter #1794048:  Learning rate = 0.002498:   Batch Loss = 0.790503, Accuracy = 0.77734375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.921678423882, Accuracy = 0.73969745636\n",
            "Iter #1798144:  Learning rate = 0.002498:   Batch Loss = 0.848449, Accuracy = 0.751953125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.879421830177, Accuracy = 0.745609462261\n",
            "Iter #1802240:  Learning rate = 0.002398:   Batch Loss = 0.969637, Accuracy = 0.69921875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.949770092964, Accuracy = 0.7099635005\n",
            "Iter #1806336:  Learning rate = 0.002398:   Batch Loss = 0.882774, Accuracy = 0.751953125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.908306181431, Accuracy = 0.743175089359\n",
            "Iter #1810432:  Learning rate = 0.002398:   Batch Loss = 0.820822, Accuracy = 0.767578125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.894690036774, Accuracy = 0.732046604156\n",
            "Iter #1814528:  Learning rate = 0.002398:   Batch Loss = 0.868354, Accuracy = 0.76953125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.859947264194, Accuracy = 0.760215640068\n",
            "Iter #1818624:  Learning rate = 0.002398:   Batch Loss = 1.090934, Accuracy = 0.6796875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.16796731949, Accuracy = 0.644931316376\n",
            "Iter #1822720:  Learning rate = 0.002398:   Batch Loss = 1.057494, Accuracy = 0.69140625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.03554391861, Accuracy = 0.696226716042\n",
            "Iter #1826816:  Learning rate = 0.002398:   Batch Loss = 0.998664, Accuracy = 0.70703125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.0236004591, Accuracy = 0.621283233166\n",
            "Iter #1830912:  Learning rate = 0.002398:   Batch Loss = 0.921280, Accuracy = 0.70703125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.01630651951, Accuracy = 0.697096168995\n",
            "Iter #1835008:  Learning rate = 0.002398:   Batch Loss = 0.939762, Accuracy = 0.701171875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.957179546356, Accuracy = 0.712919473648\n",
            "Iter #1839104:  Learning rate = 0.002398:   Batch Loss = 0.901710, Accuracy = 0.732421875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.918300509453, Accuracy = 0.740740716457\n",
            "Iter #1843200:  Learning rate = 0.002398:   Batch Loss = 0.896639, Accuracy = 0.75\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.894699275494, Accuracy = 0.741436243057\n",
            "Iter #1847296:  Learning rate = 0.002398:   Batch Loss = 0.879592, Accuracy = 0.755859375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.908332228661, Accuracy = 0.735872030258\n",
            "Iter #1851392:  Learning rate = 0.002398:   Batch Loss = 0.901851, Accuracy = 0.744140625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.886236667633, Accuracy = 0.750304281712\n",
            "Iter #1855488:  Learning rate = 0.002398:   Batch Loss = 0.881162, Accuracy = 0.744140625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.875095009804, Accuracy = 0.753086447716\n",
            "Iter #1859584:  Learning rate = 0.002398:   Batch Loss = 0.860391, Accuracy = 0.759765625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.925367236137, Accuracy = 0.749434888363\n",
            "Iter #1863680:  Learning rate = 0.002398:   Batch Loss = 0.878024, Accuracy = 0.751953125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.864500999451, Accuracy = 0.760563373566\n",
            "Iter #1867776:  Learning rate = 0.002398:   Batch Loss = 0.847270, Accuracy = 0.763671875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.912102341652, Accuracy = 0.731003284454\n",
            "Iter #1871872:  Learning rate = 0.002398:   Batch Loss = 0.823707, Accuracy = 0.78125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.870810866356, Accuracy = 0.762649953365\n",
            "Iter #1875968:  Learning rate = 0.002398:   Batch Loss = 0.878279, Accuracy = 0.734375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.911823868752, Accuracy = 0.731351077557\n",
            "Iter #1880064:  Learning rate = 0.002398:   Batch Loss = 0.844187, Accuracy = 0.755859375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.899627566338, Accuracy = 0.747522175312\n",
            "Iter #1884160:  Learning rate = 0.002398:   Batch Loss = 0.880546, Accuracy = 0.7421875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.860313296318, Accuracy = 0.754129707813\n",
            "Iter #1888256:  Learning rate = 0.002398:   Batch Loss = 0.896761, Accuracy = 0.76953125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.907753109932, Accuracy = 0.734654843807\n",
            "Iter #1892352:  Learning rate = 0.002398:   Batch Loss = 1.050535, Accuracy = 0.70703125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.968197643757, Accuracy = 0.719179272652\n",
            "Iter #1896448:  Learning rate = 0.002398:   Batch Loss = 0.939321, Accuracy = 0.69921875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.926015853882, Accuracy = 0.722135305405\n",
            "Iter #1900544:  Learning rate = 0.002302:   Batch Loss = 0.856707, Accuracy = 0.751953125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.887297391891, Accuracy = 0.750304281712\n",
            "Iter #1904640:  Learning rate = 0.002302:   Batch Loss = 0.863944, Accuracy = 0.765625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.926119446754, Accuracy = 0.729090571404\n",
            "Iter #1908736:  Learning rate = 0.002302:   Batch Loss = 0.881858, Accuracy = 0.728515625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.870878398418, Accuracy = 0.745261669159\n",
            "Iter #1912832:  Learning rate = 0.002302:   Batch Loss = 0.812253, Accuracy = 0.775390625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.87407118082, Accuracy = 0.754999101162\n",
            "Iter #1916928:  Learning rate = 0.002302:   Batch Loss = 0.848072, Accuracy = 0.7578125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.866229176521, Accuracy = 0.760737240314\n",
            "Iter #1921024:  Learning rate = 0.002302:   Batch Loss = 1.122247, Accuracy = 0.6796875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.921851694584, Accuracy = 0.735698163509\n",
            "Iter #1925120:  Learning rate = 0.002302:   Batch Loss = 0.928791, Accuracy = 0.71875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.947548031807, Accuracy = 0.71326726675\n",
            "Iter #1929216:  Learning rate = 0.002302:   Batch Loss = 0.867241, Accuracy = 0.744140625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.869416952133, Accuracy = 0.753608047962\n",
            "Iter #1933312:  Learning rate = 0.002302:   Batch Loss = 0.983039, Accuracy = 0.712890625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.878031492233, Accuracy = 0.752390861511\n",
            "Iter #1937408:  Learning rate = 0.002302:   Batch Loss = 0.846617, Accuracy = 0.736328125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.874210178852, Accuracy = 0.739349663258\n",
            "Iter #1941504:  Learning rate = 0.002302:   Batch Loss = 0.859648, Accuracy = 0.75390625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.8809440732, Accuracy = 0.740045189857\n",
            "Iter #1945600:  Learning rate = 0.002302:   Batch Loss = 0.910494, Accuracy = 0.69921875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.860424280167, Accuracy = 0.762823879719\n",
            "Iter #1949696:  Learning rate = 0.002302:   Batch Loss = 0.811079, Accuracy = 0.791015625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.832821428776, Accuracy = 0.766997039318\n",
            "Iter #1953792:  Learning rate = 0.002302:   Batch Loss = 0.879423, Accuracy = 0.73828125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.848900198936, Accuracy = 0.760041713715\n",
            "Iter #1957888:  Learning rate = 0.002302:   Batch Loss = 0.847133, Accuracy = 0.7421875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.840576887131, Accuracy = 0.764214932919\n",
            "Iter #1961984:  Learning rate = 0.002302:   Batch Loss = 0.820972, Accuracy = 0.77734375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.835435628891, Accuracy = 0.77012693882\n",
            "Iter #1966080:  Learning rate = 0.002302:   Batch Loss = 0.786194, Accuracy = 0.7890625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.89343225956, Accuracy = 0.749956548214\n",
            "Iter #1970176:  Learning rate = 0.002302:   Batch Loss = 0.860007, Accuracy = 0.75390625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.858397722244, Accuracy = 0.754477500916\n",
            "Iter #1974272:  Learning rate = 0.002302:   Batch Loss = 0.799603, Accuracy = 0.78125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.834458231926, Accuracy = 0.766301512718\n",
            "Iter #1978368:  Learning rate = 0.002302:   Batch Loss = 0.871218, Accuracy = 0.744140625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.845404148102, Accuracy = 0.76804035902\n",
            "Iter #1982464:  Learning rate = 0.002302:   Batch Loss = 0.855681, Accuracy = 0.748046875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.880409359932, Accuracy = 0.682663857937\n",
            "Iter #1986560:  Learning rate = 0.002302:   Batch Loss = 0.840953, Accuracy = 0.7734375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.835435628891, Accuracy = 0.766127645969\n",
            "Iter #1990656:  Learning rate = 0.002302:   Batch Loss = 0.851543, Accuracy = 0.73828125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.853436470032, Accuracy = 0.748565495014\n",
            "Iter #1994752:  Learning rate = 0.002302:   Batch Loss = 0.844197, Accuracy = 0.74609375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.858783841133, Accuracy = 0.751695334911\n",
            "Iter #1998848:  Learning rate = 0.002302:   Batch Loss = 0.866474, Accuracy = 0.740234375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.872362852097, Accuracy = 0.74717438221\n",
            "Iter #2002944:  Learning rate = 0.002210:   Batch Loss = 0.767626, Accuracy = 0.78515625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.865834474564, Accuracy = 0.757781267166\n",
            "Iter #2007040:  Learning rate = 0.002210:   Batch Loss = 0.829488, Accuracy = 0.759765625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.83668166399, Accuracy = 0.769257545471\n",
            "Iter #2011136:  Learning rate = 0.002210:   Batch Loss = 0.823665, Accuracy = 0.78125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.838374733925, Accuracy = 0.763867139816\n",
            "Iter #2015232:  Learning rate = 0.002210:   Batch Loss = 0.825656, Accuracy = 0.77734375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.8634339571, Accuracy = 0.755173027515\n",
            "Iter #2019328:  Learning rate = 0.002210:   Batch Loss = 0.865022, Accuracy = 0.748046875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.826979160309, Accuracy = 0.770474672318\n",
            "Iter #2023424:  Learning rate = 0.002210:   Batch Loss = 0.783384, Accuracy = 0.779296875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.885742485523, Accuracy = 0.74300122261\n",
            "Iter #2027520:  Learning rate = 0.002210:   Batch Loss = 0.825458, Accuracy = 0.767578125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.826180100441, Accuracy = 0.763171613216\n",
            "Iter #2031616:  Learning rate = 0.002210:   Batch Loss = 0.792938, Accuracy = 0.763671875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.832097709179, Accuracy = 0.764388799667\n",
            "Iter #2035712:  Learning rate = 0.002210:   Batch Loss = 0.769235, Accuracy = 0.806640625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.818438231945, Accuracy = 0.777256131172\n",
            "Iter #2039808:  Learning rate = 0.002210:   Batch Loss = 0.824449, Accuracy = 0.7421875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.895824670792, Accuracy = 0.740219116211\n",
            "Iter #2043904:  Learning rate = 0.002210:   Batch Loss = 1.975152, Accuracy = 0.583984375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.67665672302, Accuracy = 0.580420792103\n",
            "Iter #2048000:  Learning rate = 0.002210:   Batch Loss = 1.222460, Accuracy = 0.603515625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.24365282059, Accuracy = 0.595374703407\n",
            "Iter #2052096:  Learning rate = 0.002210:   Batch Loss = 1.212908, Accuracy = 0.634765625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.22093451023, Accuracy = 0.614849567413\n",
            "Iter #2056192:  Learning rate = 0.002210:   Batch Loss = 1.161728, Accuracy = 0.63671875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.18770539761, Accuracy = 0.616066753864\n",
            "Iter #2060288:  Learning rate = 0.002210:   Batch Loss = 1.089130, Accuracy = 0.67578125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.12023580074, Accuracy = 0.664753973484\n",
            "Iter #2064384:  Learning rate = 0.002210:   Batch Loss = 1.085210, Accuracy = 0.6875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.10116922855, Accuracy = 0.660059094429\n",
            "Iter #2068480:  Learning rate = 0.002210:   Batch Loss = 1.042146, Accuracy = 0.669921875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.09476387501, Accuracy = 0.680403411388\n",
            "Iter #2072576:  Learning rate = 0.002210:   Batch Loss = 1.081295, Accuracy = 0.673828125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.11963510513, Accuracy = 0.666145026684\n",
            "Iter #2076672:  Learning rate = 0.002210:   Batch Loss = 1.050086, Accuracy = 0.705078125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.13424658775, Accuracy = 0.662841260433\n",
            "Iter #2080768:  Learning rate = 0.002210:   Batch Loss = 1.047118, Accuracy = 0.701171875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.06007516384, Accuracy = 0.692922949791\n",
            "Iter #2084864:  Learning rate = 0.002210:   Batch Loss = 1.064798, Accuracy = 0.66796875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.07374310493, Accuracy = 0.676577985287\n",
            "Iter #2088960:  Learning rate = 0.002210:   Batch Loss = 1.063857, Accuracy = 0.666015625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.10722267628, Accuracy = 0.679012358189\n",
            "Iter #2093056:  Learning rate = 0.002210:   Batch Loss = 1.035818, Accuracy = 0.697265625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.05552363396, Accuracy = 0.683707177639\n",
            "Iter #2097152:  Learning rate = 0.002210:   Batch Loss = 0.965633, Accuracy = 0.708984375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.03360950947, Accuracy = 0.703182041645\n",
            "Iter #2101248:  Learning rate = 0.002122:   Batch Loss = 1.045891, Accuracy = 0.6875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.06940758228, Accuracy = 0.681968331337\n",
            "Iter #2105344:  Learning rate = 0.002122:   Batch Loss = 1.062789, Accuracy = 0.68359375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.03663229942, Accuracy = 0.702312648296\n",
            "Iter #2109440:  Learning rate = 0.002122:   Batch Loss = 1.057641, Accuracy = 0.697265625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.07213521004, Accuracy = 0.672752559185\n",
            "Iter #2113536:  Learning rate = 0.002122:   Batch Loss = 1.152554, Accuracy = 0.634765625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.03309094906, Accuracy = 0.696400642395\n",
            "Iter #2117632:  Learning rate = 0.002122:   Batch Loss = 1.000653, Accuracy = 0.68359375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.05740022659, Accuracy = 0.707007467747\n",
            "Iter #2121728:  Learning rate = 0.002122:   Batch Loss = 1.017896, Accuracy = 0.693359375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.05071997643, Accuracy = 0.689271450043\n",
            "Iter #2125824:  Learning rate = 0.002122:   Batch Loss = 1.033990, Accuracy = 0.666015625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.04557728767, Accuracy = 0.699530541897\n",
            "Iter #2129920:  Learning rate = 0.002122:   Batch Loss = 1.038697, Accuracy = 0.677734375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.02202856541, Accuracy = 0.693096876144\n",
            "Iter #2134016:  Learning rate = 0.002122:   Batch Loss = 0.959757, Accuracy = 0.720703125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.999723255634, Accuracy = 0.714832186699\n",
            "Iter #2138112:  Learning rate = 0.002122:   Batch Loss = 1.028545, Accuracy = 0.671875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.02300548553, Accuracy = 0.705442547798\n",
            "Iter #2142208:  Learning rate = 0.002122:   Batch Loss = 1.005723, Accuracy = 0.70703125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.05529904366, Accuracy = 0.68561989069\n",
            "Iter #2146304:  Learning rate = 0.002122:   Batch Loss = 1.063095, Accuracy = 0.662109375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.0831707716, Accuracy = 0.69031471014\n",
            "Iter #2150400:  Learning rate = 0.002122:   Batch Loss = 1.058906, Accuracy = 0.681640625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.03538191319, Accuracy = 0.693270742893\n",
            "Iter #2154496:  Learning rate = 0.002122:   Batch Loss = 0.937781, Accuracy = 0.75\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.0239585638, Accuracy = 0.695878982544\n",
            "Iter #2158592:  Learning rate = 0.002122:   Batch Loss = 1.027750, Accuracy = 0.677734375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.0225610733, Accuracy = 0.697965562344\n",
            "Iter #2162688:  Learning rate = 0.002122:   Batch Loss = 0.960179, Accuracy = 0.720703125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.05010974407, Accuracy = 0.682489991188\n",
            "Iter #2166784:  Learning rate = 0.002122:   Batch Loss = 0.956639, Accuracy = 0.72265625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.00650000572, Accuracy = 0.696574509144\n",
            "Iter #2170880:  Learning rate = 0.002122:   Batch Loss = 1.015728, Accuracy = 0.703125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.04562425613, Accuracy = 0.711006760597\n",
            "Iter #2174976:  Learning rate = 0.002122:   Batch Loss = 0.908186, Accuracy = 0.771484375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.01091074944, Accuracy = 0.712223947048\n",
            "Iter #2179072:  Learning rate = 0.002122:   Batch Loss = 0.987386, Accuracy = 0.712890625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.08654773235, Accuracy = 0.691531896591\n",
            "Iter #2183168:  Learning rate = 0.002122:   Batch Loss = 1.003545, Accuracy = 0.705078125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.05233216286, Accuracy = 0.695183455944\n",
            "Iter #2187264:  Learning rate = 0.002122:   Batch Loss = 0.907839, Accuracy = 0.767578125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.949537038803, Accuracy = 0.757259607315\n",
            "Iter #2191360:  Learning rate = 0.002122:   Batch Loss = 1.022662, Accuracy = 0.673828125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.01265072823, Accuracy = 0.719005405903\n",
            "Iter #2195456:  Learning rate = 0.002122:   Batch Loss = 0.960329, Accuracy = 0.748046875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.975649237633, Accuracy = 0.725091278553\n",
            "Iter #2199552:  Learning rate = 0.002122:   Batch Loss = 0.993094, Accuracy = 0.71875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.989760041237, Accuracy = 0.699704408646\n",
            "Iter #2203648:  Learning rate = 0.002037:   Batch Loss = 1.004526, Accuracy = 0.701171875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.998875916004, Accuracy = 0.700226068497\n",
            "Iter #2207744:  Learning rate = 0.002037:   Batch Loss = 0.981293, Accuracy = 0.7265625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.04288697243, Accuracy = 0.691358029842\n",
            "Iter #2211840:  Learning rate = 0.002037:   Batch Loss = 0.941832, Accuracy = 0.720703125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.9660115242, Accuracy = 0.727873384953\n",
            "Iter #2215936:  Learning rate = 0.002037:   Batch Loss = 0.999913, Accuracy = 0.72265625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.974699139595, Accuracy = 0.723700225353\n",
            "Iter #2220032:  Learning rate = 0.002037:   Batch Loss = 0.847748, Accuracy = 0.775390625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.01511585712, Accuracy = 0.700573801994\n",
            "Iter #2224128:  Learning rate = 0.002037:   Batch Loss = 1.015276, Accuracy = 0.701171875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.01298427582, Accuracy = 0.7078769207\n",
            "Iter #2228224:  Learning rate = 0.002037:   Batch Loss = 0.935088, Accuracy = 0.720703125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.993640422821, Accuracy = 0.718657612801\n",
            "Iter #2232320:  Learning rate = 0.002037:   Batch Loss = 0.974329, Accuracy = 0.70703125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.977423071861, Accuracy = 0.710311233997\n",
            "Iter #2236416:  Learning rate = 0.002037:   Batch Loss = 0.930552, Accuracy = 0.740234375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.995246171951, Accuracy = 0.701790988445\n",
            "Iter #2240512:  Learning rate = 0.002037:   Batch Loss = 0.941254, Accuracy = 0.720703125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.969135403633, Accuracy = 0.708920180798\n",
            "Iter #2244608:  Learning rate = 0.002037:   Batch Loss = 0.859226, Accuracy = 0.759765625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.961806178093, Accuracy = 0.720048666\n",
            "Iter #2248704:  Learning rate = 0.002037:   Batch Loss = 0.829926, Accuracy = 0.783203125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.933366179466, Accuracy = 0.735698163509\n",
            "Iter #2252800:  Learning rate = 0.002037:   Batch Loss = 0.943718, Accuracy = 0.75\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.962319552898, Accuracy = 0.717962086201\n",
            "Iter #2256896:  Learning rate = 0.002037:   Batch Loss = 0.869326, Accuracy = 0.775390625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.10764908791, Accuracy = 0.669274926186\n",
            "Iter #2260992:  Learning rate = 0.002037:   Batch Loss = 0.888751, Accuracy = 0.748046875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.985759735107, Accuracy = 0.716571033001\n",
            "Iter #2265088:  Learning rate = 0.002037:   Batch Loss = 0.912302, Accuracy = 0.73046875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.973443865776, Accuracy = 0.710311233997\n",
            "Iter #2269184:  Learning rate = 0.002037:   Batch Loss = 0.948041, Accuracy = 0.73828125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.954420208931, Accuracy = 0.727699518204\n",
            "Iter #2273280:  Learning rate = 0.002037:   Batch Loss = 0.829072, Accuracy = 0.7890625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.898861646652, Accuracy = 0.762302219868\n",
            "Iter #2277376:  Learning rate = 0.002037:   Batch Loss = 0.801453, Accuracy = 0.8046875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.840215444565, Accuracy = 0.777429997921\n",
            "Iter #2281472:  Learning rate = 0.002037:   Batch Loss = 0.855618, Accuracy = 0.724609375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.810990333557, Accuracy = 0.784559190273\n",
            "Iter #2285568:  Learning rate = 0.002037:   Batch Loss = 0.767091, Accuracy = 0.80859375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.778978228569, Accuracy = 0.796730995178\n",
            "Iter #2289664:  Learning rate = 0.002037:   Batch Loss = 0.708151, Accuracy = 0.822265625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.784399747849, Accuracy = 0.796383261681\n",
            "Iter #2293760:  Learning rate = 0.002037:   Batch Loss = 0.671511, Accuracy = 0.84375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.781341433525, Accuracy = 0.789080142975\n",
            "Iter #2297856:  Learning rate = 0.002037:   Batch Loss = 0.695687, Accuracy = 0.833984375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.758506953716, Accuracy = 0.794818282127\n",
            "Iter #2301952:  Learning rate = 0.001955:   Batch Loss = 0.654562, Accuracy = 0.849609375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.745465993881, Accuracy = 0.815684199333\n",
            "Iter #2306048:  Learning rate = 0.001955:   Batch Loss = 0.710554, Accuracy = 0.830078125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.754698097706, Accuracy = 0.805425167084\n",
            "Iter #2310144:  Learning rate = 0.001955:   Batch Loss = 0.774479, Accuracy = 0.791015625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.772117555141, Accuracy = 0.780559897423\n",
            "Iter #2314240:  Learning rate = 0.001955:   Batch Loss = 0.759262, Accuracy = 0.7890625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.738666057587, Accuracy = 0.809946119785\n",
            "Iter #2318336:  Learning rate = 0.001955:   Batch Loss = 0.777306, Accuracy = 0.806640625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.737136125565, Accuracy = 0.812032699585\n",
            "Iter #2322432:  Learning rate = 0.001955:   Batch Loss = 0.703370, Accuracy = 0.818359375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.735696315765, Accuracy = 0.811858832836\n",
            "Iter #2326528:  Learning rate = 0.001955:   Batch Loss = 0.649577, Accuracy = 0.83203125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.755134940147, Accuracy = 0.799513101578\n",
            "Iter #2330624:  Learning rate = 0.001955:   Batch Loss = 0.707249, Accuracy = 0.81640625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.722275674343, Accuracy = 0.821596264839\n",
            "Iter #2334720:  Learning rate = 0.001955:   Batch Loss = 0.743910, Accuracy = 0.80078125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.74944961071, Accuracy = 0.807685613632\n",
            "Iter #2338816:  Learning rate = 0.001955:   Batch Loss = 0.694953, Accuracy = 0.826171875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.742341339588, Accuracy = 0.808555006981\n",
            "Iter #2342912:  Learning rate = 0.001955:   Batch Loss = 0.671379, Accuracy = 0.818359375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.767072677612, Accuracy = 0.799339234829\n",
            "Iter #2347008:  Learning rate = 0.001955:   Batch Loss = 0.741223, Accuracy = 0.796875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.758380055428, Accuracy = 0.810119986534\n",
            "Iter #2351104:  Learning rate = 0.001955:   Batch Loss = 0.699316, Accuracy = 0.822265625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.765560984612, Accuracy = 0.782994270325\n",
            "Iter #2355200:  Learning rate = 0.001955:   Batch Loss = 0.686299, Accuracy = 0.806640625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.728898525238, Accuracy = 0.811858832836\n",
            "Iter #2359296:  Learning rate = 0.001955:   Batch Loss = 0.593794, Accuracy = 0.87109375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.742890000343, Accuracy = 0.792383909225\n",
            "Iter #2363392:  Learning rate = 0.001955:   Batch Loss = 0.700254, Accuracy = 0.81640625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.770897269249, Accuracy = 0.803686320782\n",
            "Iter #2367488:  Learning rate = 0.001955:   Batch Loss = 0.645536, Accuracy = 0.8515625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.740829586983, Accuracy = 0.799513101578\n",
            "Iter #2371584:  Learning rate = 0.001955:   Batch Loss = 0.637651, Accuracy = 0.859375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.71669793129, Accuracy = 0.820379078388\n",
            "Iter #2375680:  Learning rate = 0.001955:   Batch Loss = 0.670868, Accuracy = 0.833984375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.725634455681, Accuracy = 0.832898616791\n",
            "Iter #2379776:  Learning rate = 0.001955:   Batch Loss = 0.661595, Accuracy = 0.826171875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.713698029518, Accuracy = 0.814814805984\n",
            "Iter #2383872:  Learning rate = 0.001955:   Batch Loss = 0.644996, Accuracy = 0.853515625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.702287614346, Accuracy = 0.826986610889\n",
            "Iter #2387968:  Learning rate = 0.001955:   Batch Loss = 0.672281, Accuracy = 0.818359375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.700946807861, Accuracy = 0.83168143034\n",
            "Iter #2392064:  Learning rate = 0.001955:   Batch Loss = 0.666340, Accuracy = 0.82421875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.717483639717, Accuracy = 0.819161891937\n",
            "Iter #2396160:  Learning rate = 0.001955:   Batch Loss = 0.675014, Accuracy = 0.8203125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.693111300468, Accuracy = 0.832724750042\n",
            "Iter #2400256:  Learning rate = 0.001877:   Batch Loss = 0.667695, Accuracy = 0.833984375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.765370547771, Accuracy = 0.799687027931\n",
            "Iter #2404352:  Learning rate = 0.001877:   Batch Loss = 0.647437, Accuracy = 0.830078125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.780595302582, Accuracy = 0.754303574562\n",
            "Iter #2408448:  Learning rate = 0.001877:   Batch Loss = 0.676978, Accuracy = 0.8203125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.732982158661, Accuracy = 0.807163953781\n",
            "Iter #2412544:  Learning rate = 0.001877:   Batch Loss = 0.629013, Accuracy = 0.845703125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.715275645256, Accuracy = 0.83237695694\n",
            "Iter #2416640:  Learning rate = 0.001877:   Batch Loss = 0.615958, Accuracy = 0.849609375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.700442314148, Accuracy = 0.828551530838\n",
            "Iter #2420736:  Learning rate = 0.001877:   Batch Loss = 0.656745, Accuracy = 0.8359375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.707699656487, Accuracy = 0.824030578136\n",
            "Iter #2424832:  Learning rate = 0.001877:   Batch Loss = 0.595884, Accuracy = 0.86328125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.696026444435, Accuracy = 0.834115803242\n",
            "Iter #2428928:  Learning rate = 0.001877:   Batch Loss = 0.661341, Accuracy = 0.84375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.694058418274, Accuracy = 0.831333696842\n",
            "Iter #2433024:  Learning rate = 0.001877:   Batch Loss = 0.662808, Accuracy = 0.82421875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.712976336479, Accuracy = 0.82559555769\n",
            "Iter #2437120:  Learning rate = 0.001877:   Batch Loss = 0.727690, Accuracy = 0.802734375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.810752034187, Accuracy = 0.775865077972\n",
            "Iter #2441216:  Learning rate = 0.001877:   Batch Loss = 0.673082, Accuracy = 0.8203125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.746058702469, Accuracy = 0.810641646385\n",
            "Iter #2445312:  Learning rate = 0.001877:   Batch Loss = 0.617530, Accuracy = 0.85546875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.724291086197, Accuracy = 0.816379785538\n",
            "Iter #2449408:  Learning rate = 0.001877:   Batch Loss = 0.682782, Accuracy = 0.826171875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.695941567421, Accuracy = 0.816553652287\n",
            "Iter #2453504:  Learning rate = 0.001877:   Batch Loss = 0.655371, Accuracy = 0.865234375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.693423628807, Accuracy = 0.837419569492\n",
            "Iter #2457600:  Learning rate = 0.001877:   Batch Loss = 0.701238, Accuracy = 0.810546875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.778549909592, Accuracy = 0.802816927433\n",
            "Iter #2461696:  Learning rate = 0.001877:   Batch Loss = 0.900691, Accuracy = 0.728515625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.01654541492, Accuracy = 0.697617828846\n",
            "Iter #2465792:  Learning rate = 0.001877:   Batch Loss = 0.970031, Accuracy = 0.703125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.938221871853, Accuracy = 0.733089923859\n",
            "Iter #2469888:  Learning rate = 0.001877:   Batch Loss = 0.796334, Accuracy = 0.802734375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.803214728832, Accuracy = 0.779516577721\n",
            "Iter #2473984:  Learning rate = 0.001877:   Batch Loss = 0.685769, Accuracy = 0.8515625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.760854840279, Accuracy = 0.818814098835\n",
            "Iter #2478080:  Learning rate = 0.001877:   Batch Loss = 0.663063, Accuracy = 0.828125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.727924466133, Accuracy = 0.810293853283\n",
            "Iter #2482176:  Learning rate = 0.001877:   Batch Loss = 0.667645, Accuracy = 0.8515625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.693597435951, Accuracy = 0.846287608147\n",
            "Iter #2486272:  Learning rate = 0.001877:   Batch Loss = 0.674305, Accuracy = 0.810546875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.695883512497, Accuracy = 0.825247764587\n",
            "Iter #2490368:  Learning rate = 0.001877:   Batch Loss = 0.639722, Accuracy = 0.865234375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.674757480621, Accuracy = 0.846113741398\n",
            "Iter #2494464:  Learning rate = 0.001877:   Batch Loss = 0.665287, Accuracy = 0.849609375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.740302681923, Accuracy = 0.814814805984\n",
            "Iter #2498560:  Learning rate = 0.001877:   Batch Loss = 0.657090, Accuracy = 0.84375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.701286613941, Accuracy = 0.834811329842\n",
            "Iter #2502656:  Learning rate = 0.001802:   Batch Loss = 0.614590, Accuracy = 0.83984375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.675799369812, Accuracy = 0.842462182045\n",
            "Iter #2506752:  Learning rate = 0.001802:   Batch Loss = 0.593308, Accuracy = 0.87109375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.666172027588, Accuracy = 0.847330927849\n",
            "Iter #2510848:  Learning rate = 0.001802:   Batch Loss = 0.594302, Accuracy = 0.888671875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.669308185577, Accuracy = 0.848026454449\n",
            "Iter #2514944:  Learning rate = 0.001802:   Batch Loss = 0.652847, Accuracy = 0.85546875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.663550853729, Accuracy = 0.848026454449\n",
            "Iter #2519040:  Learning rate = 0.001802:   Batch Loss = 0.589652, Accuracy = 0.87890625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.65364664793, Accuracy = 0.854981720448\n",
            "Iter #2523136:  Learning rate = 0.001802:   Batch Loss = 0.621517, Accuracy = 0.837890625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.664047062397, Accuracy = 0.851677954197\n",
            "Iter #2527232:  Learning rate = 0.001802:   Batch Loss = 0.644069, Accuracy = 0.84375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.678942203522, Accuracy = 0.829420983791\n",
            "Iter #2531328:  Learning rate = 0.001802:   Batch Loss = 0.658171, Accuracy = 0.8359375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.706780314445, Accuracy = 0.83237695694\n",
            "Iter #2535424:  Learning rate = 0.001802:   Batch Loss = 0.623024, Accuracy = 0.84375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.665806353092, Accuracy = 0.850982427597\n",
            "Iter #2539520:  Learning rate = 0.001802:   Batch Loss = 0.558624, Accuracy = 0.892578125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.656805276871, Accuracy = 0.853069007397\n",
            "Iter #2543616:  Learning rate = 0.001802:   Batch Loss = 0.601926, Accuracy = 0.86328125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.673138856888, Accuracy = 0.844896554947\n",
            "Iter #2547712:  Learning rate = 0.001802:   Batch Loss = 0.608178, Accuracy = 0.861328125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.663264989853, Accuracy = 0.850460767746\n",
            "Iter #2551808:  Learning rate = 0.001802:   Batch Loss = 0.616877, Accuracy = 0.83984375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.679639935493, Accuracy = 0.834289669991\n",
            "Iter #2555904:  Learning rate = 0.001802:   Batch Loss = 0.598685, Accuracy = 0.84375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.675537228584, Accuracy = 0.832724750042\n",
            "Iter #2560000:  Learning rate = 0.001802:   Batch Loss = 0.603139, Accuracy = 0.8203125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.668195664883, Accuracy = 0.832550883293\n",
            "Iter #2564096:  Learning rate = 0.001802:   Batch Loss = 0.570141, Accuracy = 0.87109375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.640482783318, Accuracy = 0.85602504015\n",
            "Iter #2568192:  Learning rate = 0.001802:   Batch Loss = 0.637486, Accuracy = 0.83203125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.639629483223, Accuracy = 0.851156294346\n",
            "Iter #2572288:  Learning rate = 0.001802:   Batch Loss = 0.569432, Accuracy = 0.892578125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.646179437637, Accuracy = 0.852895140648\n",
            "Iter #2576384:  Learning rate = 0.001802:   Batch Loss = 0.562349, Accuracy = 0.8828125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.667148888111, Accuracy = 0.842809975147\n",
            "Iter #2580480:  Learning rate = 0.001802:   Batch Loss = 0.628885, Accuracy = 0.869140625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.673157811165, Accuracy = 0.837071835995\n",
            "Iter #2584576:  Learning rate = 0.001802:   Batch Loss = 0.621807, Accuracy = 0.857421875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.667378664017, Accuracy = 0.844896554947\n",
            "Iter #2588672:  Learning rate = 0.001802:   Batch Loss = 0.616136, Accuracy = 0.8515625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.631558537483, Accuracy = 0.861763179302\n",
            "Iter #2592768:  Learning rate = 0.001802:   Batch Loss = 0.605462, Accuracy = 0.85546875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.642774224281, Accuracy = 0.85672056675\n",
            "Iter #2596864:  Learning rate = 0.001802:   Batch Loss = 0.555235, Accuracy = 0.888671875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.651243686676, Accuracy = 0.85393846035\n",
            "Iter #2600960:  Learning rate = 0.001730:   Batch Loss = 0.602003, Accuracy = 0.869140625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.63879352808, Accuracy = 0.856198906898\n",
            "Iter #2605056:  Learning rate = 0.001730:   Batch Loss = 0.573947, Accuracy = 0.869140625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.651113271713, Accuracy = 0.850113034248\n",
            "Iter #2609152:  Learning rate = 0.001730:   Batch Loss = 0.610611, Accuracy = 0.865234375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.671864032745, Accuracy = 0.844027101994\n",
            "Iter #2613248:  Learning rate = 0.001730:   Batch Loss = 0.627828, Accuracy = 0.86328125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.63324534893, Accuracy = 0.862284839153\n",
            "Iter #2617344:  Learning rate = 0.001730:   Batch Loss = 0.628628, Accuracy = 0.857421875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.656356334686, Accuracy = 0.850113034248\n",
            "Iter #2621440:  Learning rate = 0.001730:   Batch Loss = 0.648485, Accuracy = 0.853515625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.679612636566, Accuracy = 0.834463596344\n",
            "Iter #2625536:  Learning rate = 0.001730:   Batch Loss = 0.568240, Accuracy = 0.861328125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.645601272583, Accuracy = 0.847504794598\n",
            "Iter #2629632:  Learning rate = 0.001730:   Batch Loss = 0.599838, Accuracy = 0.86328125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.726307272911, Accuracy = 0.801773607731\n",
            "Iter #2633728:  Learning rate = 0.001730:   Batch Loss = 0.581552, Accuracy = 0.845703125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.715536534786, Accuracy = 0.76943141222\n",
            "Iter #2637824:  Learning rate = 0.001730:   Batch Loss = 0.579417, Accuracy = 0.86328125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.663765192032, Accuracy = 0.849069714546\n",
            "Iter #2641920:  Learning rate = 0.001730:   Batch Loss = 0.560909, Accuracy = 0.890625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.64500951767, Accuracy = 0.854112327099\n",
            "Iter #2646016:  Learning rate = 0.001730:   Batch Loss = 0.627685, Accuracy = 0.85546875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.684207856655, Accuracy = 0.844548761845\n",
            "Iter #2650112:  Learning rate = 0.001730:   Batch Loss = 0.564994, Accuracy = 0.87890625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.647795915604, Accuracy = 0.856198906898\n",
            "Iter #2654208:  Learning rate = 0.001730:   Batch Loss = 0.501924, Accuracy = 0.90625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.632775962353, Accuracy = 0.85463398695\n",
            "Iter #2658304:  Learning rate = 0.001730:   Batch Loss = 0.559032, Accuracy = 0.869140625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.632269740105, Accuracy = 0.8593288064\n",
            "Iter #2662400:  Learning rate = 0.001730:   Batch Loss = 0.609093, Accuracy = 0.857421875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.645816326141, Accuracy = 0.851504087448\n",
            "Iter #2666496:  Learning rate = 0.001730:   Batch Loss = 0.536021, Accuracy = 0.900390625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.663799643517, Accuracy = 0.839506149292\n",
            "Iter #2670592:  Learning rate = 0.001730:   Batch Loss = 0.600490, Accuracy = 0.86328125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.662126481533, Accuracy = 0.849417507648\n",
            "Iter #2674688:  Learning rate = 0.001730:   Batch Loss = 0.829840, Accuracy = 0.779296875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.773964047432, Accuracy = 0.793253362179\n",
            "Iter #2678784:  Learning rate = 0.001730:   Batch Loss = 0.666510, Accuracy = 0.818359375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.713577926159, Accuracy = 0.816727519035\n",
            "Iter #2682880:  Learning rate = 0.001730:   Batch Loss = 0.653645, Accuracy = 0.837890625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.71383035183, Accuracy = 0.827508270741\n",
            "Iter #2686976:  Learning rate = 0.001730:   Batch Loss = 0.582141, Accuracy = 0.861328125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.673894524574, Accuracy = 0.842288315296\n",
            "Iter #2691072:  Learning rate = 0.001730:   Batch Loss = 0.586079, Accuracy = 0.875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.646742224693, Accuracy = 0.85393846035\n",
            "Iter #2695168:  Learning rate = 0.001730:   Batch Loss = 0.625564, Accuracy = 0.83984375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.645910024643, Accuracy = 0.85602504015\n",
            "Iter #2699264:  Learning rate = 0.001730:   Batch Loss = 0.560654, Accuracy = 0.857421875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.639248013496, Accuracy = 0.852895140648\n",
            "Iter #2703360:  Learning rate = 0.001661:   Batch Loss = 0.584239, Accuracy = 0.865234375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.653718829155, Accuracy = 0.851677954197\n",
            "Iter #2707456:  Learning rate = 0.001661:   Batch Loss = 0.565746, Accuracy = 0.884765625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.633169829845, Accuracy = 0.860024333\n",
            "Iter #2711552:  Learning rate = 0.001661:   Batch Loss = 0.549787, Accuracy = 0.890625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.653762936592, Accuracy = 0.847157001495\n",
            "Iter #2715648:  Learning rate = 0.001661:   Batch Loss = 0.563516, Accuracy = 0.876953125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.612593650818, Accuracy = 0.866631865501\n",
            "Iter #2719744:  Learning rate = 0.001661:   Batch Loss = 0.557006, Accuracy = 0.875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.629091978073, Accuracy = 0.857416093349\n",
            "Iter #2723840:  Learning rate = 0.001661:   Batch Loss = 0.603110, Accuracy = 0.873046875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.667183876038, Accuracy = 0.839158415794\n",
            "Iter #2727936:  Learning rate = 0.001661:   Batch Loss = 0.578586, Accuracy = 0.890625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.646437525749, Accuracy = 0.853764533997\n",
            "Iter #2732032:  Learning rate = 0.001661:   Batch Loss = 0.579604, Accuracy = 0.8671875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.62250739336, Accuracy = 0.858285486698\n",
            "Iter #2736128:  Learning rate = 0.001661:   Batch Loss = 0.597887, Accuracy = 0.87109375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.652056932449, Accuracy = 0.849069714546\n",
            "Iter #2740224:  Learning rate = 0.001661:   Batch Loss = 0.614447, Accuracy = 0.849609375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.654364824295, Accuracy = 0.85672056675\n",
            "Iter #2744320:  Learning rate = 0.001661:   Batch Loss = 0.553675, Accuracy = 0.869140625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.641785979271, Accuracy = 0.854286193848\n",
            "Iter #2748416:  Learning rate = 0.001661:   Batch Loss = 0.598185, Accuracy = 0.86328125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.639395177364, Accuracy = 0.857242226601\n",
            "Iter #2752512:  Learning rate = 0.001661:   Batch Loss = 0.579432, Accuracy = 0.876953125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.646933674812, Accuracy = 0.855503380299\n",
            "Iter #2756608:  Learning rate = 0.001661:   Batch Loss = 0.543941, Accuracy = 0.892578125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.619993448257, Accuracy = 0.865414738655\n",
            "Iter #2760704:  Learning rate = 0.001661:   Batch Loss = 0.551329, Accuracy = 0.86328125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.631516695023, Accuracy = 0.857242226601\n",
            "Iter #2764800:  Learning rate = 0.001661:   Batch Loss = 0.567689, Accuracy = 0.87890625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.625780820847, Accuracy = 0.858285486698\n",
            "Iter #2768896:  Learning rate = 0.001661:   Batch Loss = 0.561672, Accuracy = 0.8828125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.632340908051, Accuracy = 0.854981720448\n",
            "Iter #2772992:  Learning rate = 0.001661:   Batch Loss = 0.542096, Accuracy = 0.890625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.670627832413, Accuracy = 0.839680075645\n",
            "Iter #2777088:  Learning rate = 0.001661:   Batch Loss = 0.527398, Accuracy = 0.892578125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.636718153954, Accuracy = 0.858285486698\n",
            "Iter #2781184:  Learning rate = 0.001661:   Batch Loss = 0.600901, Accuracy = 0.853515625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.650415420532, Accuracy = 0.850982427597\n",
            "Iter #2785280:  Learning rate = 0.001661:   Batch Loss = 0.606270, Accuracy = 0.865234375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.607708096504, Accuracy = 0.868196845055\n",
            "Iter #2789376:  Learning rate = 0.001661:   Batch Loss = 0.542742, Accuracy = 0.873046875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.660343885422, Accuracy = 0.846461474895\n",
            "Iter #2793472:  Learning rate = 0.001661:   Batch Loss = 0.598660, Accuracy = 0.865234375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.687673687935, Accuracy = 0.837767362595\n",
            "Iter #2797568:  Learning rate = 0.001661:   Batch Loss = 0.552558, Accuracy = 0.87890625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.643312931061, Accuracy = 0.856198906898\n",
            "Iter #2801664:  Learning rate = 0.001594:   Batch Loss = 0.543764, Accuracy = 0.89453125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.623273968697, Accuracy = 0.863675892353\n",
            "Iter #2805760:  Learning rate = 0.001594:   Batch Loss = 0.515580, Accuracy = 0.88671875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.617334961891, Accuracy = 0.869066238403\n",
            "Iter #2809856:  Learning rate = 0.001594:   Batch Loss = 0.530664, Accuracy = 0.89453125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.605447053909, Accuracy = 0.851156294346\n",
            "Iter #2813952:  Learning rate = 0.001594:   Batch Loss = 0.521356, Accuracy = 0.921875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.577111124992, Accuracy = 0.879325330257\n",
            "Iter #2818048:  Learning rate = 0.001594:   Batch Loss = 0.530689, Accuracy = 0.8984375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.604421198368, Accuracy = 0.874108850956\n",
            "Iter #2822144:  Learning rate = 0.001594:   Batch Loss = 0.527021, Accuracy = 0.912109375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.548232078552, Accuracy = 0.893583714962\n",
            "Iter #2826240:  Learning rate = 0.001594:   Batch Loss = 0.538704, Accuracy = 0.890625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.552491366863, Accuracy = 0.89184486866\n",
            "Iter #2830336:  Learning rate = 0.001594:   Batch Loss = 0.520098, Accuracy = 0.9140625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.522886276245, Accuracy = 0.90871155262\n",
            "Iter #2834432:  Learning rate = 0.001594:   Batch Loss = 0.499297, Accuracy = 0.919921875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.525478482246, Accuracy = 0.904886126518\n",
            "Iter #2838528:  Learning rate = 0.001594:   Batch Loss = 0.495158, Accuracy = 0.927734375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.541859090328, Accuracy = 0.898104667664\n",
            "Iter #2842624:  Learning rate = 0.001594:   Batch Loss = 0.461137, Accuracy = 0.9296875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.520865142345, Accuracy = 0.91410189867\n",
            "Iter #2846720:  Learning rate = 0.001594:   Batch Loss = 0.451999, Accuracy = 0.935546875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.524603247643, Accuracy = 0.906972706318\n",
            "Iter #2850816:  Learning rate = 0.001594:   Batch Loss = 0.482876, Accuracy = 0.91796875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.523374319077, Accuracy = 0.906103312969\n",
            "Iter #2854912:  Learning rate = 0.001594:   Batch Loss = 0.548566, Accuracy = 0.888671875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.522597432137, Accuracy = 0.905407726765\n",
            "Iter #2859008:  Learning rate = 0.001594:   Batch Loss = 0.547319, Accuracy = 0.873046875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.563416957855, Accuracy = 0.877238750458\n",
            "Iter #2863104:  Learning rate = 0.001594:   Batch Loss = 0.511123, Accuracy = 0.90625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.519687354565, Accuracy = 0.904190599918\n",
            "Iter #2867200:  Learning rate = 0.001594:   Batch Loss = 0.498382, Accuracy = 0.91796875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.51738846302, Accuracy = 0.915666818619\n",
            "Iter #2871296:  Learning rate = 0.001594:   Batch Loss = 0.419942, Accuracy = 0.9453125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.489907801151, Accuracy = 0.92018777132\n",
            "Iter #2875392:  Learning rate = 0.001594:   Batch Loss = 0.462802, Accuracy = 0.923828125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.496298313141, Accuracy = 0.91949224472\n",
            "Iter #2879488:  Learning rate = 0.001594:   Batch Loss = 0.466085, Accuracy = 0.927734375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.492339581251, Accuracy = 0.91949224472\n",
            "Iter #2883584:  Learning rate = 0.001594:   Batch Loss = 0.434672, Accuracy = 0.94140625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.491711556911, Accuracy = 0.921057224274\n",
            "Iter #2887680:  Learning rate = 0.001594:   Batch Loss = 0.438935, Accuracy = 0.9375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.50693076849, Accuracy = 0.913058578968\n",
            "Iter #2891776:  Learning rate = 0.001594:   Batch Loss = 0.428271, Accuracy = 0.943359375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.485820859671, Accuracy = 0.914971292019\n",
            "Iter #2895872:  Learning rate = 0.001594:   Batch Loss = 0.437868, Accuracy = 0.939453125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.498215705156, Accuracy = 0.919666171074\n",
            "Iter #2899968:  Learning rate = 0.001594:   Batch Loss = 0.445161, Accuracy = 0.93359375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.480441391468, Accuracy = 0.92088329792\n",
            "Iter #2904064:  Learning rate = 0.001531:   Batch Loss = 0.466140, Accuracy = 0.92578125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.493303835392, Accuracy = 0.913058578968\n",
            "Iter #2908160:  Learning rate = 0.001531:   Batch Loss = 0.496790, Accuracy = 0.9140625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.505390286446, Accuracy = 0.907842099667\n",
            "Iter #2912256:  Learning rate = 0.001531:   Batch Loss = 0.447751, Accuracy = 0.935546875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.527834415436, Accuracy = 0.901060700417\n",
            "Iter #2916352:  Learning rate = 0.001531:   Batch Loss = 0.538185, Accuracy = 0.892578125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.51503610611, Accuracy = 0.904538333416\n",
            "Iter #2920448:  Learning rate = 0.001531:   Batch Loss = 0.443231, Accuracy = 0.9375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.536767661572, Accuracy = 0.898452460766\n",
            "Iter #2924544:  Learning rate = 0.001531:   Batch Loss = 0.451308, Accuracy = 0.923828125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.492958694696, Accuracy = 0.917927324772\n",
            "Iter #2928640:  Learning rate = 0.001531:   Batch Loss = 0.525797, Accuracy = 0.916015625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.59484577179, Accuracy = 0.876369297504\n",
            "Iter #2932736:  Learning rate = 0.001531:   Batch Loss = 0.475086, Accuracy = 0.9296875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.494489371777, Accuracy = 0.912015318871\n",
            "Iter #2936832:  Learning rate = 0.001531:   Batch Loss = 0.450293, Accuracy = 0.92578125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.478761643171, Accuracy = 0.924360990524\n",
            "Iter #2940928:  Learning rate = 0.001531:   Batch Loss = 0.393008, Accuracy = 0.951171875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.464786946774, Accuracy = 0.928012490273\n",
            "Iter #2945024:  Learning rate = 0.001531:   Batch Loss = 0.443280, Accuracy = 0.935546875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.479274690151, Accuracy = 0.92018777132\n",
            "Iter #2949120:  Learning rate = 0.001531:   Batch Loss = 0.430443, Accuracy = 0.93359375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.484460055828, Accuracy = 0.91688400507\n",
            "Iter #2953216:  Learning rate = 0.001531:   Batch Loss = 0.448634, Accuracy = 0.927734375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.508300185204, Accuracy = 0.91479742527\n",
            "Iter #2957312:  Learning rate = 0.001531:   Batch Loss = 0.416163, Accuracy = 0.9453125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.479872226715, Accuracy = 0.917057931423\n",
            "Iter #2961408:  Learning rate = 0.001531:   Batch Loss = 0.462225, Accuracy = 0.923828125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.465620040894, Accuracy = 0.926099836826\n",
            "Iter #2965504:  Learning rate = 0.001531:   Batch Loss = 0.399835, Accuracy = 0.951171875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.481447428465, Accuracy = 0.926447570324\n",
            "Iter #2969600:  Learning rate = 0.001531:   Batch Loss = 0.447383, Accuracy = 0.919921875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.497737705708, Accuracy = 0.91271084547\n",
            "Iter #2973696:  Learning rate = 0.001531:   Batch Loss = 0.442286, Accuracy = 0.9296875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.450303822756, Accuracy = 0.933576762676\n",
            "Iter #2977792:  Learning rate = 0.001531:   Batch Loss = 0.381722, Accuracy = 0.955078125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.453469723463, Accuracy = 0.932185709476\n",
            "Iter #2981888:  Learning rate = 0.001531:   Batch Loss = 0.401131, Accuracy = 0.9453125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.469709038734, Accuracy = 0.925404250622\n",
            "Iter #2985984:  Learning rate = 0.001531:   Batch Loss = 0.427826, Accuracy = 0.93359375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.477331936359, Accuracy = 0.926969230175\n",
            "Iter #2990080:  Learning rate = 0.001531:   Batch Loss = 0.387967, Accuracy = 0.953125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.477900594473, Accuracy = 0.920361697674\n",
            "Iter #2994176:  Learning rate = 0.001531:   Batch Loss = 0.417865, Accuracy = 0.947265625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.479009151459, Accuracy = 0.924534857273\n",
            "Iter #2998272:  Learning rate = 0.001531:   Batch Loss = 0.462559, Accuracy = 0.9296875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.480801284313, Accuracy = 0.922100484371\n",
            "Iter #3002368:  Learning rate = 0.001469:   Batch Loss = 0.395378, Accuracy = 0.94921875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.456041514874, Accuracy = 0.929403603077\n",
            "Iter #3006464:  Learning rate = 0.001469:   Batch Loss = 0.422054, Accuracy = 0.9453125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.452485650778, Accuracy = 0.933055102825\n",
            "Iter #3010560:  Learning rate = 0.001469:   Batch Loss = 0.446084, Accuracy = 0.931640625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.452225983143, Accuracy = 0.932011842728\n",
            "Iter #3014656:  Learning rate = 0.001469:   Batch Loss = 0.418080, Accuracy = 0.94140625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.501951396465, Accuracy = 0.913928031921\n",
            "Iter #3018752:  Learning rate = 0.001469:   Batch Loss = 0.426765, Accuracy = 0.94140625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.472152501345, Accuracy = 0.92088329792\n",
            "Iter #3022848:  Learning rate = 0.001469:   Batch Loss = 0.445827, Accuracy = 0.92578125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.488038420677, Accuracy = 0.915319085121\n",
            "Iter #3026944:  Learning rate = 0.001469:   Batch Loss = 0.454232, Accuracy = 0.9375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.490368753672, Accuracy = 0.911319792271\n",
            "Iter #3031040:  Learning rate = 0.001469:   Batch Loss = 0.501435, Accuracy = 0.916015625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.471489548683, Accuracy = 0.924013197422\n",
            "Iter #3035136:  Learning rate = 0.001469:   Batch Loss = 0.424220, Accuracy = 0.94140625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.459938704967, Accuracy = 0.928012490273\n",
            "Iter #3039232:  Learning rate = 0.001469:   Batch Loss = 0.399142, Accuracy = 0.951171875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.481468081474, Accuracy = 0.91271084547\n",
            "Iter #3043328:  Learning rate = 0.001469:   Batch Loss = 0.430897, Accuracy = 0.9296875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.462010741234, Accuracy = 0.927490890026\n",
            "Iter #3047424:  Learning rate = 0.001469:   Batch Loss = 0.385847, Accuracy = 0.951171875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.466900110245, Accuracy = 0.923839330673\n",
            "Iter #3051520:  Learning rate = 0.001469:   Batch Loss = 0.442629, Accuracy = 0.935546875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.45864802599, Accuracy = 0.928708076477\n",
            "Iter #3055616:  Learning rate = 0.001469:   Batch Loss = 0.419587, Accuracy = 0.9453125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.45370143652, Accuracy = 0.925752043724\n",
            "Iter #3059712:  Learning rate = 0.001469:   Batch Loss = 0.407042, Accuracy = 0.943359375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.47342479229, Accuracy = 0.92088329792\n",
            "Iter #3063808:  Learning rate = 0.001469:   Batch Loss = 0.428422, Accuracy = 0.9375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.504719257355, Accuracy = 0.909928679466\n",
            "Iter #3067904:  Learning rate = 0.001469:   Batch Loss = 0.401385, Accuracy = 0.943359375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.473266541958, Accuracy = 0.919318377972\n",
            "Iter #3072000:  Learning rate = 0.001469:   Batch Loss = 0.397021, Accuracy = 0.94921875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.460690438747, Accuracy = 0.924882650375\n",
            "Iter #3076096:  Learning rate = 0.001469:   Batch Loss = 0.414300, Accuracy = 0.947265625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.467585772276, Accuracy = 0.926273703575\n",
            "Iter #3080192:  Learning rate = 0.001469:   Batch Loss = 0.473924, Accuracy = 0.927734375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.487583458424, Accuracy = 0.917231798172\n",
            "Iter #3084288:  Learning rate = 0.001469:   Batch Loss = 0.426855, Accuracy = 0.94140625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.474496483803, Accuracy = 0.921057224274\n",
            "Iter #3088384:  Learning rate = 0.001469:   Batch Loss = 0.443495, Accuracy = 0.935546875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.471058547497, Accuracy = 0.923491537571\n",
            "Iter #3092480:  Learning rate = 0.001469:   Batch Loss = 0.505685, Accuracy = 0.912109375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.477053821087, Accuracy = 0.917057931423\n",
            "Iter #3096576:  Learning rate = 0.001469:   Batch Loss = 0.438194, Accuracy = 0.943359375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.481676101685, Accuracy = 0.919840037823\n",
            "Iter #3100672:  Learning rate = 0.001411:   Batch Loss = 0.419802, Accuracy = 0.953125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.449720233679, Accuracy = 0.930446863174\n",
            "Iter #3104768:  Learning rate = 0.001411:   Batch Loss = 0.414931, Accuracy = 0.939453125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.449759244919, Accuracy = 0.932707369328\n",
            "Iter #3108864:  Learning rate = 0.001411:   Batch Loss = 0.425053, Accuracy = 0.94921875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.467906653881, Accuracy = 0.921752750874\n",
            "Iter #3112960:  Learning rate = 0.001411:   Batch Loss = 0.381979, Accuracy = 0.9609375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.457041144371, Accuracy = 0.926621437073\n",
            "Iter #3117056:  Learning rate = 0.001411:   Batch Loss = 0.403389, Accuracy = 0.951171875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.475132972002, Accuracy = 0.920361697674\n",
            "Iter #3121152:  Learning rate = 0.001411:   Batch Loss = 0.411603, Accuracy = 0.943359375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.44624876976, Accuracy = 0.928881943226\n",
            "Iter #3125248:  Learning rate = 0.001411:   Batch Loss = 0.451689, Accuracy = 0.931640625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.442053467035, Accuracy = 0.933576762676\n",
            "Iter #3129344:  Learning rate = 0.001411:   Batch Loss = 0.454765, Accuracy = 0.923828125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.464440643787, Accuracy = 0.922100484371\n",
            "Iter #3133440:  Learning rate = 0.001411:   Batch Loss = 0.418551, Accuracy = 0.947265625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.456139862537, Accuracy = 0.926969230175\n",
            "Iter #3137536:  Learning rate = 0.001411:   Batch Loss = 0.406204, Accuracy = 0.94140625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.439744591713, Accuracy = 0.931664049625\n",
            "Iter #3141632:  Learning rate = 0.001411:   Batch Loss = 0.405656, Accuracy = 0.9453125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.444075763226, Accuracy = 0.931490182877\n",
            "Iter #3145728:  Learning rate = 0.001411:   Batch Loss = 0.423068, Accuracy = 0.94140625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.464248895645, Accuracy = 0.922274410725\n",
            "Iter #3149824:  Learning rate = 0.001411:   Batch Loss = 0.456435, Accuracy = 0.916015625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.60060608387, Accuracy = 0.860372126102\n",
            "Iter #3153920:  Learning rate = 0.001411:   Batch Loss = 0.500635, Accuracy = 0.919921875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.546363472939, Accuracy = 0.890106081963\n",
            "Iter #3158016:  Learning rate = 0.001411:   Batch Loss = 0.379949, Accuracy = 0.953125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.464346706867, Accuracy = 0.924187123775\n",
            "Iter #3162112:  Learning rate = 0.001411:   Batch Loss = 0.419648, Accuracy = 0.94140625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.489302575588, Accuracy = 0.91618847847\n",
            "Iter #3166208:  Learning rate = 0.001411:   Batch Loss = 0.428528, Accuracy = 0.93359375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.453806459904, Accuracy = 0.929751336575\n",
            "Iter #3170304:  Learning rate = 0.001411:   Batch Loss = 0.409859, Accuracy = 0.9375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.461560428143, Accuracy = 0.925056517124\n",
            "Iter #3174400:  Learning rate = 0.001411:   Batch Loss = 0.419827, Accuracy = 0.93359375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.463680624962, Accuracy = 0.923665463924\n",
            "Iter #3178496:  Learning rate = 0.001411:   Batch Loss = 0.395302, Accuracy = 0.951171875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.44044482708, Accuracy = 0.932707369328\n",
            "Iter #3182592:  Learning rate = 0.001411:   Batch Loss = 0.393216, Accuracy = 0.947265625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.436493754387, Accuracy = 0.936185002327\n",
            "Iter #3186688:  Learning rate = 0.001411:   Batch Loss = 0.413830, Accuracy = 0.9453125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.445887029171, Accuracy = 0.929055809975\n",
            "Iter #3190784:  Learning rate = 0.001411:   Batch Loss = 0.407649, Accuracy = 0.943359375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.453307330608, Accuracy = 0.930099129677\n",
            "Iter #3194880:  Learning rate = 0.001411:   Batch Loss = 0.398603, Accuracy = 0.939453125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.441624581814, Accuracy = 0.933924555779\n",
            "Iter #3198976:  Learning rate = 0.001411:   Batch Loss = 0.363976, Accuracy = 0.96875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.420748651028, Accuracy = 0.941749274731\n",
            "Iter #3203072:  Learning rate = 0.001354:   Batch Loss = 0.410338, Accuracy = 0.94140625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.428527802229, Accuracy = 0.938967108727\n",
            "Iter #3207168:  Learning rate = 0.001354:   Batch Loss = 0.412029, Accuracy = 0.939453125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.430706590414, Accuracy = 0.93774998188\n",
            "Iter #3211264:  Learning rate = 0.001354:   Batch Loss = 0.373394, Accuracy = 0.962890625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.430189013481, Accuracy = 0.937923848629\n",
            "Iter #3215360:  Learning rate = 0.001354:   Batch Loss = 0.434563, Accuracy = 0.94140625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.436512053013, Accuracy = 0.932533442974\n",
            "Iter #3219456:  Learning rate = 0.001354:   Batch Loss = 0.408195, Accuracy = 0.947265625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.437303215265, Accuracy = 0.935141742229\n",
            "Iter #3223552:  Learning rate = 0.001354:   Batch Loss = 0.405995, Accuracy = 0.947265625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.424515604973, Accuracy = 0.938967108727\n",
            "Iter #3227648:  Learning rate = 0.001354:   Batch Loss = 0.417532, Accuracy = 0.93359375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.453698277473, Accuracy = 0.926969230175\n",
            "Iter #3231744:  Learning rate = 0.001354:   Batch Loss = 0.394801, Accuracy = 0.955078125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.435416221619, Accuracy = 0.933750629425\n",
            "Iter #3235840:  Learning rate = 0.001354:   Batch Loss = 0.421619, Accuracy = 0.947265625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.430947780609, Accuracy = 0.936880528927\n",
            "Iter #3239936:  Learning rate = 0.001354:   Batch Loss = 0.407299, Accuracy = 0.9375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.43238312006, Accuracy = 0.933924555779\n",
            "Iter #3244032:  Learning rate = 0.001354:   Batch Loss = 0.399893, Accuracy = 0.9453125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.437159121037, Accuracy = 0.937054395676\n",
            "Iter #3248128:  Learning rate = 0.001354:   Batch Loss = 0.416512, Accuracy = 0.93359375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.451831459999, Accuracy = 0.928360283375\n",
            "Iter #3252224:  Learning rate = 0.001354:   Batch Loss = 0.382352, Accuracy = 0.95703125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.434508740902, Accuracy = 0.932359576225\n",
            "Iter #3256320:  Learning rate = 0.001354:   Batch Loss = 0.382313, Accuracy = 0.947265625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.457473248243, Accuracy = 0.924360990524\n",
            "Iter #3260416:  Learning rate = 0.001354:   Batch Loss = 0.448613, Accuracy = 0.931640625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.466011047363, Accuracy = 0.926273703575\n",
            "Iter #3264512:  Learning rate = 0.001354:   Batch Loss = 0.423371, Accuracy = 0.94140625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.450087308884, Accuracy = 0.930446863174\n",
            "Iter #3268608:  Learning rate = 0.001354:   Batch Loss = 0.362664, Accuracy = 0.958984375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.464724481106, Accuracy = 0.92018777132\n",
            "Iter #3272704:  Learning rate = 0.001354:   Batch Loss = 0.446505, Accuracy = 0.9296875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.461074888706, Accuracy = 0.928534150124\n",
            "Iter #3276800:  Learning rate = 0.001354:   Batch Loss = 0.341078, Accuracy = 0.96875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.436564862728, Accuracy = 0.936011135578\n",
            "Iter #3280896:  Learning rate = 0.001354:   Batch Loss = 0.363117, Accuracy = 0.955078125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.433396756649, Accuracy = 0.933402895927\n",
            "Iter #3284992:  Learning rate = 0.001354:   Batch Loss = 0.387791, Accuracy = 0.943359375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.441013932228, Accuracy = 0.931664049625\n",
            "Iter #3289088:  Learning rate = 0.001354:   Batch Loss = 0.416405, Accuracy = 0.9453125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.482497483492, Accuracy = 0.920361697674\n",
            "Iter #3293184:  Learning rate = 0.001354:   Batch Loss = 0.366242, Accuracy = 0.9609375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.438609600067, Accuracy = 0.932185709476\n",
            "Iter #3297280:  Learning rate = 0.001354:   Batch Loss = 0.360726, Accuracy = 0.96484375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.43282982707, Accuracy = 0.934446156025\n",
            "Iter #3301376:  Learning rate = 0.001300:   Batch Loss = 0.395737, Accuracy = 0.955078125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.448914557695, Accuracy = 0.929229676723\n",
            "Iter #3305472:  Learning rate = 0.001300:   Batch Loss = 0.483856, Accuracy = 0.91796875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.525220155716, Accuracy = 0.900712907314\n",
            "Iter #3309568:  Learning rate = 0.001300:   Batch Loss = 0.435485, Accuracy = 0.931640625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.515094697475, Accuracy = 0.902973413467\n",
            "Iter #3313664:  Learning rate = 0.001300:   Batch Loss = 0.422066, Accuracy = 0.9453125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.469868063927, Accuracy = 0.918622851372\n",
            "Iter #3317760:  Learning rate = 0.001300:   Batch Loss = 0.375918, Accuracy = 0.953125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.453789442778, Accuracy = 0.927316963673\n",
            "Iter #3321856:  Learning rate = 0.001300:   Batch Loss = 0.403019, Accuracy = 0.953125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.441703438759, Accuracy = 0.928708076477\n",
            "Iter #3325952:  Learning rate = 0.001300:   Batch Loss = 0.455277, Accuracy = 0.9296875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.439694732428, Accuracy = 0.932707369328\n",
            "Iter #3330048:  Learning rate = 0.001300:   Batch Loss = 0.424399, Accuracy = 0.943359375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.476408421993, Accuracy = 0.918622851372\n",
            "Iter #3334144:  Learning rate = 0.001300:   Batch Loss = 0.366086, Accuracy = 0.9609375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.43888014555, Accuracy = 0.936011135578\n",
            "Iter #3338240:  Learning rate = 0.001300:   Batch Loss = 0.370603, Accuracy = 0.966796875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.44031471014, Accuracy = 0.930968523026\n",
            "Iter #3342336:  Learning rate = 0.001300:   Batch Loss = 0.392900, Accuracy = 0.94921875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.444064795971, Accuracy = 0.929229676723\n",
            "Iter #3346432:  Learning rate = 0.001300:   Batch Loss = 0.420065, Accuracy = 0.935546875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.429352283478, Accuracy = 0.936185002327\n",
            "Iter #3350528:  Learning rate = 0.001300:   Batch Loss = 0.436515, Accuracy = 0.93359375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.425801515579, Accuracy = 0.934446156025\n",
            "Iter #3354624:  Learning rate = 0.001300:   Batch Loss = 0.364473, Accuracy = 0.96484375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.440919876099, Accuracy = 0.931664049625\n",
            "Iter #3358720:  Learning rate = 0.001300:   Batch Loss = 0.373195, Accuracy = 0.9609375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.429550796747, Accuracy = 0.931490182877\n",
            "Iter #3362816:  Learning rate = 0.001300:   Batch Loss = 0.374604, Accuracy = 0.958984375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.418165624142, Accuracy = 0.937228322029\n",
            "Iter #3366912:  Learning rate = 0.001300:   Batch Loss = 0.374334, Accuracy = 0.955078125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.432916998863, Accuracy = 0.935315608978\n",
            "Iter #3371008:  Learning rate = 0.001300:   Batch Loss = 0.419103, Accuracy = 0.95703125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.497844368219, Accuracy = 0.908885419369\n",
            "Iter #3375104:  Learning rate = 0.001300:   Batch Loss = 0.393141, Accuracy = 0.9453125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.44661539793, Accuracy = 0.927143096924\n",
            "Iter #3379200:  Learning rate = 0.001300:   Batch Loss = 0.406020, Accuracy = 0.955078125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.437306553125, Accuracy = 0.932881236076\n",
            "Iter #3383296:  Learning rate = 0.001300:   Batch Loss = 0.397957, Accuracy = 0.9453125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.416954487562, Accuracy = 0.940705955029\n",
            "Iter #3387392:  Learning rate = 0.001300:   Batch Loss = 0.353485, Accuracy = 0.966796875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.431248426437, Accuracy = 0.934098422527\n",
            "Iter #3391488:  Learning rate = 0.001300:   Batch Loss = 0.392938, Accuracy = 0.953125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.431878805161, Accuracy = 0.932011842728\n",
            "Iter #3395584:  Learning rate = 0.001300:   Batch Loss = 0.374450, Accuracy = 0.958984375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.430807054043, Accuracy = 0.931490182877\n",
            "Iter #3399680:  Learning rate = 0.001300:   Batch Loss = 0.408147, Accuracy = 0.94140625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.433777391911, Accuracy = 0.932359576225\n",
            "Iter #3403776:  Learning rate = 0.001248:   Batch Loss = 0.361595, Accuracy = 0.9609375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.429803311825, Accuracy = 0.932011842728\n",
            "Iter #3407872:  Learning rate = 0.001248:   Batch Loss = 0.354046, Accuracy = 0.958984375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.432394146919, Accuracy = 0.929403603077\n",
            "Iter #3411968:  Learning rate = 0.001248:   Batch Loss = 0.368248, Accuracy = 0.958984375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.430535137653, Accuracy = 0.932359576225\n",
            "Iter #3416064:  Learning rate = 0.001248:   Batch Loss = 0.403026, Accuracy = 0.947265625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.434180259705, Accuracy = 0.932881236076\n",
            "Iter #3420160:  Learning rate = 0.001248:   Batch Loss = 0.367124, Accuracy = 0.958984375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.424863517284, Accuracy = 0.938793241978\n",
            "Iter #3424256:  Learning rate = 0.001248:   Batch Loss = 0.326206, Accuracy = 0.978515625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.41741257906, Accuracy = 0.938271582127\n",
            "Iter #3428352:  Learning rate = 0.001248:   Batch Loss = 0.395769, Accuracy = 0.951171875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.439000159502, Accuracy = 0.926795363426\n",
            "Iter #3432448:  Learning rate = 0.001248:   Batch Loss = 0.382605, Accuracy = 0.958984375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.451095283031, Accuracy = 0.922969937325\n",
            "Iter #3436544:  Learning rate = 0.001248:   Batch Loss = 0.382988, Accuracy = 0.951171875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.450059175491, Accuracy = 0.927490890026\n",
            "Iter #3440640:  Learning rate = 0.001248:   Batch Loss = 0.377655, Accuracy = 0.955078125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.454732716084, Accuracy = 0.919840037823\n",
            "Iter #3444736:  Learning rate = 0.001248:   Batch Loss = 0.394130, Accuracy = 0.947265625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.436987936497, Accuracy = 0.932707369328\n",
            "Iter #3448832:  Learning rate = 0.001248:   Batch Loss = 0.366682, Accuracy = 0.958984375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.427376866341, Accuracy = 0.934272289276\n",
            "Iter #3452928:  Learning rate = 0.001248:   Batch Loss = 0.389923, Accuracy = 0.953125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.445063829422, Accuracy = 0.927664756775\n",
            "Iter #3457024:  Learning rate = 0.001248:   Batch Loss = 0.390453, Accuracy = 0.943359375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.461058974266, Accuracy = 0.925404250622\n",
            "Iter #3461120:  Learning rate = 0.001248:   Batch Loss = 0.387483, Accuracy = 0.9453125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.436545193195, Accuracy = 0.931142389774\n",
            "Iter #3465216:  Learning rate = 0.001248:   Batch Loss = 0.350885, Accuracy = 0.96484375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.42151248455, Accuracy = 0.937923848629\n",
            "Iter #3469312:  Learning rate = 0.001248:   Batch Loss = 0.362145, Accuracy = 0.955078125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.450480550528, Accuracy = 0.925056517124\n",
            "Iter #3473408:  Learning rate = 0.001248:   Batch Loss = 0.363283, Accuracy = 0.96484375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.439971625805, Accuracy = 0.930968523026\n",
            "Iter #3477504:  Learning rate = 0.001248:   Batch Loss = 0.420992, Accuracy = 0.9375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.43109703064, Accuracy = 0.933924555779\n",
            "Iter #3481600:  Learning rate = 0.001248:   Batch Loss = 0.388701, Accuracy = 0.947265625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.439947754145, Accuracy = 0.928881943226\n",
            "Iter #3485696:  Learning rate = 0.001248:   Batch Loss = 0.416006, Accuracy = 0.93359375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.442474275827, Accuracy = 0.929403603077\n",
            "Iter #3489792:  Learning rate = 0.001248:   Batch Loss = 0.370727, Accuracy = 0.95703125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.430775970221, Accuracy = 0.934620082378\n",
            "Iter #3493888:  Learning rate = 0.001248:   Batch Loss = 0.436823, Accuracy = 0.93359375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.439417749643, Accuracy = 0.932881236076\n",
            "Iter #3497984:  Learning rate = 0.001248:   Batch Loss = 0.365502, Accuracy = 0.962890625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.443920314312, Accuracy = 0.924360990524\n",
            "Iter #3502080:  Learning rate = 0.001198:   Batch Loss = 0.918519, Accuracy = 0.787109375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.20975220203, Accuracy = 0.701269328594\n",
            "Iter #3506176:  Learning rate = 0.001198:   Batch Loss = 0.719320, Accuracy = 0.798828125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.678335785866, Accuracy = 0.83237695694\n",
            "Iter #3510272:  Learning rate = 0.001198:   Batch Loss = 0.497544, Accuracy = 0.912109375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.540898025036, Accuracy = 0.898974120617\n",
            "Iter #3514368:  Learning rate = 0.001198:   Batch Loss = 0.500123, Accuracy = 0.919921875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.51100975275, Accuracy = 0.904886126518\n",
            "Iter #3518464:  Learning rate = 0.001198:   Batch Loss = 0.441610, Accuracy = 0.943359375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.454393684864, Accuracy = 0.929577469826\n",
            "Iter #3522560:  Learning rate = 0.001198:   Batch Loss = 0.425248, Accuracy = 0.94921875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.440606832504, Accuracy = 0.930099129677\n",
            "Iter #3526656:  Learning rate = 0.001198:   Batch Loss = 0.387452, Accuracy = 0.94921875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.439032822847, Accuracy = 0.932185709476\n",
            "Iter #3530752:  Learning rate = 0.001198:   Batch Loss = 0.410532, Accuracy = 0.953125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.430640041828, Accuracy = 0.935837268829\n",
            "Iter #3534848:  Learning rate = 0.001198:   Batch Loss = 0.392348, Accuracy = 0.94921875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.428856641054, Accuracy = 0.935489475727\n",
            "Iter #3538944:  Learning rate = 0.001198:   Batch Loss = 0.439088, Accuracy = 0.92578125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.427618205547, Accuracy = 0.935663342476\n",
            "Iter #3543040:  Learning rate = 0.001198:   Batch Loss = 0.376612, Accuracy = 0.96484375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.443792968988, Accuracy = 0.928360283375\n",
            "Iter #3547136:  Learning rate = 0.001198:   Batch Loss = 0.390131, Accuracy = 0.943359375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.474264085293, Accuracy = 0.920535564423\n",
            "Iter #3551232:  Learning rate = 0.001198:   Batch Loss = 0.392318, Accuracy = 0.939453125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.456376552582, Accuracy = 0.926621437073\n",
            "Iter #3555328:  Learning rate = 0.001198:   Batch Loss = 0.362147, Accuracy = 0.962890625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.433899283409, Accuracy = 0.932185709476\n",
            "Iter #3559424:  Learning rate = 0.001198:   Batch Loss = 0.397782, Accuracy = 0.943359375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.433354109526, Accuracy = 0.932011842728\n",
            "Iter #3563520:  Learning rate = 0.001198:   Batch Loss = 0.396609, Accuracy = 0.943359375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.460734844208, Accuracy = 0.924187123775\n",
            "Iter #3567616:  Learning rate = 0.001198:   Batch Loss = 0.418330, Accuracy = 0.94140625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.459863305092, Accuracy = 0.924360990524\n",
            "Iter #3571712:  Learning rate = 0.001198:   Batch Loss = 0.368339, Accuracy = 0.955078125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.425473570824, Accuracy = 0.935315608978\n",
            "Iter #3575808:  Learning rate = 0.001198:   Batch Loss = 0.394878, Accuracy = 0.947265625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.421125411987, Accuracy = 0.938097715378\n",
            "Iter #3579904:  Learning rate = 0.001198:   Batch Loss = 0.352428, Accuracy = 0.96484375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.420951664448, Accuracy = 0.93844550848\n",
            "Iter #3584000:  Learning rate = 0.001198:   Batch Loss = 0.374746, Accuracy = 0.95703125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.441548526287, Accuracy = 0.930620789528\n",
            "Iter #3588096:  Learning rate = 0.001198:   Batch Loss = 0.376683, Accuracy = 0.953125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.421373963356, Accuracy = 0.940358221531\n",
            "Iter #3592192:  Learning rate = 0.001198:   Batch Loss = 0.368664, Accuracy = 0.95703125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.434403210878, Accuracy = 0.929055809975\n",
            "Iter #3596288:  Learning rate = 0.001198:   Batch Loss = 0.378693, Accuracy = 0.955078125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.423183321953, Accuracy = 0.934793949127\n",
            "Iter #3600384:  Learning rate = 0.001150:   Batch Loss = 0.349365, Accuracy = 0.96875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.410437703133, Accuracy = 0.938967108727\n",
            "Iter #3604480:  Learning rate = 0.001150:   Batch Loss = 0.369669, Accuracy = 0.951171875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.412890791893, Accuracy = 0.938271582127\n",
            "Iter #3608576:  Learning rate = 0.001150:   Batch Loss = 0.394376, Accuracy = 0.943359375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.449681550264, Accuracy = 0.919318377972\n",
            "Iter #3612672:  Learning rate = 0.001150:   Batch Loss = 0.373175, Accuracy = 0.95703125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.436114430428, Accuracy = 0.932881236076\n",
            "Iter #3616768:  Learning rate = 0.001150:   Batch Loss = 0.379463, Accuracy = 0.9609375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.429672837257, Accuracy = 0.931490182877\n",
            "Iter #3620864:  Learning rate = 0.001150:   Batch Loss = 0.331120, Accuracy = 0.97265625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.432585835457, Accuracy = 0.930620789528\n",
            "Iter #3624960:  Learning rate = 0.001150:   Batch Loss = 0.412565, Accuracy = 0.94140625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.42201179266, Accuracy = 0.934967815876\n",
            "Iter #3629056:  Learning rate = 0.001150:   Batch Loss = 0.340800, Accuracy = 0.96875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.450729608536, Accuracy = 0.925925910473\n",
            "Iter #3633152:  Learning rate = 0.001150:   Batch Loss = 0.378971, Accuracy = 0.94921875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.430289149284, Accuracy = 0.932185709476\n",
            "Iter #3637248:  Learning rate = 0.001150:   Batch Loss = 0.347402, Accuracy = 0.96875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.417465209961, Accuracy = 0.940010428429\n",
            "Iter #3641344:  Learning rate = 0.001150:   Batch Loss = 0.346327, Accuracy = 0.966796875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.414814054966, Accuracy = 0.938619375229\n",
            "Iter #3645440:  Learning rate = 0.001150:   Batch Loss = 0.389987, Accuracy = 0.9453125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.417383909225, Accuracy = 0.938967108727\n",
            "Iter #3649536:  Learning rate = 0.001150:   Batch Loss = 0.354306, Accuracy = 0.96484375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.411843419075, Accuracy = 0.941749274731\n",
            "Iter #3653632:  Learning rate = 0.001150:   Batch Loss = 0.368184, Accuracy = 0.953125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.438140362501, Accuracy = 0.933055102825\n",
            "Iter #3657728:  Learning rate = 0.001150:   Batch Loss = 0.352070, Accuracy = 0.966796875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.415484547615, Accuracy = 0.934446156025\n",
            "Iter #3661824:  Learning rate = 0.001150:   Batch Loss = 0.403537, Accuracy = 0.947265625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.432714641094, Accuracy = 0.931490182877\n",
            "Iter #3665920:  Learning rate = 0.001150:   Batch Loss = 0.369568, Accuracy = 0.955078125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.429641067982, Accuracy = 0.933055102825\n",
            "Iter #3670016:  Learning rate = 0.001150:   Batch Loss = 0.411316, Accuracy = 0.953125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.419007599354, Accuracy = 0.937054395676\n",
            "Iter #3674112:  Learning rate = 0.001150:   Batch Loss = 0.357433, Accuracy = 0.96484375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.438590317965, Accuracy = 0.929403603077\n",
            "Iter #3678208:  Learning rate = 0.001150:   Batch Loss = 0.389605, Accuracy = 0.951171875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.413554608822, Accuracy = 0.938619375229\n",
            "Iter #3682304:  Learning rate = 0.001150:   Batch Loss = 0.332289, Accuracy = 0.97265625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.415167331696, Accuracy = 0.942444801331\n",
            "Iter #3686400:  Learning rate = 0.001150:   Batch Loss = 0.361128, Accuracy = 0.962890625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.434922784567, Accuracy = 0.931142389774\n",
            "Iter #3690496:  Learning rate = 0.001150:   Batch Loss = 0.369282, Accuracy = 0.9609375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.414464741945, Accuracy = 0.941749274731\n",
            "Iter #3694592:  Learning rate = 0.001150:   Batch Loss = 0.380935, Accuracy = 0.951171875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.412780940533, Accuracy = 0.940010428429\n",
            "Iter #3698688:  Learning rate = 0.001150:   Batch Loss = 0.370013, Accuracy = 0.958984375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.412808001041, Accuracy = 0.937402188778\n",
            "Iter #3702784:  Learning rate = 0.001104:   Batch Loss = 0.368002, Accuracy = 0.95703125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.406203389168, Accuracy = 0.94053208828\n",
            "Iter #3706880:  Learning rate = 0.001104:   Batch Loss = 0.400370, Accuracy = 0.947265625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.429415643215, Accuracy = 0.930968523026\n",
            "Iter #3710976:  Learning rate = 0.001104:   Batch Loss = 0.353620, Accuracy = 0.966796875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.405782848597, Accuracy = 0.941575407982\n",
            "Iter #3715072:  Learning rate = 0.001104:   Batch Loss = 0.340277, Accuracy = 0.97265625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.414297163486, Accuracy = 0.935663342476\n",
            "Iter #3719168:  Learning rate = 0.001104:   Batch Loss = 0.332178, Accuracy = 0.96875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.40830630064, Accuracy = 0.93983656168\n",
            "Iter #3723264:  Learning rate = 0.001104:   Batch Loss = 0.361377, Accuracy = 0.958984375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.410882413387, Accuracy = 0.936185002327\n",
            "Iter #3727360:  Learning rate = 0.001104:   Batch Loss = 0.357913, Accuracy = 0.958984375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.420774281025, Accuracy = 0.934272289276\n",
            "Iter #3731456:  Learning rate = 0.001104:   Batch Loss = 0.388464, Accuracy = 0.94921875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.442103922367, Accuracy = 0.926795363426\n",
            "Iter #3735552:  Learning rate = 0.001104:   Batch Loss = 0.405166, Accuracy = 0.94140625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.427045583725, Accuracy = 0.928360283375\n",
            "Iter #3739648:  Learning rate = 0.001104:   Batch Loss = 0.373446, Accuracy = 0.9609375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.451164275408, Accuracy = 0.929925203323\n",
            "Iter #3743744:  Learning rate = 0.001104:   Batch Loss = 0.378660, Accuracy = 0.955078125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.430838048458, Accuracy = 0.935489475727\n",
            "Iter #3747840:  Learning rate = 0.001104:   Batch Loss = 0.350211, Accuracy = 0.966796875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.423497021198, Accuracy = 0.937923848629\n",
            "Iter #3751936:  Learning rate = 0.001104:   Batch Loss = 0.393861, Accuracy = 0.943359375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.417660534382, Accuracy = 0.935837268829\n",
            "Iter #3756032:  Learning rate = 0.001104:   Batch Loss = 0.349519, Accuracy = 0.966796875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.410774439573, Accuracy = 0.936185002327\n",
            "Iter #3760128:  Learning rate = 0.001104:   Batch Loss = 0.354906, Accuracy = 0.95703125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.406332612038, Accuracy = 0.936880528927\n",
            "Iter #3764224:  Learning rate = 0.001104:   Batch Loss = 0.328344, Accuracy = 0.9609375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.427192628384, Accuracy = 0.933924555779\n",
            "Iter #3768320:  Learning rate = 0.001104:   Batch Loss = 0.365361, Accuracy = 0.951171875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.420580625534, Accuracy = 0.932707369328\n",
            "Iter #3772416:  Learning rate = 0.001104:   Batch Loss = 0.333752, Accuracy = 0.9765625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.416829496622, Accuracy = 0.932707369328\n",
            "Iter #3776512:  Learning rate = 0.001104:   Batch Loss = 0.363607, Accuracy = 0.958984375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.437615513802, Accuracy = 0.929403603077\n",
            "Iter #3780608:  Learning rate = 0.001104:   Batch Loss = 0.411970, Accuracy = 0.935546875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.416392475367, Accuracy = 0.93914103508\n",
            "Iter #3784704:  Learning rate = 0.001104:   Batch Loss = 0.381274, Accuracy = 0.951171875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.407900989056, Accuracy = 0.93914103508\n",
            "Iter #3788800:  Learning rate = 0.001104:   Batch Loss = 0.340313, Accuracy = 0.962890625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.440895944834, Accuracy = 0.926621437073\n",
            "Iter #3792896:  Learning rate = 0.001104:   Batch Loss = 0.395138, Accuracy = 0.951171875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.417591631413, Accuracy = 0.935489475727\n",
            "Iter #3796992:  Learning rate = 0.001104:   Batch Loss = 0.352862, Accuracy = 0.95703125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.400614261627, Accuracy = 0.942444801331\n",
            "Iter #3801088:  Learning rate = 0.001060:   Batch Loss = 0.359678, Accuracy = 0.962890625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.402848660946, Accuracy = 0.941749274731\n",
            "Iter #3805184:  Learning rate = 0.001060:   Batch Loss = 0.381180, Accuracy = 0.94921875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.418386042118, Accuracy = 0.933576762676\n",
            "Iter #3809280:  Learning rate = 0.001060:   Batch Loss = 0.335796, Accuracy = 0.9609375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.412954360247, Accuracy = 0.938097715378\n",
            "Iter #3813376:  Learning rate = 0.001060:   Batch Loss = 0.358793, Accuracy = 0.9609375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.402025133371, Accuracy = 0.94314032793\n",
            "Iter #3817472:  Learning rate = 0.001060:   Batch Loss = 0.343604, Accuracy = 0.96484375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.408932000399, Accuracy = 0.936532795429\n",
            "Iter #3821568:  Learning rate = 0.001060:   Batch Loss = 0.374571, Accuracy = 0.955078125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.401159524918, Accuracy = 0.938967108727\n",
            "Iter #3825664:  Learning rate = 0.001060:   Batch Loss = 0.350994, Accuracy = 0.95703125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.398287713528, Accuracy = 0.941923141479\n",
            "Iter #3829760:  Learning rate = 0.001060:   Batch Loss = 0.366442, Accuracy = 0.953125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.398641854525, Accuracy = 0.941053748131\n",
            "Iter #3833856:  Learning rate = 0.001060:   Batch Loss = 0.348772, Accuracy = 0.970703125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.413693487644, Accuracy = 0.936880528927\n",
            "Iter #3837952:  Learning rate = 0.001060:   Batch Loss = 0.370502, Accuracy = 0.94921875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.409053504467, Accuracy = 0.937923848629\n",
            "Iter #3842048:  Learning rate = 0.001060:   Batch Loss = 0.369709, Accuracy = 0.95703125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.418967872858, Accuracy = 0.933924555779\n",
            "Iter #3846144:  Learning rate = 0.001060:   Batch Loss = 0.404734, Accuracy = 0.943359375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.415779948235, Accuracy = 0.934967815876\n",
            "Iter #3850240:  Learning rate = 0.001060:   Batch Loss = 0.379471, Accuracy = 0.939453125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.396264106035, Accuracy = 0.944879174232\n",
            "Iter #3854336:  Learning rate = 0.001060:   Batch Loss = 0.332289, Accuracy = 0.966796875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.418417394161, Accuracy = 0.935837268829\n",
            "Iter #3858432:  Learning rate = 0.001060:   Batch Loss = 0.362829, Accuracy = 0.955078125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.415767014027, Accuracy = 0.937228322029\n",
            "Iter #3862528:  Learning rate = 0.001060:   Batch Loss = 0.365473, Accuracy = 0.953125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.416218757629, Accuracy = 0.935315608978\n",
            "Iter #3866624:  Learning rate = 0.001060:   Batch Loss = 0.325213, Accuracy = 0.974609375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.405534625053, Accuracy = 0.941401481628\n",
            "Iter #3870720:  Learning rate = 0.001060:   Batch Loss = 0.361083, Accuracy = 0.953125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.418101787567, Accuracy = 0.934793949127\n",
            "Iter #3874816:  Learning rate = 0.001060:   Batch Loss = 0.330965, Accuracy = 0.9609375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.420047074556, Accuracy = 0.938097715378\n",
            "Iter #3878912:  Learning rate = 0.001060:   Batch Loss = 0.350497, Accuracy = 0.953125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.412066847086, Accuracy = 0.940358221531\n",
            "Iter #3883008:  Learning rate = 0.001060:   Batch Loss = 0.331689, Accuracy = 0.96484375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.401858270168, Accuracy = 0.944357514381\n",
            "Iter #3887104:  Learning rate = 0.001060:   Batch Loss = 0.340868, Accuracy = 0.958984375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.418077647686, Accuracy = 0.93774998188\n",
            "Iter #3891200:  Learning rate = 0.001060:   Batch Loss = 0.359786, Accuracy = 0.951171875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.407554626465, Accuracy = 0.937923848629\n",
            "Iter #3895296:  Learning rate = 0.001060:   Batch Loss = 0.374588, Accuracy = 0.958984375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.416308760643, Accuracy = 0.934446156025\n",
            "Iter #3899392:  Learning rate = 0.001060:   Batch Loss = 0.359210, Accuracy = 0.95703125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.437631368637, Accuracy = 0.932707369328\n",
            "Iter #3903488:  Learning rate = 0.001018:   Batch Loss = 0.375065, Accuracy = 0.94921875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.42440867424, Accuracy = 0.935489475727\n",
            "Iter #3907584:  Learning rate = 0.001018:   Batch Loss = 0.361677, Accuracy = 0.953125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.40336817503, Accuracy = 0.939662694931\n",
            "Iter #3911680:  Learning rate = 0.001018:   Batch Loss = 0.356747, Accuracy = 0.95703125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.44657176733, Accuracy = 0.928186416626\n",
            "Iter #3915776:  Learning rate = 0.001018:   Batch Loss = 0.369381, Accuracy = 0.94921875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.436606585979, Accuracy = 0.932011842728\n",
            "Iter #3919872:  Learning rate = 0.001018:   Batch Loss = 0.421869, Accuracy = 0.9296875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.448496639729, Accuracy = 0.924013197422\n",
            "Iter #3923968:  Learning rate = 0.001018:   Batch Loss = 0.372929, Accuracy = 0.947265625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.43183106184, Accuracy = 0.929751336575\n",
            "Iter #3928064:  Learning rate = 0.001018:   Batch Loss = 0.354803, Accuracy = 0.958984375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.419990301132, Accuracy = 0.935141742229\n",
            "Iter #3932160:  Learning rate = 0.001018:   Batch Loss = 0.353712, Accuracy = 0.96484375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.399298369884, Accuracy = 0.941923141479\n",
            "Iter #3936256:  Learning rate = 0.001018:   Batch Loss = 0.387365, Accuracy = 0.943359375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.417861968279, Accuracy = 0.935837268829\n",
            "Iter #3940352:  Learning rate = 0.001018:   Batch Loss = 0.328041, Accuracy = 0.974609375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.406201422215, Accuracy = 0.940184295177\n",
            "Iter #3944448:  Learning rate = 0.001018:   Batch Loss = 0.344603, Accuracy = 0.9609375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.40083438158, Accuracy = 0.941749274731\n",
            "Iter #3948544:  Learning rate = 0.001018:   Batch Loss = 0.370193, Accuracy = 0.955078125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.410829126835, Accuracy = 0.937228322029\n",
            "Iter #3952640:  Learning rate = 0.001018:   Batch Loss = 0.353346, Accuracy = 0.96484375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.398515164852, Accuracy = 0.942618668079\n",
            "Iter #3956736:  Learning rate = 0.001018:   Batch Loss = 0.346301, Accuracy = 0.9609375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.403242886066, Accuracy = 0.940879821777\n",
            "Iter #3960832:  Learning rate = 0.001018:   Batch Loss = 0.386469, Accuracy = 0.951171875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.433488845825, Accuracy = 0.926621437073\n",
            "Iter #3964928:  Learning rate = 0.001018:   Batch Loss = 0.365266, Accuracy = 0.958984375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.405792295933, Accuracy = 0.93914103508\n",
            "Iter #3969024:  Learning rate = 0.001018:   Batch Loss = 0.312636, Accuracy = 0.96875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.408822417259, Accuracy = 0.937402188778\n",
            "Iter #3973120:  Learning rate = 0.001018:   Batch Loss = 0.332363, Accuracy = 0.962890625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.404931664467, Accuracy = 0.941053748131\n",
            "Iter #3977216:  Learning rate = 0.001018:   Batch Loss = 0.386664, Accuracy = 0.9453125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.410920023918, Accuracy = 0.938619375229\n",
            "Iter #3981312:  Learning rate = 0.001018:   Batch Loss = 0.300032, Accuracy = 0.984375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.403116583824, Accuracy = 0.939662694931\n",
            "Iter #3985408:  Learning rate = 0.001018:   Batch Loss = 0.330838, Accuracy = 0.96484375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.427628219128, Accuracy = 0.933229029179\n",
            "Iter #3989504:  Learning rate = 0.001018:   Batch Loss = 0.376169, Accuracy = 0.951171875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.412961304188, Accuracy = 0.934967815876\n",
            "Iter #3993600:  Learning rate = 0.001018:   Batch Loss = 0.333940, Accuracy = 0.970703125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.412162721157, Accuracy = 0.932707369328\n",
            "Iter #3997696:  Learning rate = 0.001018:   Batch Loss = 0.338811, Accuracy = 0.958984375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.418192058802, Accuracy = 0.935141742229\n",
            "Iter #4001792:  Learning rate = 0.000977:   Batch Loss = 0.346542, Accuracy = 0.953125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.436983704567, Accuracy = 0.927838623524\n",
            "Iter #4005888:  Learning rate = 0.000977:   Batch Loss = 0.377350, Accuracy = 0.939453125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.426133334637, Accuracy = 0.933924555779\n",
            "Iter #4009984:  Learning rate = 0.000977:   Batch Loss = 0.312223, Accuracy = 0.9765625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.41733032465, Accuracy = 0.934272289276\n",
            "Iter #4014080:  Learning rate = 0.000977:   Batch Loss = 0.367765, Accuracy = 0.955078125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.410303533077, Accuracy = 0.934967815876\n",
            "Iter #4018176:  Learning rate = 0.000977:   Batch Loss = 0.319323, Accuracy = 0.974609375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.39626082778, Accuracy = 0.942618668079\n",
            "Iter #4022272:  Learning rate = 0.000977:   Batch Loss = 0.368825, Accuracy = 0.951171875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.398145586252, Accuracy = 0.942444801331\n",
            "Iter #4026368:  Learning rate = 0.000977:   Batch Loss = 0.361246, Accuracy = 0.947265625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.413784205914, Accuracy = 0.935141742229\n",
            "Iter #4030464:  Learning rate = 0.000977:   Batch Loss = 0.337678, Accuracy = 0.9609375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.408822476864, Accuracy = 0.940879821777\n",
            "Iter #4034560:  Learning rate = 0.000977:   Batch Loss = 0.372203, Accuracy = 0.94140625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.436494201422, Accuracy = 0.929229676723\n",
            "Iter #4038656:  Learning rate = 0.000977:   Batch Loss = 0.351432, Accuracy = 0.9609375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.443543553352, Accuracy = 0.930272996426\n",
            "Iter #4042752:  Learning rate = 0.000977:   Batch Loss = 0.340683, Accuracy = 0.96484375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.41769656539, Accuracy = 0.934793949127\n",
            "Iter #4046848:  Learning rate = 0.000977:   Batch Loss = 0.376616, Accuracy = 0.953125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.406703799963, Accuracy = 0.941575407982\n",
            "Iter #4050944:  Learning rate = 0.000977:   Batch Loss = 0.349683, Accuracy = 0.9609375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.425297260284, Accuracy = 0.932359576225\n",
            "Iter #4055040:  Learning rate = 0.000977:   Batch Loss = 0.333053, Accuracy = 0.958984375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.404138922691, Accuracy = 0.942097008228\n",
            "Iter #4059136:  Learning rate = 0.000977:   Batch Loss = 0.359818, Accuracy = 0.94140625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.408933550119, Accuracy = 0.937576055527\n",
            "Iter #4063232:  Learning rate = 0.000977:   Batch Loss = 0.338466, Accuracy = 0.970703125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.406477957964, Accuracy = 0.939662694931\n",
            "Iter #4067328:  Learning rate = 0.000977:   Batch Loss = 0.334336, Accuracy = 0.958984375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.413685083389, Accuracy = 0.937402188778\n",
            "Iter #4071424:  Learning rate = 0.000977:   Batch Loss = 0.335227, Accuracy = 0.962890625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.403375089169, Accuracy = 0.941053748131\n",
            "Iter #4075520:  Learning rate = 0.000977:   Batch Loss = 0.395017, Accuracy = 0.947265625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.442884385586, Accuracy = 0.930968523026\n",
            "Iter #4079616:  Learning rate = 0.000977:   Batch Loss = 0.355734, Accuracy = 0.955078125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.424191296101, Accuracy = 0.930620789528\n",
            "Iter #4083712:  Learning rate = 0.000977:   Batch Loss = 0.343380, Accuracy = 0.962890625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.454304397106, Accuracy = 0.928708076477\n",
            "Iter #4087808:  Learning rate = 0.000977:   Batch Loss = 0.335676, Accuracy = 0.962890625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.422787666321, Accuracy = 0.931837916374\n",
            "Iter #4091904:  Learning rate = 0.000977:   Batch Loss = 0.398551, Accuracy = 0.943359375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.417662888765, Accuracy = 0.931837916374\n",
            "Iter #4096000:  Learning rate = 0.000977:   Batch Loss = 0.337577, Accuracy = 0.9609375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.415223747492, Accuracy = 0.936880528927\n",
            "Iter #4100096:  Learning rate = 0.000938:   Batch Loss = 0.328765, Accuracy = 0.96484375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.409403115511, Accuracy = 0.934098422527\n",
            "Iter #4104192:  Learning rate = 0.000938:   Batch Loss = 0.328612, Accuracy = 0.96484375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.393941253424, Accuracy = 0.945400774479\n",
            "Iter #4108288:  Learning rate = 0.000938:   Batch Loss = 0.380449, Accuracy = 0.953125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.410970032215, Accuracy = 0.937228322029\n",
            "Iter #4112384:  Learning rate = 0.000938:   Batch Loss = 0.344897, Accuracy = 0.9609375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.406383156776, Accuracy = 0.942097008228\n",
            "Iter #4116480:  Learning rate = 0.000938:   Batch Loss = 0.377597, Accuracy = 0.9453125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.411958873272, Accuracy = 0.936532795429\n",
            "Iter #4120576:  Learning rate = 0.000938:   Batch Loss = 0.340337, Accuracy = 0.966796875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.399860024452, Accuracy = 0.94053208828\n",
            "Iter #4124672:  Learning rate = 0.000938:   Batch Loss = 0.340629, Accuracy = 0.962890625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.406171381474, Accuracy = 0.940010428429\n",
            "Iter #4128768:  Learning rate = 0.000938:   Batch Loss = 0.332512, Accuracy = 0.96875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.395469278097, Accuracy = 0.942966461182\n",
            "Iter #4132864:  Learning rate = 0.000938:   Batch Loss = 0.382573, Accuracy = 0.94921875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.410002112389, Accuracy = 0.93774998188\n",
            "Iter #4136960:  Learning rate = 0.000938:   Batch Loss = 0.327514, Accuracy = 0.962890625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.408898174763, Accuracy = 0.936185002327\n",
            "Iter #4141056:  Learning rate = 0.000938:   Batch Loss = 0.384241, Accuracy = 0.947265625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.405780345201, Accuracy = 0.941053748131\n",
            "Iter #4145152:  Learning rate = 0.000938:   Batch Loss = 0.346343, Accuracy = 0.96484375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.404479980469, Accuracy = 0.940010428429\n",
            "Iter #4149248:  Learning rate = 0.000938:   Batch Loss = 0.416751, Accuracy = 0.93359375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.449266672134, Accuracy = 0.921578884125\n",
            "Iter #4153344:  Learning rate = 0.000938:   Batch Loss = 0.361530, Accuracy = 0.94921875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 4.1445813179, Accuracy = 0.230742484331\n",
            "Iter #4157440:  Learning rate = 0.000938:   Batch Loss = 0.391552, Accuracy = 0.947265625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.445923149586, Accuracy = 0.927664756775\n",
            "Iter #4161536:  Learning rate = 0.000938:   Batch Loss = 0.359734, Accuracy = 0.962890625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.441104590893, Accuracy = 0.931316316128\n",
            "Iter #4165632:  Learning rate = 0.000938:   Batch Loss = 0.360246, Accuracy = 0.96484375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.415010273457, Accuracy = 0.937054395676\n",
            "Iter #4169728:  Learning rate = 0.000938:   Batch Loss = 0.360774, Accuracy = 0.955078125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.424312829971, Accuracy = 0.934793949127\n",
            "Iter #4173824:  Learning rate = 0.000938:   Batch Loss = 0.399467, Accuracy = 0.927734375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.402879357338, Accuracy = 0.93914103508\n",
            "Iter #4177920:  Learning rate = 0.000938:   Batch Loss = 0.370938, Accuracy = 0.9453125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.404704421759, Accuracy = 0.940010428429\n",
            "Iter #4182016:  Learning rate = 0.000938:   Batch Loss = 0.362359, Accuracy = 0.951171875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.388063371181, Accuracy = 0.94383585453\n",
            "Iter #4186112:  Learning rate = 0.000938:   Batch Loss = 0.344175, Accuracy = 0.966796875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.395086139441, Accuracy = 0.94314032793\n",
            "Iter #4190208:  Learning rate = 0.000938:   Batch Loss = 0.345172, Accuracy = 0.970703125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.398613035679, Accuracy = 0.940705955029\n",
            "Iter #4194304:  Learning rate = 0.000938:   Batch Loss = 0.328533, Accuracy = 0.970703125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.408913075924, Accuracy = 0.937923848629\n",
            "Iter #4198400:  Learning rate = 0.000938:   Batch Loss = 0.358186, Accuracy = 0.953125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.396493643522, Accuracy = 0.94314032793\n",
            "Iter #4202496:  Learning rate = 0.000900:   Batch Loss = 0.327116, Accuracy = 0.97265625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.407079100609, Accuracy = 0.938271582127\n",
            "Iter #4206592:  Learning rate = 0.000900:   Batch Loss = 0.329929, Accuracy = 0.96484375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.394857466221, Accuracy = 0.942618668079\n",
            "Iter #4210688:  Learning rate = 0.000900:   Batch Loss = 0.341624, Accuracy = 0.962890625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.389922767878, Accuracy = 0.943661987782\n",
            "Iter #4214784:  Learning rate = 0.000900:   Batch Loss = 0.379721, Accuracy = 0.955078125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.416619122028, Accuracy = 0.934620082378\n",
            "Iter #4218880:  Learning rate = 0.000900:   Batch Loss = 0.351859, Accuracy = 0.94921875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.404848784208, Accuracy = 0.936532795429\n",
            "Iter #4222976:  Learning rate = 0.000900:   Batch Loss = 0.356173, Accuracy = 0.953125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.395573854446, Accuracy = 0.942444801331\n",
            "Iter #4227072:  Learning rate = 0.000900:   Batch Loss = 0.335762, Accuracy = 0.96875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.386362195015, Accuracy = 0.946270227432\n",
            "Iter #4231168:  Learning rate = 0.000900:   Batch Loss = 0.313865, Accuracy = 0.974609375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.386607587337, Accuracy = 0.943661987782\n",
            "Iter #4235264:  Learning rate = 0.000900:   Batch Loss = 0.356869, Accuracy = 0.953125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.390449762344, Accuracy = 0.94314032793\n",
            "Iter #4239360:  Learning rate = 0.000900:   Batch Loss = 3.470238, Accuracy = 0.306640625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 2.91973018646, Accuracy = 0.314901769161\n",
            "Iter #4243456:  Learning rate = 0.000900:   Batch Loss = 1.544779, Accuracy = 0.47265625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.44111645222, Accuracy = 0.533820211887\n",
            "Iter #4247552:  Learning rate = 0.000900:   Batch Loss = 1.029911, Accuracy = 0.69921875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 1.03402638435, Accuracy = 0.697965562344\n",
            "Iter #4251648:  Learning rate = 0.000900:   Batch Loss = 0.847048, Accuracy = 0.759765625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.880975186825, Accuracy = 0.754477500916\n",
            "Iter #4255744:  Learning rate = 0.000900:   Batch Loss = 0.741446, Accuracy = 0.79296875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.810141563416, Accuracy = 0.779516577721\n",
            "Iter #4259840:  Learning rate = 0.000900:   Batch Loss = 0.806550, Accuracy = 0.76953125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.726755976677, Accuracy = 0.801599740982\n",
            "Iter #4263936:  Learning rate = 0.000900:   Batch Loss = 0.654805, Accuracy = 0.837890625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.686180710793, Accuracy = 0.819335758686\n",
            "Iter #4268032:  Learning rate = 0.000900:   Batch Loss = 0.647021, Accuracy = 0.853515625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.652234971523, Accuracy = 0.838115096092\n",
            "Iter #4272128:  Learning rate = 0.000900:   Batch Loss = 0.597835, Accuracy = 0.86328125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.637678682804, Accuracy = 0.858807146549\n",
            "Iter #4276224:  Learning rate = 0.000900:   Batch Loss = 0.579979, Accuracy = 0.87109375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.60527151823, Accuracy = 0.870805084705\n",
            "Iter #4280320:  Learning rate = 0.000900:   Batch Loss = 0.559672, Accuracy = 0.875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.618463873863, Accuracy = 0.851677954197\n",
            "Iter #4284416:  Learning rate = 0.000900:   Batch Loss = 0.553880, Accuracy = 0.884765625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.65747988224, Accuracy = 0.846635341644\n",
            "Iter #4288512:  Learning rate = 0.000900:   Batch Loss = 0.542748, Accuracy = 0.890625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.614718794823, Accuracy = 0.8607198596\n",
            "Iter #4292608:  Learning rate = 0.000900:   Batch Loss = 0.533645, Accuracy = 0.875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.582056164742, Accuracy = 0.875847697258\n",
            "Iter #4296704:  Learning rate = 0.000900:   Batch Loss = 0.525517, Accuracy = 0.900390625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.576172709465, Accuracy = 0.881238043308\n",
            "Iter #4300800:  Learning rate = 0.000864:   Batch Loss = 0.504802, Accuracy = 0.912109375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.581875443459, Accuracy = 0.875499904156\n",
            "Iter #4304896:  Learning rate = 0.000864:   Batch Loss = 0.527140, Accuracy = 0.892578125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.602460563183, Accuracy = 0.858459413052\n",
            "Iter #4308992:  Learning rate = 0.000864:   Batch Loss = 0.521936, Accuracy = 0.90234375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.550418376923, Accuracy = 0.883846282959\n",
            "Iter #4313088:  Learning rate = 0.000864:   Batch Loss = 0.505761, Accuracy = 0.91796875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.558935403824, Accuracy = 0.877586483955\n",
            "Iter #4317184:  Learning rate = 0.000864:   Batch Loss = 0.555056, Accuracy = 0.90234375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.531561553478, Accuracy = 0.892888188362\n",
            "Iter #4321280:  Learning rate = 0.000864:   Batch Loss = 0.511697, Accuracy = 0.900390625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.553723394871, Accuracy = 0.886106789112\n",
            "Iter #4325376:  Learning rate = 0.000864:   Batch Loss = 0.471345, Accuracy = 0.921875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.568056344986, Accuracy = 0.880890250206\n",
            "Iter #4329472:  Learning rate = 0.000864:   Batch Loss = 0.523630, Accuracy = 0.90234375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.545295596123, Accuracy = 0.88367241621\n",
            "Iter #4333568:  Learning rate = 0.000864:   Batch Loss = 0.481318, Accuracy = 0.9140625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.546846210957, Accuracy = 0.891323268414\n",
            "Iter #4337664:  Learning rate = 0.000864:   Batch Loss = 0.467770, Accuracy = 0.9296875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.510588765144, Accuracy = 0.901930093765\n",
            "Iter #4341760:  Learning rate = 0.000864:   Batch Loss = 0.520038, Accuracy = 0.884765625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.541351318359, Accuracy = 0.888019502163\n",
            "Iter #4345856:  Learning rate = 0.000864:   Batch Loss = 0.465576, Accuracy = 0.927734375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.506131887436, Accuracy = 0.906451046467\n",
            "Iter #4349952:  Learning rate = 0.000864:   Batch Loss = 0.491086, Accuracy = 0.91015625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.543199300766, Accuracy = 0.889584422112\n",
            "Iter #4354048:  Learning rate = 0.000864:   Batch Loss = 0.482364, Accuracy = 0.912109375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.510861814022, Accuracy = 0.904538333416\n",
            "Iter #4358144:  Learning rate = 0.000864:   Batch Loss = 0.426490, Accuracy = 0.927734375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.500216603279, Accuracy = 0.902451753616\n",
            "Iter #4362240:  Learning rate = 0.000864:   Batch Loss = 0.443262, Accuracy = 0.923828125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.520087003708, Accuracy = 0.900017380714\n",
            "Iter #4366336:  Learning rate = 0.000864:   Batch Loss = 0.495345, Accuracy = 0.927734375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.535576045513, Accuracy = 0.88715004921\n",
            "Iter #4370432:  Learning rate = 0.000864:   Batch Loss = 0.422544, Accuracy = 0.943359375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.502267718315, Accuracy = 0.904712200165\n",
            "Iter #4374528:  Learning rate = 0.000864:   Batch Loss = 0.446220, Accuracy = 0.93359375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.509371638298, Accuracy = 0.905059993267\n",
            "Iter #4378624:  Learning rate = 0.000864:   Batch Loss = 0.450099, Accuracy = 0.919921875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.493650496006, Accuracy = 0.907842099667\n",
            "Iter #4382720:  Learning rate = 0.000864:   Batch Loss = 0.442675, Accuracy = 0.93359375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.554689705372, Accuracy = 0.88297688961\n",
            "Iter #4386816:  Learning rate = 0.000864:   Batch Loss = 0.450614, Accuracy = 0.923828125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.53937548399, Accuracy = 0.889236629009\n",
            "Iter #4390912:  Learning rate = 0.000864:   Batch Loss = 0.538435, Accuracy = 0.896484375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.516811847687, Accuracy = 0.893757581711\n",
            "Iter #4395008:  Learning rate = 0.000864:   Batch Loss = 0.430698, Accuracy = 0.935546875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.508935987949, Accuracy = 0.904886126518\n",
            "Iter #4399104:  Learning rate = 0.000864:   Batch Loss = 0.471525, Accuracy = 0.927734375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.519526541233, Accuracy = 0.897756934166\n",
            "Iter #4403200:  Learning rate = 0.000830:   Batch Loss = 0.455778, Accuracy = 0.92578125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.492160439491, Accuracy = 0.909059286118\n",
            "Iter #4407296:  Learning rate = 0.000830:   Batch Loss = 0.468844, Accuracy = 0.927734375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.488155275583, Accuracy = 0.913580238819\n",
            "Iter #4411392:  Learning rate = 0.000830:   Batch Loss = 0.454731, Accuracy = 0.9296875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.489017426968, Accuracy = 0.906624913216\n",
            "Iter #4415488:  Learning rate = 0.000830:   Batch Loss = 0.443771, Accuracy = 0.927734375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.506583034992, Accuracy = 0.901408433914\n",
            "Iter #4419584:  Learning rate = 0.000830:   Batch Loss = 0.439815, Accuracy = 0.919921875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.518239200115, Accuracy = 0.897061407566\n",
            "Iter #4423680:  Learning rate = 0.000830:   Batch Loss = 0.511674, Accuracy = 0.900390625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.482563316822, Accuracy = 0.912015318871\n",
            "Iter #4427776:  Learning rate = 0.000830:   Batch Loss = 0.440501, Accuracy = 0.93359375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.497188031673, Accuracy = 0.905233860016\n",
            "Iter #4431872:  Learning rate = 0.000830:   Batch Loss = 0.412483, Accuracy = 0.94140625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.479681074619, Accuracy = 0.913058578968\n",
            "Iter #4435968:  Learning rate = 0.000830:   Batch Loss = 0.418633, Accuracy = 0.93359375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.550486922264, Accuracy = 0.882802963257\n",
            "Iter #4440064:  Learning rate = 0.000830:   Batch Loss = 0.408139, Accuracy = 0.943359375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.501726210117, Accuracy = 0.906624913216\n",
            "Iter #4444160:  Learning rate = 0.000830:   Batch Loss = 0.398651, Accuracy = 0.9453125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.474907100201, Accuracy = 0.915840744972\n",
            "Iter #4448256:  Learning rate = 0.000830:   Batch Loss = 0.423945, Accuracy = 0.92578125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.479812443256, Accuracy = 0.914449632168\n",
            "Iter #4452352:  Learning rate = 0.000830:   Batch Loss = 0.410032, Accuracy = 0.947265625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.500865101814, Accuracy = 0.907494366169\n",
            "Iter #4456448:  Learning rate = 0.000830:   Batch Loss = 0.481396, Accuracy = 0.912109375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.503472685814, Accuracy = 0.907494366169\n",
            "Iter #4460544:  Learning rate = 0.000830:   Batch Loss = 0.415681, Accuracy = 0.923828125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.499847888947, Accuracy = 0.897930800915\n",
            "Iter #4464640:  Learning rate = 0.000830:   Batch Loss = 0.397763, Accuracy = 0.9453125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.485777497292, Accuracy = 0.910450339317\n",
            "Iter #4468736:  Learning rate = 0.000830:   Batch Loss = 0.431481, Accuracy = 0.93359375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.498855948448, Accuracy = 0.909754812717\n",
            "Iter #4472832:  Learning rate = 0.000830:   Batch Loss = 0.432325, Accuracy = 0.94140625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.47045686841, Accuracy = 0.919840037823\n",
            "Iter #4476928:  Learning rate = 0.000830:   Batch Loss = 0.385490, Accuracy = 0.951171875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.47496587038, Accuracy = 0.914275765419\n",
            "Iter #4481024:  Learning rate = 0.000830:   Batch Loss = 0.400205, Accuracy = 0.953125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.460081756115, Accuracy = 0.923665463924\n",
            "Iter #4485120:  Learning rate = 0.000830:   Batch Loss = 0.418969, Accuracy = 0.9296875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.480403125286, Accuracy = 0.914275765419\n",
            "Iter #4489216:  Learning rate = 0.000830:   Batch Loss = 0.446825, Accuracy = 0.927734375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.500996112823, Accuracy = 0.905581653118\n",
            "Iter #4493312:  Learning rate = 0.000830:   Batch Loss = 0.435347, Accuracy = 0.923828125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.497883349657, Accuracy = 0.903495073318\n",
            "Iter #4497408:  Learning rate = 0.000830:   Batch Loss = 0.401644, Accuracy = 0.939453125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 2.19439435005, Accuracy = 0.551556229591\n",
            "Iter #4501504:  Learning rate = 0.000796:   Batch Loss = 0.462259, Accuracy = 0.92578125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.524312376976, Accuracy = 0.896713614464\n",
            "Iter #4505600:  Learning rate = 0.000796:   Batch Loss = 0.466464, Accuracy = 0.919921875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.491840422153, Accuracy = 0.904538333416\n",
            "Iter #4509696:  Learning rate = 0.000796:   Batch Loss = 0.439543, Accuracy = 0.935546875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.483970880508, Accuracy = 0.910971999168\n",
            "Iter #4513792:  Learning rate = 0.000796:   Batch Loss = 0.424191, Accuracy = 0.9453125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.49231132865, Accuracy = 0.908363759518\n",
            "Iter #4517888:  Learning rate = 0.000796:   Batch Loss = 0.406536, Accuracy = 0.943359375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.477612614632, Accuracy = 0.91340637207\n",
            "Iter #4521984:  Learning rate = 0.000796:   Batch Loss = 0.428394, Accuracy = 0.93359375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.46675401926, Accuracy = 0.921926617622\n",
            "Iter #4526080:  Learning rate = 0.000796:   Batch Loss = 0.449923, Accuracy = 0.912109375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.478325277567, Accuracy = 0.913928031921\n",
            "Iter #4530176:  Learning rate = 0.000796:   Batch Loss = 0.416141, Accuracy = 0.939453125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.457397341728, Accuracy = 0.922448277473\n",
            "Iter #4534272:  Learning rate = 0.000796:   Batch Loss = 0.406582, Accuracy = 0.943359375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.469410836697, Accuracy = 0.918622851372\n",
            "Iter #4538368:  Learning rate = 0.000796:   Batch Loss = 0.440735, Accuracy = 0.919921875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.466075062752, Accuracy = 0.91688400507\n",
            "Iter #4542464:  Learning rate = 0.000796:   Batch Loss = 0.422081, Accuracy = 0.92578125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.460251271725, Accuracy = 0.921231091022\n",
            "Iter #4546560:  Learning rate = 0.000796:   Batch Loss = 0.399975, Accuracy = 0.93359375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.476259410381, Accuracy = 0.91271084547\n",
            "Iter #4550656:  Learning rate = 0.000796:   Batch Loss = 0.384692, Accuracy = 0.955078125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.483135342598, Accuracy = 0.914449632168\n",
            "Iter #4554752:  Learning rate = 0.000796:   Batch Loss = 0.405528, Accuracy = 0.9375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.488190412521, Accuracy = 0.907668232918\n",
            "Iter #4558848:  Learning rate = 0.000796:   Batch Loss = 0.402282, Accuracy = 0.947265625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.468702912331, Accuracy = 0.919144511223\n",
            "Iter #4562944:  Learning rate = 0.000796:   Batch Loss = 0.376307, Accuracy = 0.947265625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.48866134882, Accuracy = 0.907668232918\n",
            "Iter #4567040:  Learning rate = 0.000796:   Batch Loss = 0.454108, Accuracy = 0.916015625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.503446519375, Accuracy = 0.908537626266\n",
            "Iter #4571136:  Learning rate = 0.000796:   Batch Loss = 0.486738, Accuracy = 0.91015625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.487410485744, Accuracy = 0.906798839569\n",
            "Iter #4575232:  Learning rate = 0.000796:   Batch Loss = 0.382226, Accuracy = 0.955078125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.458135634661, Accuracy = 0.921578884125\n",
            "Iter #4579328:  Learning rate = 0.000796:   Batch Loss = 0.421461, Accuracy = 0.94140625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.477706313133, Accuracy = 0.913232505322\n",
            "Iter #4583424:  Learning rate = 0.000796:   Batch Loss = 0.458747, Accuracy = 0.919921875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.454877436161, Accuracy = 0.924013197422\n",
            "Iter #4587520:  Learning rate = 0.000796:   Batch Loss = 0.371038, Accuracy = 0.966796875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.465891182423, Accuracy = 0.921404957771\n",
            "Iter #4591616:  Learning rate = 0.000796:   Batch Loss = 0.371837, Accuracy = 0.955078125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.461682677269, Accuracy = 0.920013904572\n",
            "Iter #4595712:  Learning rate = 0.000796:   Batch Loss = 0.384833, Accuracy = 0.935546875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.486397385597, Accuracy = 0.906277179718\n",
            "Iter #4599808:  Learning rate = 0.000796:   Batch Loss = 0.365063, Accuracy = 0.95703125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.456764966249, Accuracy = 0.925404250622\n",
            "Iter #4603904:  Learning rate = 0.000765:   Batch Loss = 0.430117, Accuracy = 0.919921875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.469497382641, Accuracy = 0.918622851372\n",
            "Iter #4608000:  Learning rate = 0.000765:   Batch Loss = 0.386990, Accuracy = 0.94140625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.459600567818, Accuracy = 0.924187123775\n",
            "Iter #4612096:  Learning rate = 0.000765:   Batch Loss = 0.431432, Accuracy = 0.939453125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.452633738518, Accuracy = 0.92018777132\n",
            "Iter #4616192:  Learning rate = 0.000765:   Batch Loss = 0.415219, Accuracy = 0.951171875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.456479877234, Accuracy = 0.921057224274\n",
            "Iter #4620288:  Learning rate = 0.000765:   Batch Loss = 0.383669, Accuracy = 0.953125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.443681776524, Accuracy = 0.928186416626\n",
            "Iter #4624384:  Learning rate = 0.000765:   Batch Loss = 0.441052, Accuracy = 0.91796875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.447812616825, Accuracy = 0.925578176975\n",
            "Iter #4628480:  Learning rate = 0.000765:   Batch Loss = 0.390096, Accuracy = 0.94921875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.472578525543, Accuracy = 0.91949224472\n",
            "Iter #4632576:  Learning rate = 0.000765:   Batch Loss = 0.430893, Accuracy = 0.9296875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.458994805813, Accuracy = 0.920013904572\n",
            "Iter #4636672:  Learning rate = 0.000765:   Batch Loss = 0.397958, Accuracy = 0.94140625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.477860569954, Accuracy = 0.917405664921\n",
            "Iter #4640768:  Learning rate = 0.000765:   Batch Loss = 0.426540, Accuracy = 0.93359375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.511792898178, Accuracy = 0.902799487114\n",
            "Iter #4644864:  Learning rate = 0.000765:   Batch Loss = 0.398926, Accuracy = 0.939453125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.472835958004, Accuracy = 0.913754105568\n",
            "Iter #4648960:  Learning rate = 0.000765:   Batch Loss = 0.414538, Accuracy = 0.9375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.528693139553, Accuracy = 0.900365173817\n",
            "Iter #4653056:  Learning rate = 0.000765:   Batch Loss = 0.478889, Accuracy = 0.908203125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.486302912235, Accuracy = 0.908537626266\n",
            "Iter #4657152:  Learning rate = 0.000765:   Batch Loss = 0.440213, Accuracy = 0.927734375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.469972729683, Accuracy = 0.91949224472\n",
            "Iter #4661248:  Learning rate = 0.000765:   Batch Loss = 0.407740, Accuracy = 0.943359375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.472282350063, Accuracy = 0.917405664921\n",
            "Iter #4665344:  Learning rate = 0.000765:   Batch Loss = 0.394454, Accuracy = 0.94921875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.475236535072, Accuracy = 0.908885419369\n",
            "Iter #4669440:  Learning rate = 0.000765:   Batch Loss = 0.426707, Accuracy = 0.94140625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.4428191185, Accuracy = 0.925056517124\n",
            "Iter #4673536:  Learning rate = 0.000765:   Batch Loss = 0.397018, Accuracy = 0.943359375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.453442871571, Accuracy = 0.927316963673\n",
            "Iter #4677632:  Learning rate = 0.000765:   Batch Loss = 0.386817, Accuracy = 0.943359375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.455874621868, Accuracy = 0.92088329792\n",
            "Iter #4681728:  Learning rate = 0.000765:   Batch Loss = 0.374189, Accuracy = 0.955078125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.44780933857, Accuracy = 0.925752043724\n",
            "Iter #4685824:  Learning rate = 0.000765:   Batch Loss = 0.355650, Accuracy = 0.955078125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.448689162731, Accuracy = 0.926099836826\n",
            "Iter #4689920:  Learning rate = 0.000765:   Batch Loss = 0.434748, Accuracy = 0.93359375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.446682393551, Accuracy = 0.926447570324\n",
            "Iter #4694016:  Learning rate = 0.000765:   Batch Loss = 0.423275, Accuracy = 0.947265625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.447535812855, Accuracy = 0.924187123775\n",
            "Iter #4698112:  Learning rate = 0.000765:   Batch Loss = 0.413938, Accuracy = 0.9375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.461287289858, Accuracy = 0.92088329792\n",
            "Iter #4702208:  Learning rate = 0.000734:   Batch Loss = 0.382681, Accuracy = 0.947265625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.464144170284, Accuracy = 0.923491537571\n",
            "Iter #4706304:  Learning rate = 0.000734:   Batch Loss = 0.356520, Accuracy = 0.9609375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.452303409576, Accuracy = 0.923665463924\n",
            "Iter #4710400:  Learning rate = 0.000734:   Batch Loss = 0.363335, Accuracy = 0.955078125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.447337448597, Accuracy = 0.925752043724\n",
            "Iter #4714496:  Learning rate = 0.000734:   Batch Loss = 0.378779, Accuracy = 0.9609375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.443546891212, Accuracy = 0.925925910473\n",
            "Iter #4718592:  Learning rate = 0.000734:   Batch Loss = 0.381519, Accuracy = 0.9453125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.451776504517, Accuracy = 0.925925910473\n",
            "Iter #4722688:  Learning rate = 0.000734:   Batch Loss = 0.387230, Accuracy = 0.947265625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.458619475365, Accuracy = 0.916536271572\n",
            "Iter #4726784:  Learning rate = 0.000734:   Batch Loss = 0.421974, Accuracy = 0.943359375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.450061351061, Accuracy = 0.922100484371\n",
            "Iter #4730880:  Learning rate = 0.000734:   Batch Loss = 0.370353, Accuracy = 0.951171875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.443695664406, Accuracy = 0.926621437073\n",
            "Iter #4734976:  Learning rate = 0.000734:   Batch Loss = 0.386788, Accuracy = 0.9453125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.447494029999, Accuracy = 0.919666171074\n",
            "Iter #4739072:  Learning rate = 0.000734:   Batch Loss = 0.356973, Accuracy = 0.96875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.432226121426, Accuracy = 0.930272996426\n",
            "Iter #4743168:  Learning rate = 0.000734:   Batch Loss = 0.399235, Accuracy = 0.939453125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.450071841478, Accuracy = 0.927143096924\n",
            "Iter #4747264:  Learning rate = 0.000734:   Batch Loss = 0.370821, Accuracy = 0.95703125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.436562120914, Accuracy = 0.924882650375\n",
            "Iter #4751360:  Learning rate = 0.000734:   Batch Loss = 0.360349, Accuracy = 0.958984375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.464221298695, Accuracy = 0.917753458023\n",
            "Iter #4755456:  Learning rate = 0.000734:   Batch Loss = 0.404317, Accuracy = 0.93359375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.459394693375, Accuracy = 0.915840744972\n",
            "Iter #4759552:  Learning rate = 0.000734:   Batch Loss = 0.357713, Accuracy = 0.958984375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.464559793472, Accuracy = 0.919840037823\n",
            "Iter #4763648:  Learning rate = 0.000734:   Batch Loss = 0.369738, Accuracy = 0.953125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.44684690237, Accuracy = 0.924882650375\n",
            "Iter #4767744:  Learning rate = 0.000734:   Batch Loss = 0.360870, Accuracy = 0.95703125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.446678340435, Accuracy = 0.923839330673\n",
            "Iter #4771840:  Learning rate = 0.000734:   Batch Loss = 0.373119, Accuracy = 0.94921875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.444675028324, Accuracy = 0.929055809975\n",
            "Iter #4775936:  Learning rate = 0.000734:   Batch Loss = 0.406001, Accuracy = 0.9375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.454382658005, Accuracy = 0.920361697674\n",
            "Iter #4780032:  Learning rate = 0.000734:   Batch Loss = 0.348492, Accuracy = 0.953125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.431275188923, Accuracy = 0.929925203323\n",
            "Iter #4784128:  Learning rate = 0.000734:   Batch Loss = 0.388993, Accuracy = 0.955078125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.42866230011, Accuracy = 0.932011842728\n",
            "Iter #4788224:  Learning rate = 0.000734:   Batch Loss = 0.399286, Accuracy = 0.951171875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.446581274271, Accuracy = 0.926447570324\n",
            "Iter #4792320:  Learning rate = 0.000734:   Batch Loss = 0.392599, Accuracy = 0.94140625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.438450753689, Accuracy = 0.926447570324\n",
            "Iter #4796416:  Learning rate = 0.000734:   Batch Loss = 0.356136, Accuracy = 0.958984375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.458038926125, Accuracy = 0.921752750874\n",
            "Iter #4800512:  Learning rate = 0.000705:   Batch Loss = 0.360066, Accuracy = 0.95703125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.446475207806, Accuracy = 0.924187123775\n",
            "Iter #4804608:  Learning rate = 0.000705:   Batch Loss = 0.388988, Accuracy = 0.943359375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.438048541546, Accuracy = 0.928012490273\n",
            "Iter #4808704:  Learning rate = 0.000705:   Batch Loss = 0.365036, Accuracy = 0.955078125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.465307712555, Accuracy = 0.917405664921\n",
            "Iter #4812800:  Learning rate = 0.000705:   Batch Loss = 0.413276, Accuracy = 0.931640625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.457674920559, Accuracy = 0.924708724022\n",
            "Iter #4816896:  Learning rate = 0.000705:   Batch Loss = 0.356337, Accuracy = 0.966796875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.444763749838, Accuracy = 0.926273703575\n",
            "Iter #4820992:  Learning rate = 0.000705:   Batch Loss = 0.359547, Accuracy = 0.953125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.44735661149, Accuracy = 0.923143804073\n",
            "Iter #4825088:  Learning rate = 0.000705:   Batch Loss = 0.338979, Accuracy = 0.962890625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.432597637177, Accuracy = 0.929751336575\n",
            "Iter #4829184:  Learning rate = 0.000705:   Batch Loss = 0.382372, Accuracy = 0.951171875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.438161432743, Accuracy = 0.928186416626\n",
            "Iter #4833280:  Learning rate = 0.000705:   Batch Loss = 0.362733, Accuracy = 0.94921875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.436269938946, Accuracy = 0.929403603077\n",
            "Iter #4837376:  Learning rate = 0.000705:   Batch Loss = 0.353357, Accuracy = 0.953125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.446918696165, Accuracy = 0.921404957771\n",
            "Iter #4841472:  Learning rate = 0.000705:   Batch Loss = 0.376072, Accuracy = 0.955078125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.446405768394, Accuracy = 0.925056517124\n",
            "Iter #4845568:  Learning rate = 0.000705:   Batch Loss = 0.342375, Accuracy = 0.95703125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.454491972923, Accuracy = 0.923317670822\n",
            "Iter #4849664:  Learning rate = 0.000705:   Batch Loss = 0.348350, Accuracy = 0.970703125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.434784024954, Accuracy = 0.928881943226\n",
            "Iter #4853760:  Learning rate = 0.000705:   Batch Loss = 0.400551, Accuracy = 0.94140625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.430016815662, Accuracy = 0.933229029179\n",
            "Iter #4857856:  Learning rate = 0.000705:   Batch Loss = 0.412918, Accuracy = 0.931640625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.437761604786, Accuracy = 0.926447570324\n",
            "Iter #4861952:  Learning rate = 0.000705:   Batch Loss = 0.386172, Accuracy = 0.94140625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.435874938965, Accuracy = 0.930968523026\n",
            "Iter #4866048:  Learning rate = 0.000705:   Batch Loss = 0.412104, Accuracy = 0.939453125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.437813878059, Accuracy = 0.930620789528\n",
            "Iter #4870144:  Learning rate = 0.000705:   Batch Loss = 0.364638, Accuracy = 0.953125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.445511519909, Accuracy = 0.926621437073\n",
            "Iter #4874240:  Learning rate = 0.000705:   Batch Loss = 0.361433, Accuracy = 0.95703125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.445287525654, Accuracy = 0.924708724022\n",
            "Iter #4878336:  Learning rate = 0.000705:   Batch Loss = 0.349601, Accuracy = 0.9609375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.43124371767, Accuracy = 0.932011842728\n",
            "Iter #4882432:  Learning rate = 0.000705:   Batch Loss = 0.366448, Accuracy = 0.953125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.442751824856, Accuracy = 0.925925910473\n",
            "Iter #4886528:  Learning rate = 0.000705:   Batch Loss = 0.377354, Accuracy = 0.95703125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.455692768097, Accuracy = 0.923665463924\n",
            "Iter #4890624:  Learning rate = 0.000705:   Batch Loss = 0.419409, Accuracy = 0.939453125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.469747900963, Accuracy = 0.917405664921\n",
            "Iter #4894720:  Learning rate = 0.000705:   Batch Loss = 0.371846, Accuracy = 0.955078125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.462000072002, Accuracy = 0.914623558521\n",
            "Iter #4898816:  Learning rate = 0.000705:   Batch Loss = 0.363287, Accuracy = 0.953125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.430428683758, Accuracy = 0.933924555779\n",
            "Iter #4902912:  Learning rate = 0.000676:   Batch Loss = 0.379700, Accuracy = 0.943359375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.441706717014, Accuracy = 0.929751336575\n",
            "Iter #4907008:  Learning rate = 0.000676:   Batch Loss = 0.346263, Accuracy = 0.9609375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.426091372967, Accuracy = 0.930794656277\n",
            "Iter #4911104:  Learning rate = 0.000676:   Batch Loss = 0.360503, Accuracy = 0.94921875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.442166388035, Accuracy = 0.928360283375\n",
            "Iter #4915200:  Learning rate = 0.000676:   Batch Loss = 0.359336, Accuracy = 0.953125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.441958963871, Accuracy = 0.931142389774\n",
            "Iter #4919296:  Learning rate = 0.000676:   Batch Loss = 0.371592, Accuracy = 0.947265625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.434621572495, Accuracy = 0.930620789528\n",
            "Iter #4923392:  Learning rate = 0.000676:   Batch Loss = 0.365402, Accuracy = 0.953125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.433821797371, Accuracy = 0.928708076477\n",
            "Iter #4927488:  Learning rate = 0.000676:   Batch Loss = 0.394090, Accuracy = 0.935546875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.438536405563, Accuracy = 0.924187123775\n",
            "Iter #4931584:  Learning rate = 0.000676:   Batch Loss = 0.384724, Accuracy = 0.958984375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.424934267998, Accuracy = 0.934793949127\n",
            "Iter #4935680:  Learning rate = 0.000676:   Batch Loss = 0.332971, Accuracy = 0.958984375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.433429658413, Accuracy = 0.922969937325\n",
            "Iter #4939776:  Learning rate = 0.000676:   Batch Loss = 0.344905, Accuracy = 0.96875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.426770985126, Accuracy = 0.932707369328\n",
            "Iter #4943872:  Learning rate = 0.000676:   Batch Loss = 0.314602, Accuracy = 0.96875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.426003903151, Accuracy = 0.933576762676\n",
            "Iter #4947968:  Learning rate = 0.000676:   Batch Loss = 0.376544, Accuracy = 0.953125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.459155708551, Accuracy = 0.912884712219\n",
            "Iter #4952064:  Learning rate = 0.000676:   Batch Loss = 0.371480, Accuracy = 0.953125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.441900998354, Accuracy = 0.927490890026\n",
            "Iter #4956160:  Learning rate = 0.000676:   Batch Loss = 0.380131, Accuracy = 0.947265625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.464126169682, Accuracy = 0.916710138321\n",
            "Iter #4960256:  Learning rate = 0.000676:   Batch Loss = 0.361602, Accuracy = 0.953125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.437800347805, Accuracy = 0.928360283375\n",
            "Iter #4964352:  Learning rate = 0.000676:   Batch Loss = 0.381957, Accuracy = 0.947265625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.425902187824, Accuracy = 0.931142389774\n",
            "Iter #4968448:  Learning rate = 0.000676:   Batch Loss = 0.407037, Accuracy = 0.935546875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.450069636106, Accuracy = 0.920013904572\n",
            "Iter #4972544:  Learning rate = 0.000676:   Batch Loss = 0.377135, Accuracy = 0.947265625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.436164796352, Accuracy = 0.929403603077\n",
            "Iter #4976640:  Learning rate = 0.000676:   Batch Loss = 0.393098, Accuracy = 0.931640625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.435717046261, Accuracy = 0.926969230175\n",
            "Iter #4980736:  Learning rate = 0.000676:   Batch Loss = 0.391983, Accuracy = 0.947265625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.464983522892, Accuracy = 0.914971292019\n",
            "Iter #4984832:  Learning rate = 0.000676:   Batch Loss = 0.366356, Accuracy = 0.943359375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.439753651619, Accuracy = 0.923491537571\n",
            "Iter #4988928:  Learning rate = 0.000676:   Batch Loss = 0.355627, Accuracy = 0.9609375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.439808130264, Accuracy = 0.924882650375\n",
            "Iter #4993024:  Learning rate = 0.000676:   Batch Loss = 0.369697, Accuracy = 0.9453125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.438090264797, Accuracy = 0.928012490273\n",
            "Iter #4997120:  Learning rate = 0.000676:   Batch Loss = 0.357475, Accuracy = 0.962890625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.456577420235, Accuracy = 0.920361697674\n",
            "Iter #5001216:  Learning rate = 0.000649:   Batch Loss = 0.399706, Accuracy = 0.935546875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.436425715685, Accuracy = 0.929577469826\n",
            "Iter #5005312:  Learning rate = 0.000649:   Batch Loss = 0.366799, Accuracy = 0.955078125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.427176207304, Accuracy = 0.933229029179\n",
            "Iter #5009408:  Learning rate = 0.000649:   Batch Loss = 0.344875, Accuracy = 0.96484375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.427405655384, Accuracy = 0.934446156025\n",
            "Iter #5013504:  Learning rate = 0.000649:   Batch Loss = 0.335001, Accuracy = 0.95703125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.416111528873, Accuracy = 0.935489475727\n",
            "Iter #5017600:  Learning rate = 0.000649:   Batch Loss = 0.323017, Accuracy = 0.974609375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.448506474495, Accuracy = 0.927490890026\n",
            "Iter #5021696:  Learning rate = 0.000649:   Batch Loss = 0.326530, Accuracy = 0.97265625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.422665208578, Accuracy = 0.933576762676\n",
            "Iter #5025792:  Learning rate = 0.000649:   Batch Loss = 0.351593, Accuracy = 0.958984375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.423253595829, Accuracy = 0.934446156025\n",
            "Iter #5029888:  Learning rate = 0.000649:   Batch Loss = 0.346481, Accuracy = 0.95703125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.429518818855, Accuracy = 0.928881943226\n",
            "Iter #5033984:  Learning rate = 0.000649:   Batch Loss = 0.376750, Accuracy = 0.95703125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.438268870115, Accuracy = 0.929229676723\n",
            "Iter #5038080:  Learning rate = 0.000649:   Batch Loss = 0.373530, Accuracy = 0.95703125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.421294510365, Accuracy = 0.933229029179\n",
            "Iter #5042176:  Learning rate = 0.000649:   Batch Loss = 0.352899, Accuracy = 0.9609375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.426653265953, Accuracy = 0.929751336575\n",
            "Iter #5046272:  Learning rate = 0.000649:   Batch Loss = 0.360404, Accuracy = 0.953125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.441535323858, Accuracy = 0.925230383873\n",
            "Iter #5050368:  Learning rate = 0.000649:   Batch Loss = 0.318624, Accuracy = 0.96484375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.418726950884, Accuracy = 0.934098422527\n",
            "Iter #5054464:  Learning rate = 0.000649:   Batch Loss = 0.326713, Accuracy = 0.966796875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.436568796635, Accuracy = 0.928708076477\n",
            "Iter #5058560:  Learning rate = 0.000649:   Batch Loss = 0.333928, Accuracy = 0.966796875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.436570435762, Accuracy = 0.931664049625\n",
            "Iter #5062656:  Learning rate = 0.000649:   Batch Loss = 0.367412, Accuracy = 0.943359375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.436478495598, Accuracy = 0.928534150124\n",
            "Iter #5066752:  Learning rate = 0.000649:   Batch Loss = 0.371881, Accuracy = 0.947265625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.421469926834, Accuracy = 0.932359576225\n",
            "Iter #5070848:  Learning rate = 0.000649:   Batch Loss = 0.357098, Accuracy = 0.95703125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.429059624672, Accuracy = 0.931490182877\n",
            "Iter #5074944:  Learning rate = 0.000649:   Batch Loss = 0.348684, Accuracy = 0.9609375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.436412215233, Accuracy = 0.927490890026\n",
            "Iter #5079040:  Learning rate = 0.000649:   Batch Loss = 0.344576, Accuracy = 0.955078125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.419487059116, Accuracy = 0.936358869076\n",
            "Iter #5083136:  Learning rate = 0.000649:   Batch Loss = 0.356225, Accuracy = 0.958984375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.432353824377, Accuracy = 0.926273703575\n",
            "Iter #5087232:  Learning rate = 0.000649:   Batch Loss = 0.375875, Accuracy = 0.9453125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.438915908337, Accuracy = 0.925578176975\n",
            "Iter #5091328:  Learning rate = 0.000649:   Batch Loss = 0.322702, Accuracy = 0.97265625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.424154996872, Accuracy = 0.931837916374\n",
            "Iter #5095424:  Learning rate = 0.000649:   Batch Loss = 0.311328, Accuracy = 0.96875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.433739602566, Accuracy = 0.932533442974\n",
            "Iter #5099520:  Learning rate = 0.000649:   Batch Loss = 0.381449, Accuracy = 0.951171875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.432036548853, Accuracy = 0.926447570324\n",
            "Iter #5103616:  Learning rate = 0.000623:   Batch Loss = 0.365651, Accuracy = 0.9453125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.424975156784, Accuracy = 0.929925203323\n",
            "Iter #5107712:  Learning rate = 0.000623:   Batch Loss = 0.341302, Accuracy = 0.96875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.417317211628, Accuracy = 0.933576762676\n",
            "Iter #5111808:  Learning rate = 0.000623:   Batch Loss = 0.391367, Accuracy = 0.96484375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.42811653018, Accuracy = 0.932707369328\n",
            "Iter #5115904:  Learning rate = 0.000623:   Batch Loss = 0.352426, Accuracy = 0.955078125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.425235331059, Accuracy = 0.934446156025\n",
            "Iter #5120000:  Learning rate = 0.000623:   Batch Loss = 0.336471, Accuracy = 0.9609375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.446776896715, Accuracy = 0.926099836826\n",
            "Iter #5124096:  Learning rate = 0.000623:   Batch Loss = 0.328301, Accuracy = 0.974609375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.427178680897, Accuracy = 0.930272996426\n",
            "Iter #5128192:  Learning rate = 0.000623:   Batch Loss = 0.344304, Accuracy = 0.962890625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.424970209599, Accuracy = 0.933750629425\n",
            "Iter #5132288:  Learning rate = 0.000623:   Batch Loss = 0.360290, Accuracy = 0.962890625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.418568313122, Accuracy = 0.934793949127\n",
            "Iter #5136384:  Learning rate = 0.000623:   Batch Loss = 0.376719, Accuracy = 0.953125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.433122217655, Accuracy = 0.929055809975\n",
            "Iter #5140480:  Learning rate = 0.000623:   Batch Loss = 0.353886, Accuracy = 0.955078125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.430074453354, Accuracy = 0.928708076477\n",
            "Iter #5144576:  Learning rate = 0.000623:   Batch Loss = 0.327741, Accuracy = 0.970703125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.43881213665, Accuracy = 0.923143804073\n",
            "Iter #5148672:  Learning rate = 0.000623:   Batch Loss = 0.323644, Accuracy = 0.96484375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.42813616991, Accuracy = 0.931316316128\n",
            "Iter #5152768:  Learning rate = 0.000623:   Batch Loss = 0.348155, Accuracy = 0.958984375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.417166829109, Accuracy = 0.933576762676\n",
            "Iter #5156864:  Learning rate = 0.000623:   Batch Loss = 0.331200, Accuracy = 0.96484375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.418609499931, Accuracy = 0.935141742229\n",
            "Iter #5160960:  Learning rate = 0.000623:   Batch Loss = 0.337641, Accuracy = 0.96484375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.432893186808, Accuracy = 0.928012490273\n",
            "Iter #5165056:  Learning rate = 0.000623:   Batch Loss = 0.343711, Accuracy = 0.958984375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.42555424571, Accuracy = 0.934098422527\n",
            "Iter #5169152:  Learning rate = 0.000623:   Batch Loss = 0.393622, Accuracy = 0.951171875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.427035093307, Accuracy = 0.927316963673\n",
            "Iter #5173248:  Learning rate = 0.000623:   Batch Loss = 0.328260, Accuracy = 0.96875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.421727567911, Accuracy = 0.934793949127\n",
            "Iter #5177344:  Learning rate = 0.000623:   Batch Loss = 0.376270, Accuracy = 0.9375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.443513005972, Accuracy = 0.928012490273\n",
            "Iter #5181440:  Learning rate = 0.000623:   Batch Loss = 0.311319, Accuracy = 0.966796875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.430484235287, Accuracy = 0.926621437073\n",
            "Iter #5185536:  Learning rate = 0.000623:   Batch Loss = 0.349359, Accuracy = 0.94921875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.442629158497, Accuracy = 0.922969937325\n",
            "Iter #5189632:  Learning rate = 0.000623:   Batch Loss = 0.399172, Accuracy = 0.94140625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.428975403309, Accuracy = 0.930968523026\n",
            "Iter #5193728:  Learning rate = 0.000623:   Batch Loss = 0.310074, Accuracy = 0.978515625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.42768740654, Accuracy = 0.930272996426\n",
            "Iter #5197824:  Learning rate = 0.000623:   Batch Loss = 0.309114, Accuracy = 0.97265625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.444141417742, Accuracy = 0.91757953167\n",
            "Iter #5201920:  Learning rate = 0.000599:   Batch Loss = 0.351650, Accuracy = 0.955078125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.439055889845, Accuracy = 0.926447570324\n",
            "Iter #5206016:  Learning rate = 0.000599:   Batch Loss = 0.371270, Accuracy = 0.94921875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.433428525925, Accuracy = 0.929577469826\n",
            "Iter #5210112:  Learning rate = 0.000599:   Batch Loss = 0.337393, Accuracy = 0.96484375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.412452220917, Accuracy = 0.934967815876\n",
            "Iter #5214208:  Learning rate = 0.000599:   Batch Loss = 0.324551, Accuracy = 0.96875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.42381811142, Accuracy = 0.931316316128\n",
            "Iter #5218304:  Learning rate = 0.000599:   Batch Loss = 0.322511, Accuracy = 0.966796875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.414108812809, Accuracy = 0.93914103508\n",
            "Iter #5222400:  Learning rate = 0.000599:   Batch Loss = 0.378057, Accuracy = 0.94140625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.489236950874, Accuracy = 0.902451753616\n",
            "Iter #5226496:  Learning rate = 0.000599:   Batch Loss = 0.389376, Accuracy = 0.93359375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.466069757938, Accuracy = 0.91010260582\n",
            "Iter #5230592:  Learning rate = 0.000599:   Batch Loss = 0.378852, Accuracy = 0.9375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.427638351917, Accuracy = 0.928534150124\n",
            "Iter #5234688:  Learning rate = 0.000599:   Batch Loss = 0.382580, Accuracy = 0.9453125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.424256503582, Accuracy = 0.932881236076\n",
            "Iter #5238784:  Learning rate = 0.000599:   Batch Loss = 0.352854, Accuracy = 0.953125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.433500796556, Accuracy = 0.923491537571\n",
            "Iter #5242880:  Learning rate = 0.000599:   Batch Loss = 0.322860, Accuracy = 0.974609375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.428474605083, Accuracy = 0.931490182877\n",
            "Iter #5246976:  Learning rate = 0.000599:   Batch Loss = 0.355128, Accuracy = 0.95703125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.423596054316, Accuracy = 0.929229676723\n",
            "Iter #5251072:  Learning rate = 0.000599:   Batch Loss = 0.335602, Accuracy = 0.962890625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.420928120613, Accuracy = 0.935315608978\n",
            "Iter #5255168:  Learning rate = 0.000599:   Batch Loss = 0.378507, Accuracy = 0.947265625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.427156478167, Accuracy = 0.934793949127\n",
            "Iter #5259264:  Learning rate = 0.000599:   Batch Loss = 0.366410, Accuracy = 0.95703125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.412686884403, Accuracy = 0.935837268829\n",
            "Iter #5263360:  Learning rate = 0.000599:   Batch Loss = 0.367354, Accuracy = 0.943359375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.44491237402, Accuracy = 0.925752043724\n",
            "Iter #5267456:  Learning rate = 0.000599:   Batch Loss = 0.365010, Accuracy = 0.953125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.445883691311, Accuracy = 0.927490890026\n",
            "Iter #5271552:  Learning rate = 0.000599:   Batch Loss = 0.389448, Accuracy = 0.9453125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.438220441341, Accuracy = 0.924708724022\n",
            "Iter #5275648:  Learning rate = 0.000599:   Batch Loss = 0.374295, Accuracy = 0.94921875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.412240624428, Accuracy = 0.935663342476\n",
            "Iter #5279744:  Learning rate = 0.000599:   Batch Loss = 0.419563, Accuracy = 0.92578125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.434952497482, Accuracy = 0.933402895927\n",
            "Iter #5283840:  Learning rate = 0.000599:   Batch Loss = 0.358653, Accuracy = 0.953125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.458542019129, Accuracy = 0.917405664921\n",
            "Iter #5287936:  Learning rate = 0.000599:   Batch Loss = 0.371074, Accuracy = 0.943359375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.432787239552, Accuracy = 0.929577469826\n",
            "Iter #5292032:  Learning rate = 0.000599:   Batch Loss = 0.416528, Accuracy = 0.939453125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.41792011261, Accuracy = 0.935663342476\n",
            "Iter #5296128:  Learning rate = 0.000599:   Batch Loss = 0.373905, Accuracy = 0.9296875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.425261616707, Accuracy = 0.934446156025\n",
            "Iter #5300224:  Learning rate = 0.000575:   Batch Loss = 0.328459, Accuracy = 0.958984375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.435218751431, Accuracy = 0.923665463924\n",
            "Iter #5304320:  Learning rate = 0.000575:   Batch Loss = 0.355446, Accuracy = 0.951171875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.412698745728, Accuracy = 0.93844550848\n",
            "Iter #5308416:  Learning rate = 0.000575:   Batch Loss = 0.330292, Accuracy = 0.958984375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.424184978008, Accuracy = 0.933576762676\n",
            "Iter #5312512:  Learning rate = 0.000575:   Batch Loss = 0.315280, Accuracy = 0.966796875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.428208351135, Accuracy = 0.929229676723\n",
            "Iter #5316608:  Learning rate = 0.000575:   Batch Loss = 0.320595, Accuracy = 0.97265625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.431613326073, Accuracy = 0.930446863174\n",
            "Iter #5320704:  Learning rate = 0.000575:   Batch Loss = 0.371900, Accuracy = 0.94921875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.419711947441, Accuracy = 0.932707369328\n",
            "Iter #5324800:  Learning rate = 0.000575:   Batch Loss = 0.326263, Accuracy = 0.962890625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.423067063093, Accuracy = 0.930794656277\n",
            "Iter #5328896:  Learning rate = 0.000575:   Batch Loss = 0.326167, Accuracy = 0.9609375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.410484611988, Accuracy = 0.937054395676\n",
            "Iter #5332992:  Learning rate = 0.000575:   Batch Loss = 0.382508, Accuracy = 0.947265625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.418225049973, Accuracy = 0.933924555779\n",
            "Iter #5337088:  Learning rate = 0.000575:   Batch Loss = 0.338620, Accuracy = 0.96484375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.421152770519, Accuracy = 0.935663342476\n",
            "Iter #5341184:  Learning rate = 0.000575:   Batch Loss = 0.345830, Accuracy = 0.962890625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.420973271132, Accuracy = 0.929577469826\n",
            "Iter #5345280:  Learning rate = 0.000575:   Batch Loss = 0.322432, Accuracy = 0.970703125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.408174455166, Accuracy = 0.936532795429\n",
            "Iter #5349376:  Learning rate = 0.000575:   Batch Loss = 0.331900, Accuracy = 0.95703125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.417534351349, Accuracy = 0.937054395676\n",
            "Iter #5353472:  Learning rate = 0.000575:   Batch Loss = 0.329038, Accuracy = 0.96875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.417916744947, Accuracy = 0.931142389774\n",
            "Iter #5357568:  Learning rate = 0.000575:   Batch Loss = 0.331668, Accuracy = 0.95703125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.418189764023, Accuracy = 0.937576055527\n",
            "Iter #5361664:  Learning rate = 0.000575:   Batch Loss = 0.366155, Accuracy = 0.947265625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.43543869257, Accuracy = 0.929925203323\n",
            "Iter #5365760:  Learning rate = 0.000575:   Batch Loss = 0.317260, Accuracy = 0.96875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.442542314529, Accuracy = 0.924013197422\n",
            "Iter #5369856:  Learning rate = 0.000575:   Batch Loss = 0.392194, Accuracy = 0.939453125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.450279682875, Accuracy = 0.926621437073\n",
            "Iter #5373952:  Learning rate = 0.000575:   Batch Loss = 0.380116, Accuracy = 0.953125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.430574774742, Accuracy = 0.926795363426\n",
            "Iter #5378048:  Learning rate = 0.000575:   Batch Loss = 0.405990, Accuracy = 0.9375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.434746980667, Accuracy = 0.932707369328\n",
            "Iter #5382144:  Learning rate = 0.000575:   Batch Loss = 0.359259, Accuracy = 0.95703125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.426511496305, Accuracy = 0.927316963673\n",
            "Iter #5386240:  Learning rate = 0.000575:   Batch Loss = 0.341580, Accuracy = 0.962890625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.416604936123, Accuracy = 0.934620082378\n",
            "Iter #5390336:  Learning rate = 0.000575:   Batch Loss = 0.361936, Accuracy = 0.953125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.448124229908, Accuracy = 0.921057224274\n",
            "Iter #5394432:  Learning rate = 0.000575:   Batch Loss = 0.349178, Accuracy = 0.962890625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.426531165838, Accuracy = 0.932881236076\n",
            "Iter #5398528:  Learning rate = 0.000575:   Batch Loss = 0.317542, Accuracy = 0.97265625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.415508985519, Accuracy = 0.937923848629\n",
            "Iter #5402624:  Learning rate = 0.000552:   Batch Loss = 0.333681, Accuracy = 0.958984375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.428591966629, Accuracy = 0.928881943226\n",
            "Iter #5406720:  Learning rate = 0.000552:   Batch Loss = 0.375058, Accuracy = 0.962890625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.421800732613, Accuracy = 0.933229029179\n",
            "Iter #5410816:  Learning rate = 0.000552:   Batch Loss = 0.349817, Accuracy = 0.95703125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.430910229683, Accuracy = 0.930620789528\n",
            "Iter #5414912:  Learning rate = 0.000552:   Batch Loss = 0.364021, Accuracy = 0.95703125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.449464768171, Accuracy = 0.921404957771\n",
            "Iter #5419008:  Learning rate = 0.000552:   Batch Loss = 0.350556, Accuracy = 0.951171875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.432567775249, Accuracy = 0.934098422527\n",
            "Iter #5423104:  Learning rate = 0.000552:   Batch Loss = 0.355705, Accuracy = 0.947265625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.416144013405, Accuracy = 0.936706662178\n",
            "Iter #5427200:  Learning rate = 0.000552:   Batch Loss = 0.359138, Accuracy = 0.955078125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.427898526192, Accuracy = 0.930446863174\n",
            "Iter #5431296:  Learning rate = 0.000552:   Batch Loss = 0.365797, Accuracy = 0.94921875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.415498077869, Accuracy = 0.936880528927\n",
            "Iter #5435392:  Learning rate = 0.000552:   Batch Loss = 0.354175, Accuracy = 0.95703125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.412550628185, Accuracy = 0.934446156025\n",
            "Iter #5439488:  Learning rate = 0.000552:   Batch Loss = 0.337415, Accuracy = 0.958984375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.416317731142, Accuracy = 0.934098422527\n",
            "Iter #5443584:  Learning rate = 0.000552:   Batch Loss = 0.370283, Accuracy = 0.951171875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.418437808752, Accuracy = 0.931837916374\n",
            "Iter #5447680:  Learning rate = 0.000552:   Batch Loss = 0.318928, Accuracy = 0.974609375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.406547605991, Accuracy = 0.936185002327\n",
            "Iter #5451776:  Learning rate = 0.000552:   Batch Loss = 0.334723, Accuracy = 0.9609375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.412674605846, Accuracy = 0.940705955029\n",
            "Iter #5455872:  Learning rate = 0.000552:   Batch Loss = 0.368039, Accuracy = 0.947265625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.411067724228, Accuracy = 0.93844550848\n",
            "Iter #5459968:  Learning rate = 0.000552:   Batch Loss = 0.319576, Accuracy = 0.970703125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.411291182041, Accuracy = 0.937923848629\n",
            "Iter #5464064:  Learning rate = 0.000552:   Batch Loss = 0.321325, Accuracy = 0.966796875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.439835637808, Accuracy = 0.928881943226\n",
            "Iter #5468160:  Learning rate = 0.000552:   Batch Loss = 0.320209, Accuracy = 0.97265625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.422442615032, Accuracy = 0.933924555779\n",
            "Iter #5472256:  Learning rate = 0.000552:   Batch Loss = 0.321669, Accuracy = 0.970703125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.419560045004, Accuracy = 0.933229029179\n",
            "Iter #5476352:  Learning rate = 0.000552:   Batch Loss = 0.312866, Accuracy = 0.974609375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.417616903782, Accuracy = 0.932707369328\n",
            "Iter #5480448:  Learning rate = 0.000552:   Batch Loss = 0.335460, Accuracy = 0.9609375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.42476272583, Accuracy = 0.930794656277\n",
            "Iter #5484544:  Learning rate = 0.000552:   Batch Loss = 0.310112, Accuracy = 0.97265625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.46432608366, Accuracy = 0.91340637207\n",
            "Iter #5488640:  Learning rate = 0.000552:   Batch Loss = 0.323553, Accuracy = 0.96484375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.417545735836, Accuracy = 0.934272289276\n",
            "Iter #5492736:  Learning rate = 0.000552:   Batch Loss = 0.308384, Accuracy = 0.974609375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.418989449739, Accuracy = 0.934967815876\n",
            "Iter #5496832:  Learning rate = 0.000552:   Batch Loss = 0.318059, Accuracy = 0.97265625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.407454520464, Accuracy = 0.941053748131\n",
            "Iter #5500928:  Learning rate = 0.000530:   Batch Loss = 0.335045, Accuracy = 0.962890625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.407811105251, Accuracy = 0.935663342476\n",
            "Iter #5505024:  Learning rate = 0.000530:   Batch Loss = 0.356033, Accuracy = 0.95703125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.42196649313, Accuracy = 0.934446156025\n",
            "Iter #5509120:  Learning rate = 0.000530:   Batch Loss = 0.332078, Accuracy = 0.96484375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.422284960747, Accuracy = 0.929751336575\n",
            "Iter #5513216:  Learning rate = 0.000530:   Batch Loss = 0.338714, Accuracy = 0.96875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.413745760918, Accuracy = 0.93774998188\n",
            "Iter #5517312:  Learning rate = 0.000530:   Batch Loss = 0.350921, Accuracy = 0.94921875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.412290215492, Accuracy = 0.936011135578\n",
            "Iter #5521408:  Learning rate = 0.000530:   Batch Loss = 0.343500, Accuracy = 0.953125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.419665962458, Accuracy = 0.933576762676\n",
            "Iter #5525504:  Learning rate = 0.000530:   Batch Loss = 0.322532, Accuracy = 0.962890625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.441428273916, Accuracy = 0.930272996426\n",
            "Iter #5529600:  Learning rate = 0.000530:   Batch Loss = 0.334935, Accuracy = 0.9609375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.421759665012, Accuracy = 0.930446863174\n",
            "Iter #5533696:  Learning rate = 0.000530:   Batch Loss = 0.329863, Accuracy = 0.966796875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.426436126232, Accuracy = 0.929229676723\n",
            "Iter #5537792:  Learning rate = 0.000530:   Batch Loss = 0.325974, Accuracy = 0.9609375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.421751141548, Accuracy = 0.933402895927\n",
            "Iter #5541888:  Learning rate = 0.000530:   Batch Loss = 0.341383, Accuracy = 0.95703125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.406687617302, Accuracy = 0.937402188778\n",
            "Iter #5545984:  Learning rate = 0.000530:   Batch Loss = 0.367666, Accuracy = 0.9453125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.416127353907, Accuracy = 0.935141742229\n",
            "Iter #5550080:  Learning rate = 0.000530:   Batch Loss = 0.338021, Accuracy = 0.95703125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.421266436577, Accuracy = 0.933229029179\n",
            "Iter #5554176:  Learning rate = 0.000530:   Batch Loss = 0.319138, Accuracy = 0.970703125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.40930134058, Accuracy = 0.938271582127\n",
            "Iter #5558272:  Learning rate = 0.000530:   Batch Loss = 0.390702, Accuracy = 0.939453125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.428327441216, Accuracy = 0.932185709476\n",
            "Iter #5562368:  Learning rate = 0.000530:   Batch Loss = 0.328561, Accuracy = 0.97265625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.41377466917, Accuracy = 0.936532795429\n",
            "Iter #5566464:  Learning rate = 0.000530:   Batch Loss = 0.347725, Accuracy = 0.9609375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.423742651939, Accuracy = 0.930794656277\n",
            "Iter #5570560:  Learning rate = 0.000530:   Batch Loss = 0.347661, Accuracy = 0.95703125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.404060840607, Accuracy = 0.94053208828\n",
            "Iter #5574656:  Learning rate = 0.000530:   Batch Loss = 0.338830, Accuracy = 0.96484375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.432261019945, Accuracy = 0.929229676723\n",
            "Iter #5578752:  Learning rate = 0.000530:   Batch Loss = 0.335130, Accuracy = 0.95703125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.42429202795, Accuracy = 0.930446863174\n",
            "Iter #5582848:  Learning rate = 0.000530:   Batch Loss = 0.397851, Accuracy = 0.93359375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.419119477272, Accuracy = 0.931837916374\n",
            "Iter #5586944:  Learning rate = 0.000530:   Batch Loss = 0.381726, Accuracy = 0.94921875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.437677621841, Accuracy = 0.930099129677\n",
            "Iter #5591040:  Learning rate = 0.000530:   Batch Loss = 0.353229, Accuracy = 0.9609375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.404170691967, Accuracy = 0.93774998188\n",
            "Iter #5595136:  Learning rate = 0.000530:   Batch Loss = 0.340056, Accuracy = 0.958984375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.410696029663, Accuracy = 0.938967108727\n",
            "Iter #5599232:  Learning rate = 0.000530:   Batch Loss = 0.368047, Accuracy = 0.951171875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.420628547668, Accuracy = 0.934272289276\n",
            "Iter #5603328:  Learning rate = 0.000508:   Batch Loss = 0.302179, Accuracy = 0.9765625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.407957673073, Accuracy = 0.936011135578\n",
            "Iter #5607424:  Learning rate = 0.000508:   Batch Loss = 0.353447, Accuracy = 0.95703125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.417347103357, Accuracy = 0.931837916374\n",
            "Iter #5611520:  Learning rate = 0.000508:   Batch Loss = 0.342304, Accuracy = 0.966796875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.427248358727, Accuracy = 0.934098422527\n",
            "Iter #5615616:  Learning rate = 0.000508:   Batch Loss = 0.333562, Accuracy = 0.94921875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.415224343538, Accuracy = 0.934098422527\n",
            "Iter #5619712:  Learning rate = 0.000508:   Batch Loss = 0.321728, Accuracy = 0.966796875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.407276451588, Accuracy = 0.938271582127\n",
            "Iter #5623808:  Learning rate = 0.000508:   Batch Loss = 0.367037, Accuracy = 0.9453125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.416443407536, Accuracy = 0.930620789528\n",
            "Iter #5627904:  Learning rate = 0.000508:   Batch Loss = 0.331769, Accuracy = 0.9609375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.432708203793, Accuracy = 0.931664049625\n",
            "Iter #5632000:  Learning rate = 0.000508:   Batch Loss = 0.330629, Accuracy = 0.958984375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.426159799099, Accuracy = 0.926447570324\n",
            "Iter #5636096:  Learning rate = 0.000508:   Batch Loss = 0.352058, Accuracy = 0.955078125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.408638715744, Accuracy = 0.937402188778\n",
            "Iter #5640192:  Learning rate = 0.000508:   Batch Loss = 0.322919, Accuracy = 0.955078125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.424933105707, Accuracy = 0.925404250622\n",
            "Iter #5644288:  Learning rate = 0.000508:   Batch Loss = 0.344317, Accuracy = 0.9609375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.412971884012, Accuracy = 0.933576762676\n",
            "Iter #5648384:  Learning rate = 0.000508:   Batch Loss = 0.314308, Accuracy = 0.966796875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.409846305847, Accuracy = 0.936706662178\n",
            "Iter #5652480:  Learning rate = 0.000508:   Batch Loss = 0.316730, Accuracy = 0.96875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.400637328625, Accuracy = 0.941923141479\n",
            "Iter #5656576:  Learning rate = 0.000508:   Batch Loss = 0.318270, Accuracy = 0.966796875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.407445281744, Accuracy = 0.935837268829\n",
            "Iter #5660672:  Learning rate = 0.000508:   Batch Loss = 0.314378, Accuracy = 0.96875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.410280227661, Accuracy = 0.933055102825\n",
            "Iter #5664768:  Learning rate = 0.000508:   Batch Loss = 0.328723, Accuracy = 0.958984375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.414404094219, Accuracy = 0.939662694931\n",
            "Iter #5668864:  Learning rate = 0.000508:   Batch Loss = 0.322121, Accuracy = 0.96484375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.396078646183, Accuracy = 0.93914103508\n",
            "Iter #5672960:  Learning rate = 0.000508:   Batch Loss = 0.332069, Accuracy = 0.97265625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.397918254137, Accuracy = 0.940879821777\n",
            "Iter #5677056:  Learning rate = 0.000508:   Batch Loss = 0.311559, Accuracy = 0.97265625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.413059055805, Accuracy = 0.93774998188\n",
            "Iter #5681152:  Learning rate = 0.000508:   Batch Loss = 0.308850, Accuracy = 0.97265625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.405790507793, Accuracy = 0.936706662178\n",
            "Iter #5685248:  Learning rate = 0.000508:   Batch Loss = 0.312367, Accuracy = 0.96875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.39683920145, Accuracy = 0.941401481628\n",
            "Iter #5689344:  Learning rate = 0.000508:   Batch Loss = 0.297972, Accuracy = 0.978515625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.402638614178, Accuracy = 0.941053748131\n",
            "Iter #5693440:  Learning rate = 0.000508:   Batch Loss = 0.323789, Accuracy = 0.962890625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.411172568798, Accuracy = 0.935141742229\n",
            "Iter #5697536:  Learning rate = 0.000508:   Batch Loss = 0.344642, Accuracy = 0.9609375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.402743279934, Accuracy = 0.937054395676\n",
            "Iter #5701632:  Learning rate = 0.000488:   Batch Loss = 0.305297, Accuracy = 0.966796875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.405633687973, Accuracy = 0.934272289276\n",
            "Iter #5705728:  Learning rate = 0.000488:   Batch Loss = 0.312743, Accuracy = 0.974609375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.410509645939, Accuracy = 0.937054395676\n",
            "Iter #5709824:  Learning rate = 0.000488:   Batch Loss = 0.314145, Accuracy = 0.970703125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.419163525105, Accuracy = 0.931490182877\n",
            "Iter #5713920:  Learning rate = 0.000488:   Batch Loss = 0.324877, Accuracy = 0.96484375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.405627250671, Accuracy = 0.936185002327\n",
            "Iter #5718016:  Learning rate = 0.000488:   Batch Loss = 0.300013, Accuracy = 0.970703125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.40054166317, Accuracy = 0.940184295177\n",
            "Iter #5722112:  Learning rate = 0.000488:   Batch Loss = 0.308732, Accuracy = 0.966796875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.403209328651, Accuracy = 0.936532795429\n",
            "Iter #5726208:  Learning rate = 0.000488:   Batch Loss = 0.322479, Accuracy = 0.95703125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.415153682232, Accuracy = 0.933750629425\n",
            "Iter #5730304:  Learning rate = 0.000488:   Batch Loss = 0.314240, Accuracy = 0.96875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.399485051632, Accuracy = 0.93983656168\n",
            "Iter #5734400:  Learning rate = 0.000488:   Batch Loss = 0.337745, Accuracy = 0.95703125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.40819004178, Accuracy = 0.93844550848\n",
            "Iter #5738496:  Learning rate = 0.000488:   Batch Loss = 0.309450, Accuracy = 0.970703125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.406695663929, Accuracy = 0.936532795429\n",
            "Iter #5742592:  Learning rate = 0.000488:   Batch Loss = 0.322543, Accuracy = 0.966796875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.409048229456, Accuracy = 0.936358869076\n",
            "Iter #5746688:  Learning rate = 0.000488:   Batch Loss = 0.301350, Accuracy = 0.9765625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.406645476818, Accuracy = 0.936532795429\n",
            "Iter #5750784:  Learning rate = 0.000488:   Batch Loss = 0.344552, Accuracy = 0.955078125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.410518527031, Accuracy = 0.938793241978\n",
            "Iter #5754880:  Learning rate = 0.000488:   Batch Loss = 0.350466, Accuracy = 0.955078125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.398985385895, Accuracy = 0.94053208828\n",
            "Iter #5758976:  Learning rate = 0.000488:   Batch Loss = 0.346520, Accuracy = 0.958984375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.403133004904, Accuracy = 0.933055102825\n",
            "Iter #5763072:  Learning rate = 0.000488:   Batch Loss = 0.297418, Accuracy = 0.978515625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.398814201355, Accuracy = 0.941749274731\n",
            "Iter #5767168:  Learning rate = 0.000488:   Batch Loss = 0.305397, Accuracy = 0.96484375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.398612856865, Accuracy = 0.940358221531\n",
            "Iter #5771264:  Learning rate = 0.000488:   Batch Loss = 0.298633, Accuracy = 0.97265625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.397308200598, Accuracy = 0.939488768578\n",
            "Iter #5775360:  Learning rate = 0.000488:   Batch Loss = 0.333755, Accuracy = 0.95703125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.398004591465, Accuracy = 0.941749274731\n",
            "Iter #5779456:  Learning rate = 0.000488:   Batch Loss = 0.305691, Accuracy = 0.974609375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.405863344669, Accuracy = 0.936706662178\n",
            "Iter #5783552:  Learning rate = 0.000488:   Batch Loss = 0.327519, Accuracy = 0.955078125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.401231974363, Accuracy = 0.93914103508\n",
            "Iter #5787648:  Learning rate = 0.000488:   Batch Loss = 0.303220, Accuracy = 0.978515625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.399366796017, Accuracy = 0.93774998188\n",
            "Iter #5791744:  Learning rate = 0.000488:   Batch Loss = 0.320200, Accuracy = 0.970703125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.409053385258, Accuracy = 0.938271582127\n",
            "Iter #5795840:  Learning rate = 0.000488:   Batch Loss = 0.338285, Accuracy = 0.958984375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.402032315731, Accuracy = 0.937228322029\n",
            "Iter #5799936:  Learning rate = 0.000488:   Batch Loss = 0.299829, Accuracy = 0.974609375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.409063786268, Accuracy = 0.936706662178\n",
            "Iter #5804032:  Learning rate = 0.000468:   Batch Loss = 0.311773, Accuracy = 0.966796875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.419894129038, Accuracy = 0.934620082378\n",
            "Iter #5808128:  Learning rate = 0.000468:   Batch Loss = 0.307707, Accuracy = 0.970703125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.396111726761, Accuracy = 0.93914103508\n",
            "Iter #5812224:  Learning rate = 0.000468:   Batch Loss = 0.320248, Accuracy = 0.95703125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.405119717121, Accuracy = 0.935315608978\n",
            "Iter #5816320:  Learning rate = 0.000468:   Batch Loss = 0.323790, Accuracy = 0.966796875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.398593485355, Accuracy = 0.938967108727\n",
            "Iter #5820416:  Learning rate = 0.000468:   Batch Loss = 0.318347, Accuracy = 0.97265625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.408026754856, Accuracy = 0.938793241978\n",
            "Iter #5824512:  Learning rate = 0.000468:   Batch Loss = 0.289874, Accuracy = 0.9765625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.392364382744, Accuracy = 0.93914103508\n",
            "Iter #5828608:  Learning rate = 0.000468:   Batch Loss = 0.324181, Accuracy = 0.96484375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.394525229931, Accuracy = 0.941923141479\n",
            "Iter #5832704:  Learning rate = 0.000468:   Batch Loss = 0.316979, Accuracy = 0.958984375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.403233647346, Accuracy = 0.938097715378\n",
            "Iter #5836800:  Learning rate = 0.000468:   Batch Loss = 0.314787, Accuracy = 0.974609375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.412149608135, Accuracy = 0.937228322029\n",
            "Iter #5840896:  Learning rate = 0.000468:   Batch Loss = 0.326577, Accuracy = 0.96484375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.398445039988, Accuracy = 0.941575407982\n",
            "Iter #5844992:  Learning rate = 0.000468:   Batch Loss = 0.305524, Accuracy = 0.966796875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.391406387091, Accuracy = 0.942444801331\n",
            "Iter #5849088:  Learning rate = 0.000468:   Batch Loss = 0.304798, Accuracy = 0.97265625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.397365897894, Accuracy = 0.938271582127\n",
            "Iter #5853184:  Learning rate = 0.000468:   Batch Loss = 0.304734, Accuracy = 0.970703125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.395389795303, Accuracy = 0.93844550848\n",
            "Iter #5857280:  Learning rate = 0.000468:   Batch Loss = 0.312653, Accuracy = 0.97265625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.39234906435, Accuracy = 0.941923141479\n",
            "Iter #5861376:  Learning rate = 0.000468:   Batch Loss = 0.301440, Accuracy = 0.9765625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.397525668144, Accuracy = 0.94053208828\n",
            "Iter #5865472:  Learning rate = 0.000468:   Batch Loss = 0.310093, Accuracy = 0.966796875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.394786000252, Accuracy = 0.941749274731\n",
            "Iter #5869568:  Learning rate = 0.000468:   Batch Loss = 0.330371, Accuracy = 0.9609375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.399740368128, Accuracy = 0.939314901829\n",
            "Iter #5873664:  Learning rate = 0.000468:   Batch Loss = 0.319828, Accuracy = 0.958984375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.404311776161, Accuracy = 0.937576055527\n",
            "Iter #5877760:  Learning rate = 0.000468:   Batch Loss = 0.308675, Accuracy = 0.966796875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.390995979309, Accuracy = 0.943314194679\n",
            "Iter #5881856:  Learning rate = 0.000468:   Batch Loss = 0.300432, Accuracy = 0.970703125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.401299655437, Accuracy = 0.940358221531\n",
            "Iter #5885952:  Learning rate = 0.000468:   Batch Loss = 0.299199, Accuracy = 0.970703125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.403158545494, Accuracy = 0.936011135578\n",
            "Iter #5890048:  Learning rate = 0.000468:   Batch Loss = 0.298133, Accuracy = 0.974609375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.388646602631, Accuracy = 0.944183647633\n",
            "Iter #5894144:  Learning rate = 0.000468:   Batch Loss = 0.329005, Accuracy = 0.96484375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.393101423979, Accuracy = 0.940705955029\n",
            "Iter #5898240:  Learning rate = 0.000468:   Batch Loss = 0.321877, Accuracy = 0.96484375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.409050941467, Accuracy = 0.933924555779\n",
            "Iter #5902336:  Learning rate = 0.000450:   Batch Loss = 0.314640, Accuracy = 0.974609375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.389680415392, Accuracy = 0.941401481628\n",
            "Iter #5906432:  Learning rate = 0.000450:   Batch Loss = 0.310792, Accuracy = 0.9765625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.396164596081, Accuracy = 0.939314901829\n",
            "Iter #5910528:  Learning rate = 0.000450:   Batch Loss = 0.320411, Accuracy = 0.9609375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.3852186203, Accuracy = 0.942444801331\n",
            "Iter #5914624:  Learning rate = 0.000450:   Batch Loss = 0.310220, Accuracy = 0.96875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.394187450409, Accuracy = 0.940184295177\n",
            "Iter #5918720:  Learning rate = 0.000450:   Batch Loss = 0.290484, Accuracy = 0.96875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.393904626369, Accuracy = 0.940184295177\n",
            "Iter #5922816:  Learning rate = 0.000450:   Batch Loss = 0.311154, Accuracy = 0.96484375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.407979846001, Accuracy = 0.934098422527\n",
            "Iter #5926912:  Learning rate = 0.000450:   Batch Loss = 0.349427, Accuracy = 0.95703125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.389695763588, Accuracy = 0.940705955029\n",
            "Iter #5931008:  Learning rate = 0.000450:   Batch Loss = 0.314028, Accuracy = 0.96484375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.396574467421, Accuracy = 0.93983656168\n",
            "Iter #5935104:  Learning rate = 0.000450:   Batch Loss = 0.316252, Accuracy = 0.970703125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.393849730492, Accuracy = 0.940705955029\n",
            "Iter #5939200:  Learning rate = 0.000450:   Batch Loss = 0.295474, Accuracy = 0.978515625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.400008440018, Accuracy = 0.936532795429\n",
            "Iter #5943296:  Learning rate = 0.000450:   Batch Loss = 0.331695, Accuracy = 0.96484375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.394639790058, Accuracy = 0.939488768578\n",
            "Iter #5947392:  Learning rate = 0.000450:   Batch Loss = 0.334905, Accuracy = 0.95703125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.406002938747, Accuracy = 0.938619375229\n",
            "Iter #5951488:  Learning rate = 0.000450:   Batch Loss = 0.295439, Accuracy = 0.974609375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.392043292522, Accuracy = 0.93983656168\n",
            "Iter #5955584:  Learning rate = 0.000450:   Batch Loss = 0.284776, Accuracy = 0.98046875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.394117176533, Accuracy = 0.937576055527\n",
            "Iter #5959680:  Learning rate = 0.000450:   Batch Loss = 0.350606, Accuracy = 0.94140625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.405733823776, Accuracy = 0.938619375229\n",
            "Iter #5963776:  Learning rate = 0.000450:   Batch Loss = 0.294432, Accuracy = 0.9765625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.408504366875, Accuracy = 0.932533442974\n",
            "Iter #5967872:  Learning rate = 0.000450:   Batch Loss = 0.327723, Accuracy = 0.96875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.408228397369, Accuracy = 0.93983656168\n",
            "Iter #5971968:  Learning rate = 0.000450:   Batch Loss = 0.290433, Accuracy = 0.974609375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.409414172173, Accuracy = 0.934620082378\n",
            "Iter #5976064:  Learning rate = 0.000450:   Batch Loss = 0.322597, Accuracy = 0.955078125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.405423998833, Accuracy = 0.940010428429\n",
            "Iter #5980160:  Learning rate = 0.000450:   Batch Loss = 0.316135, Accuracy = 0.970703125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.39402538538, Accuracy = 0.941401481628\n",
            "Iter #5984256:  Learning rate = 0.000450:   Batch Loss = 0.333012, Accuracy = 0.95703125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.396737396717, Accuracy = 0.941053748131\n",
            "Iter #5988352:  Learning rate = 0.000450:   Batch Loss = 0.295427, Accuracy = 0.98046875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.38842317462, Accuracy = 0.942792534828\n",
            "Iter #5992448:  Learning rate = 0.000450:   Batch Loss = 0.304890, Accuracy = 0.978515625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.391675949097, Accuracy = 0.940705955029\n",
            "Iter #5996544:  Learning rate = 0.000450:   Batch Loss = 0.310849, Accuracy = 0.97265625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.397602975368, Accuracy = 0.939488768578\n",
            "Iter #6000640:  Learning rate = 0.000432:   Batch Loss = 0.289637, Accuracy = 0.9765625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.398639380932, Accuracy = 0.936185002327\n",
            "Iter #6004736:  Learning rate = 0.000432:   Batch Loss = 0.346722, Accuracy = 0.958984375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.392410755157, Accuracy = 0.941923141479\n",
            "Iter #6008832:  Learning rate = 0.000432:   Batch Loss = 0.311559, Accuracy = 0.9609375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.406894505024, Accuracy = 0.932881236076\n",
            "Iter #6012928:  Learning rate = 0.000432:   Batch Loss = 0.322031, Accuracy = 0.96484375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.405710965395, Accuracy = 0.93774998188\n",
            "Iter #6017024:  Learning rate = 0.000432:   Batch Loss = 0.317248, Accuracy = 0.966796875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.395746946335, Accuracy = 0.940184295177\n",
            "Iter #6021120:  Learning rate = 0.000432:   Batch Loss = 0.302381, Accuracy = 0.966796875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.40528512001, Accuracy = 0.937228322029\n",
            "Iter #6025216:  Learning rate = 0.000432:   Batch Loss = 0.298801, Accuracy = 0.966796875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.388386845589, Accuracy = 0.94314032793\n",
            "Iter #6029312:  Learning rate = 0.000432:   Batch Loss = 0.335498, Accuracy = 0.962890625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.395942270756, Accuracy = 0.940184295177\n",
            "Iter #6033408:  Learning rate = 0.000432:   Batch Loss = 0.317783, Accuracy = 0.966796875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.390073299408, Accuracy = 0.943661987782\n",
            "Iter #6037504:  Learning rate = 0.000432:   Batch Loss = 0.297270, Accuracy = 0.982421875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.397333085537, Accuracy = 0.940358221531\n",
            "Iter #6041600:  Learning rate = 0.000432:   Batch Loss = 0.300940, Accuracy = 0.974609375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.398897886276, Accuracy = 0.940358221531\n",
            "Iter #6045696:  Learning rate = 0.000432:   Batch Loss = 0.307077, Accuracy = 0.974609375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.395934790373, Accuracy = 0.939488768578\n",
            "Iter #6049792:  Learning rate = 0.000432:   Batch Loss = 0.319815, Accuracy = 0.96875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.384731829166, Accuracy = 0.943661987782\n",
            "Iter #6053888:  Learning rate = 0.000432:   Batch Loss = 0.317963, Accuracy = 0.958984375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.390316724777, Accuracy = 0.940705955029\n",
            "Iter #6057984:  Learning rate = 0.000432:   Batch Loss = 0.307913, Accuracy = 0.966796875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.411877095699, Accuracy = 0.934098422527\n",
            "Iter #6062080:  Learning rate = 0.000432:   Batch Loss = 0.310329, Accuracy = 0.974609375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.395245790482, Accuracy = 0.938271582127\n",
            "Iter #6066176:  Learning rate = 0.000432:   Batch Loss = 0.331202, Accuracy = 0.953125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.383302122355, Accuracy = 0.942792534828\n",
            "Iter #6070272:  Learning rate = 0.000432:   Batch Loss = 0.283952, Accuracy = 0.974609375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.392315208912, Accuracy = 0.94383585453\n",
            "Iter #6074368:  Learning rate = 0.000432:   Batch Loss = 0.300135, Accuracy = 0.974609375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.394615203142, Accuracy = 0.93914103508\n",
            "Iter #6078464:  Learning rate = 0.000432:   Batch Loss = 0.285846, Accuracy = 0.978515625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.387407720089, Accuracy = 0.941749274731\n",
            "Iter #6082560:  Learning rate = 0.000432:   Batch Loss = 0.290889, Accuracy = 0.98046875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.392371624708, Accuracy = 0.941401481628\n",
            "Iter #6086656:  Learning rate = 0.000432:   Batch Loss = 0.309385, Accuracy = 0.96875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.406562209129, Accuracy = 0.939488768578\n",
            "Iter #6090752:  Learning rate = 0.000432:   Batch Loss = 0.325726, Accuracy = 0.953125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.400209009647, Accuracy = 0.937923848629\n",
            "Iter #6094848:  Learning rate = 0.000432:   Batch Loss = 0.300488, Accuracy = 0.970703125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.392246723175, Accuracy = 0.937576055527\n",
            "Iter #6098944:  Learning rate = 0.000432:   Batch Loss = 0.306810, Accuracy = 0.970703125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.390739619732, Accuracy = 0.943488061428\n",
            "Iter #6103040:  Learning rate = 0.000414:   Batch Loss = 0.284953, Accuracy = 0.984375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.400610208511, Accuracy = 0.938793241978\n",
            "Iter #6107136:  Learning rate = 0.000414:   Batch Loss = 0.301430, Accuracy = 0.970703125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.398730099201, Accuracy = 0.942792534828\n",
            "Iter #6111232:  Learning rate = 0.000414:   Batch Loss = 0.318500, Accuracy = 0.96484375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.3889721632, Accuracy = 0.93844550848\n",
            "Iter #6115328:  Learning rate = 0.000414:   Batch Loss = 0.296845, Accuracy = 0.970703125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.385239541531, Accuracy = 0.942270934582\n",
            "Iter #6119424:  Learning rate = 0.000414:   Batch Loss = 0.313024, Accuracy = 0.96875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.387009501457, Accuracy = 0.941053748131\n",
            "Iter #6123520:  Learning rate = 0.000414:   Batch Loss = 0.277266, Accuracy = 0.982421875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.398568034172, Accuracy = 0.939662694931\n",
            "Iter #6127616:  Learning rate = 0.000414:   Batch Loss = 0.293556, Accuracy = 0.970703125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.393831312656, Accuracy = 0.938097715378\n",
            "Iter #6131712:  Learning rate = 0.000414:   Batch Loss = 0.328235, Accuracy = 0.962890625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.396382451057, Accuracy = 0.93914103508\n",
            "Iter #6135808:  Learning rate = 0.000414:   Batch Loss = 0.322802, Accuracy = 0.962890625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.403868377209, Accuracy = 0.937923848629\n",
            "Iter #6139904:  Learning rate = 0.000414:   Batch Loss = 0.311645, Accuracy = 0.96484375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.385437428951, Accuracy = 0.940010428429\n",
            "Iter #6144000:  Learning rate = 0.000414:   Batch Loss = 0.297704, Accuracy = 0.96875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.391609102488, Accuracy = 0.942097008228\n",
            "Iter #6148096:  Learning rate = 0.000414:   Batch Loss = 0.310643, Accuracy = 0.96484375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.388343751431, Accuracy = 0.942444801331\n",
            "Iter #6152192:  Learning rate = 0.000414:   Batch Loss = 0.328376, Accuracy = 0.962890625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.414099395275, Accuracy = 0.932185709476\n",
            "Iter #6156288:  Learning rate = 0.000414:   Batch Loss = 0.335479, Accuracy = 0.95703125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.41502392292, Accuracy = 0.933229029179\n",
            "Iter #6160384:  Learning rate = 0.000414:   Batch Loss = 0.316630, Accuracy = 0.962890625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.391285061836, Accuracy = 0.940705955029\n",
            "Iter #6164480:  Learning rate = 0.000414:   Batch Loss = 0.298786, Accuracy = 0.96875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.38742005825, Accuracy = 0.94053208828\n",
            "Iter #6168576:  Learning rate = 0.000414:   Batch Loss = 0.301940, Accuracy = 0.97265625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.393364757299, Accuracy = 0.942097008228\n",
            "Iter #6172672:  Learning rate = 0.000414:   Batch Loss = 0.309333, Accuracy = 0.966796875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.396178543568, Accuracy = 0.935141742229\n",
            "Iter #6176768:  Learning rate = 0.000414:   Batch Loss = 0.306086, Accuracy = 0.97265625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.396791338921, Accuracy = 0.942270934582\n",
            "Iter #6180864:  Learning rate = 0.000414:   Batch Loss = 0.282201, Accuracy = 0.98046875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.388052046299, Accuracy = 0.941401481628\n",
            "Iter #6184960:  Learning rate = 0.000414:   Batch Loss = 0.292518, Accuracy = 0.982421875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.395159840584, Accuracy = 0.939662694931\n",
            "Iter #6189056:  Learning rate = 0.000414:   Batch Loss = 0.302916, Accuracy = 0.966796875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.388023495674, Accuracy = 0.940010428429\n",
            "Iter #6193152:  Learning rate = 0.000414:   Batch Loss = 0.302072, Accuracy = 0.96875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.38933378458, Accuracy = 0.942444801331\n",
            "Iter #6197248:  Learning rate = 0.000414:   Batch Loss = 0.294648, Accuracy = 0.970703125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.394297897816, Accuracy = 0.94053208828\n",
            "Iter #6201344:  Learning rate = 0.000398:   Batch Loss = 0.312644, Accuracy = 0.97265625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.390735387802, Accuracy = 0.938097715378\n",
            "Iter #6205440:  Learning rate = 0.000398:   Batch Loss = 0.316064, Accuracy = 0.970703125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.369788169861, Accuracy = 0.944009721279\n",
            "Iter #6209536:  Learning rate = 0.000398:   Batch Loss = 0.334556, Accuracy = 0.95703125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.389967083931, Accuracy = 0.941923141479\n",
            "Iter #6213632:  Learning rate = 0.000398:   Batch Loss = 0.303048, Accuracy = 0.98046875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.387642383575, Accuracy = 0.937576055527\n",
            "Iter #6217728:  Learning rate = 0.000398:   Batch Loss = 0.275327, Accuracy = 0.986328125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.3872833848, Accuracy = 0.94122761488\n",
            "Iter #6221824:  Learning rate = 0.000398:   Batch Loss = 0.311700, Accuracy = 0.96484375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.389525651932, Accuracy = 0.94053208828\n",
            "Iter #6225920:  Learning rate = 0.000398:   Batch Loss = 0.313318, Accuracy = 0.970703125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.391330301762, Accuracy = 0.941749274731\n",
            "Iter #6230016:  Learning rate = 0.000398:   Batch Loss = 0.299886, Accuracy = 0.970703125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.394664049149, Accuracy = 0.94122761488\n",
            "Iter #6234112:  Learning rate = 0.000398:   Batch Loss = 0.337317, Accuracy = 0.953125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.389951050282, Accuracy = 0.941053748131\n",
            "Iter #6238208:  Learning rate = 0.000398:   Batch Loss = 0.316377, Accuracy = 0.966796875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.388232469559, Accuracy = 0.941749274731\n",
            "Iter #6242304:  Learning rate = 0.000398:   Batch Loss = 0.315363, Accuracy = 0.970703125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.396430253983, Accuracy = 0.937923848629\n",
            "Iter #6246400:  Learning rate = 0.000398:   Batch Loss = 0.295345, Accuracy = 0.974609375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.396139800549, Accuracy = 0.93983656168\n",
            "Iter #6250496:  Learning rate = 0.000398:   Batch Loss = 0.311373, Accuracy = 0.96484375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.390292316675, Accuracy = 0.94122761488\n",
            "Iter #6254592:  Learning rate = 0.000398:   Batch Loss = 0.311974, Accuracy = 0.96484375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.387082636356, Accuracy = 0.942270934582\n",
            "Iter #6258688:  Learning rate = 0.000398:   Batch Loss = 0.318345, Accuracy = 0.96484375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.386442363262, Accuracy = 0.940705955029\n",
            "Iter #6262784:  Learning rate = 0.000398:   Batch Loss = 0.283848, Accuracy = 0.974609375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.386707484722, Accuracy = 0.944009721279\n",
            "Iter #6266880:  Learning rate = 0.000398:   Batch Loss = 0.290226, Accuracy = 0.98046875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.382370114326, Accuracy = 0.942618668079\n",
            "Iter #6270976:  Learning rate = 0.000398:   Batch Loss = 0.296995, Accuracy = 0.9765625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.393064886332, Accuracy = 0.939662694931\n",
            "Iter #6275072:  Learning rate = 0.000398:   Batch Loss = 0.287208, Accuracy = 0.978515625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.388633131981, Accuracy = 0.939488768578\n",
            "Iter #6279168:  Learning rate = 0.000398:   Batch Loss = 0.299040, Accuracy = 0.96875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.385301440954, Accuracy = 0.942966461182\n",
            "Iter #6283264:  Learning rate = 0.000398:   Batch Loss = 0.298893, Accuracy = 0.9765625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.381556302309, Accuracy = 0.942618668079\n",
            "Iter #6287360:  Learning rate = 0.000398:   Batch Loss = 0.305296, Accuracy = 0.970703125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.389421194792, Accuracy = 0.941575407982\n",
            "Iter #6291456:  Learning rate = 0.000398:   Batch Loss = 0.295490, Accuracy = 0.978515625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.380609989166, Accuracy = 0.945400774479\n",
            "Iter #6295552:  Learning rate = 0.000398:   Batch Loss = 0.282275, Accuracy = 0.98046875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.394929528236, Accuracy = 0.93844550848\n",
            "Iter #6299648:  Learning rate = 0.000398:   Batch Loss = 0.299582, Accuracy = 0.970703125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.400851845741, Accuracy = 0.942270934582\n",
            "Iter #6303744:  Learning rate = 0.000382:   Batch Loss = 0.309443, Accuracy = 0.966796875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.379978060722, Accuracy = 0.942618668079\n",
            "Iter #6307840:  Learning rate = 0.000382:   Batch Loss = 0.319530, Accuracy = 0.95703125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.38041049242, Accuracy = 0.945053040981\n",
            "Iter #6311936:  Learning rate = 0.000382:   Batch Loss = 0.304125, Accuracy = 0.970703125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.384735763073, Accuracy = 0.942270934582\n",
            "Iter #6316032:  Learning rate = 0.000382:   Batch Loss = 0.283017, Accuracy = 0.982421875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.386637747288, Accuracy = 0.942966461182\n",
            "Iter #6320128:  Learning rate = 0.000382:   Batch Loss = 0.289900, Accuracy = 0.9765625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.383992880583, Accuracy = 0.943661987782\n",
            "Iter #6324224:  Learning rate = 0.000382:   Batch Loss = 0.321055, Accuracy = 0.96484375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.37973934412, Accuracy = 0.94522690773\n",
            "Iter #6328320:  Learning rate = 0.000382:   Batch Loss = 0.329712, Accuracy = 0.9609375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.379223763943, Accuracy = 0.946791887283\n",
            "Iter #6332416:  Learning rate = 0.000382:   Batch Loss = 0.307650, Accuracy = 0.966796875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.390528976917, Accuracy = 0.941575407982\n",
            "Iter #6336512:  Learning rate = 0.000382:   Batch Loss = 0.294075, Accuracy = 0.96875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.392105281353, Accuracy = 0.94053208828\n",
            "Iter #6340608:  Learning rate = 0.000382:   Batch Loss = 0.316901, Accuracy = 0.962890625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.390759289265, Accuracy = 0.938967108727\n",
            "Iter #6344704:  Learning rate = 0.000382:   Batch Loss = 0.299731, Accuracy = 0.974609375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.392804324627, Accuracy = 0.94314032793\n",
            "Iter #6348800:  Learning rate = 0.000382:   Batch Loss = 0.292094, Accuracy = 0.97265625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.3969848454, Accuracy = 0.936706662178\n",
            "Iter #6352896:  Learning rate = 0.000382:   Batch Loss = 0.303765, Accuracy = 0.96875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.382511198521, Accuracy = 0.944705247879\n",
            "Iter #6356992:  Learning rate = 0.000382:   Batch Loss = 0.306535, Accuracy = 0.9765625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.388972908258, Accuracy = 0.940010428429\n",
            "Iter #6361088:  Learning rate = 0.000382:   Batch Loss = 0.283192, Accuracy = 0.97265625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.390734791756, Accuracy = 0.943661987782\n",
            "Iter #6365184:  Learning rate = 0.000382:   Batch Loss = 0.272502, Accuracy = 0.984375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.385221332312, Accuracy = 0.942270934582\n",
            "Iter #6369280:  Learning rate = 0.000382:   Batch Loss = 0.267628, Accuracy = 0.986328125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.386770546436, Accuracy = 0.941053748131\n",
            "Iter #6373376:  Learning rate = 0.000382:   Batch Loss = 0.297006, Accuracy = 0.974609375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.38352444768, Accuracy = 0.944183647633\n",
            "Iter #6377472:  Learning rate = 0.000382:   Batch Loss = 0.314530, Accuracy = 0.958984375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.394467949867, Accuracy = 0.93914103508\n",
            "Iter #6381568:  Learning rate = 0.000382:   Batch Loss = 0.324190, Accuracy = 0.95703125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.402964413166, Accuracy = 0.936358869076\n",
            "Iter #6385664:  Learning rate = 0.000382:   Batch Loss = 0.292609, Accuracy = 0.974609375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.379428654909, Accuracy = 0.94314032793\n",
            "Iter #6389760:  Learning rate = 0.000382:   Batch Loss = 0.313286, Accuracy = 0.9609375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.394536316395, Accuracy = 0.938793241978\n",
            "Iter #6393856:  Learning rate = 0.000382:   Batch Loss = 0.293582, Accuracy = 0.970703125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.403328001499, Accuracy = 0.938619375229\n",
            "Iter #6397952:  Learning rate = 0.000382:   Batch Loss = 0.287787, Accuracy = 0.982421875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.391185760498, Accuracy = 0.938793241978\n",
            "Iter #6402048:  Learning rate = 0.000367:   Batch Loss = 0.306068, Accuracy = 0.970703125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.3835927248, Accuracy = 0.94453138113\n",
            "Iter #6406144:  Learning rate = 0.000367:   Batch Loss = 0.286425, Accuracy = 0.98046875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.39009770751, Accuracy = 0.941923141479\n",
            "Iter #6410240:  Learning rate = 0.000367:   Batch Loss = 0.318264, Accuracy = 0.96484375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.39249765873, Accuracy = 0.94053208828\n",
            "Iter #6414336:  Learning rate = 0.000367:   Batch Loss = 0.303512, Accuracy = 0.96875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.388510942459, Accuracy = 0.94453138113\n",
            "Iter #6418432:  Learning rate = 0.000367:   Batch Loss = 0.304919, Accuracy = 0.962890625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.386725723743, Accuracy = 0.943314194679\n",
            "Iter #6422528:  Learning rate = 0.000367:   Batch Loss = 0.302735, Accuracy = 0.96484375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.391855955124, Accuracy = 0.940705955029\n",
            "Iter #6426624:  Learning rate = 0.000367:   Batch Loss = 0.287859, Accuracy = 0.9765625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.393838852644, Accuracy = 0.93914103508\n",
            "Iter #6430720:  Learning rate = 0.000367:   Batch Loss = 0.303774, Accuracy = 0.974609375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.383419036865, Accuracy = 0.94383585453\n",
            "Iter #6434816:  Learning rate = 0.000367:   Batch Loss = 0.290552, Accuracy = 0.9765625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.38234141469, Accuracy = 0.943661987782\n",
            "Iter #6438912:  Learning rate = 0.000367:   Batch Loss = 0.304918, Accuracy = 0.96875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.391034662724, Accuracy = 0.940358221531\n",
            "Iter #6443008:  Learning rate = 0.000367:   Batch Loss = 0.310161, Accuracy = 0.962890625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.388480424881, Accuracy = 0.941749274731\n",
            "Iter #6447104:  Learning rate = 0.000367:   Batch Loss = 0.273142, Accuracy = 0.98046875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.382017195225, Accuracy = 0.94314032793\n",
            "Iter #6451200:  Learning rate = 0.000367:   Batch Loss = 0.290989, Accuracy = 0.970703125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.383213639259, Accuracy = 0.943314194679\n",
            "Iter #6455296:  Learning rate = 0.000367:   Batch Loss = 0.293499, Accuracy = 0.96875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.392274439335, Accuracy = 0.942444801331\n",
            "Iter #6459392:  Learning rate = 0.000367:   Batch Loss = 0.303580, Accuracy = 0.9765625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.401941299438, Accuracy = 0.937228322029\n",
            "Iter #6463488:  Learning rate = 0.000367:   Batch Loss = 0.279176, Accuracy = 0.978515625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.39441716671, Accuracy = 0.941053748131\n",
            "Iter #6467584:  Learning rate = 0.000367:   Batch Loss = 0.308505, Accuracy = 0.970703125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.380564928055, Accuracy = 0.941923141479\n",
            "Iter #6471680:  Learning rate = 0.000367:   Batch Loss = 0.278777, Accuracy = 0.98046875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.389968693256, Accuracy = 0.941923141479\n",
            "Iter #6475776:  Learning rate = 0.000367:   Batch Loss = 0.293922, Accuracy = 0.97265625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.378676712513, Accuracy = 0.941923141479\n",
            "Iter #6479872:  Learning rate = 0.000367:   Batch Loss = 0.294214, Accuracy = 0.9765625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.388449281454, Accuracy = 0.944183647633\n",
            "Iter #6483968:  Learning rate = 0.000367:   Batch Loss = 0.332689, Accuracy = 0.958984375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.380626767874, Accuracy = 0.943314194679\n",
            "Iter #6488064:  Learning rate = 0.000367:   Batch Loss = 0.300754, Accuracy = 0.96875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.381476581097, Accuracy = 0.941575407982\n",
            "Iter #6492160:  Learning rate = 0.000367:   Batch Loss = 0.297664, Accuracy = 0.962890625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.381645262241, Accuracy = 0.94453138113\n",
            "Iter #6496256:  Learning rate = 0.000367:   Batch Loss = 0.311101, Accuracy = 0.970703125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.376674413681, Accuracy = 0.94383585453\n",
            "Iter #6500352:  Learning rate = 0.000352:   Batch Loss = 0.321696, Accuracy = 0.96484375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.380339562893, Accuracy = 0.944705247879\n",
            "Iter #6504448:  Learning rate = 0.000352:   Batch Loss = 0.294841, Accuracy = 0.96875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.380816280842, Accuracy = 0.94314032793\n",
            "Iter #6508544:  Learning rate = 0.000352:   Batch Loss = 0.315904, Accuracy = 0.966796875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.380552828312, Accuracy = 0.942618668079\n",
            "Iter #6512640:  Learning rate = 0.000352:   Batch Loss = 0.325054, Accuracy = 0.95703125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.38485378027, Accuracy = 0.942444801331\n",
            "Iter #6516736:  Learning rate = 0.000352:   Batch Loss = 0.299952, Accuracy = 0.97265625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.386046856642, Accuracy = 0.938619375229\n",
            "Iter #6520832:  Learning rate = 0.000352:   Batch Loss = 0.301074, Accuracy = 0.970703125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.390765190125, Accuracy = 0.94122761488\n",
            "Iter #6524928:  Learning rate = 0.000352:   Batch Loss = 0.301264, Accuracy = 0.96484375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.385887920856, Accuracy = 0.941575407982\n",
            "Iter #6529024:  Learning rate = 0.000352:   Batch Loss = 0.272153, Accuracy = 0.978515625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.384611606598, Accuracy = 0.94122761488\n",
            "Iter #6533120:  Learning rate = 0.000352:   Batch Loss = 0.346498, Accuracy = 0.94921875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.380756556988, Accuracy = 0.945400774479\n",
            "Iter #6537216:  Learning rate = 0.000352:   Batch Loss = 0.309714, Accuracy = 0.966796875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.379694581032, Accuracy = 0.942097008228\n",
            "Iter #6541312:  Learning rate = 0.000352:   Batch Loss = 0.293298, Accuracy = 0.97265625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.391381502151, Accuracy = 0.94122761488\n",
            "Iter #6545408:  Learning rate = 0.000352:   Batch Loss = 0.298367, Accuracy = 0.974609375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.386612355709, Accuracy = 0.939314901829\n",
            "Iter #6549504:  Learning rate = 0.000352:   Batch Loss = 0.303782, Accuracy = 0.96484375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.387540519238, Accuracy = 0.942618668079\n",
            "Iter #6553600:  Learning rate = 0.000352:   Batch Loss = 0.302643, Accuracy = 0.96484375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.381769686937, Accuracy = 0.942792534828\n",
            "Iter #6557696:  Learning rate = 0.000352:   Batch Loss = 0.292113, Accuracy = 0.97265625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.392990291119, Accuracy = 0.936880528927\n",
            "Iter #6561792:  Learning rate = 0.000352:   Batch Loss = 0.277041, Accuracy = 0.98046875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.384901493788, Accuracy = 0.94453138113\n",
            "Iter #6565888:  Learning rate = 0.000352:   Batch Loss = 0.279689, Accuracy = 0.978515625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.370571047068, Accuracy = 0.94731348753\n",
            "Iter #6569984:  Learning rate = 0.000352:   Batch Loss = 0.331331, Accuracy = 0.9609375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.379300922155, Accuracy = 0.947661280632\n",
            "Iter #6574080:  Learning rate = 0.000352:   Batch Loss = 0.303597, Accuracy = 0.966796875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.384731292725, Accuracy = 0.94122761488\n",
            "Iter #6578176:  Learning rate = 0.000352:   Batch Loss = 0.277231, Accuracy = 0.982421875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.397400170565, Accuracy = 0.93983656168\n",
            "Iter #6582272:  Learning rate = 0.000352:   Batch Loss = 0.335153, Accuracy = 0.958984375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.397341370583, Accuracy = 0.938793241978\n",
            "Iter #6586368:  Learning rate = 0.000352:   Batch Loss = 0.325973, Accuracy = 0.966796875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.383688092232, Accuracy = 0.940358221531\n",
            "Iter #6590464:  Learning rate = 0.000352:   Batch Loss = 0.342406, Accuracy = 0.95703125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.39564293623, Accuracy = 0.938271582127\n",
            "Iter #6594560:  Learning rate = 0.000352:   Batch Loss = 0.292629, Accuracy = 0.974609375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.378987103701, Accuracy = 0.944183647633\n",
            "Iter #6598656:  Learning rate = 0.000352:   Batch Loss = 0.287795, Accuracy = 0.974609375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.391952931881, Accuracy = 0.936706662178\n",
            "Iter #6602752:  Learning rate = 0.000338:   Batch Loss = 0.272063, Accuracy = 0.984375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.387004822493, Accuracy = 0.941923141479\n",
            "Iter #6606848:  Learning rate = 0.000338:   Batch Loss = 0.292847, Accuracy = 0.96875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.391087502241, Accuracy = 0.935663342476\n",
            "Iter #6610944:  Learning rate = 0.000338:   Batch Loss = 0.307227, Accuracy = 0.97265625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.382078647614, Accuracy = 0.941053748131\n",
            "Iter #6615040:  Learning rate = 0.000338:   Batch Loss = 0.326525, Accuracy = 0.96484375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.385513305664, Accuracy = 0.938619375229\n",
            "Iter #6619136:  Learning rate = 0.000338:   Batch Loss = 0.296887, Accuracy = 0.96484375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.390382796526, Accuracy = 0.942792534828\n",
            "Iter #6623232:  Learning rate = 0.000338:   Batch Loss = 0.307151, Accuracy = 0.974609375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.3767991364, Accuracy = 0.945053040981\n",
            "Iter #6627328:  Learning rate = 0.000338:   Batch Loss = 0.272354, Accuracy = 0.982421875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.382996082306, Accuracy = 0.944183647633\n",
            "Iter #6631424:  Learning rate = 0.000338:   Batch Loss = 0.286002, Accuracy = 0.978515625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.384948253632, Accuracy = 0.941749274731\n",
            "Iter #6635520:  Learning rate = 0.000338:   Batch Loss = 0.311878, Accuracy = 0.970703125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.38665252924, Accuracy = 0.940184295177\n",
            "Iter #6639616:  Learning rate = 0.000338:   Batch Loss = 0.306252, Accuracy = 0.970703125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.386944293976, Accuracy = 0.941923141479\n",
            "Iter #6643712:  Learning rate = 0.000338:   Batch Loss = 0.295241, Accuracy = 0.966796875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.375606238842, Accuracy = 0.944183647633\n",
            "Iter #6647808:  Learning rate = 0.000338:   Batch Loss = 0.280286, Accuracy = 0.98046875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.365498304367, Accuracy = 0.947139620781\n",
            "Iter #6651904:  Learning rate = 0.000338:   Batch Loss = 0.293533, Accuracy = 0.97265625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.383698105812, Accuracy = 0.94122761488\n",
            "Iter #6656000:  Learning rate = 0.000338:   Batch Loss = 0.303977, Accuracy = 0.974609375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.390009582043, Accuracy = 0.939314901829\n",
            "Iter #6660096:  Learning rate = 0.000338:   Batch Loss = 0.323579, Accuracy = 0.96484375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.388957053423, Accuracy = 0.936185002327\n",
            "Iter #6664192:  Learning rate = 0.000338:   Batch Loss = 0.314769, Accuracy = 0.958984375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.381352543831, Accuracy = 0.942618668079\n",
            "Iter #6668288:  Learning rate = 0.000338:   Batch Loss = 0.284904, Accuracy = 0.974609375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.374299705029, Accuracy = 0.94383585453\n",
            "Iter #6672384:  Learning rate = 0.000338:   Batch Loss = 0.284702, Accuracy = 0.982421875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.371451616287, Accuracy = 0.94522690773\n",
            "Iter #6676480:  Learning rate = 0.000338:   Batch Loss = 0.293290, Accuracy = 0.9609375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.380581796169, Accuracy = 0.942270934582\n",
            "Iter #6680576:  Learning rate = 0.000338:   Batch Loss = 0.305231, Accuracy = 0.966796875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.380166471004, Accuracy = 0.944183647633\n",
            "Iter #6684672:  Learning rate = 0.000338:   Batch Loss = 0.287083, Accuracy = 0.96875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.378944158554, Accuracy = 0.942097008228\n",
            "Iter #6688768:  Learning rate = 0.000338:   Batch Loss = 0.300530, Accuracy = 0.970703125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.372562050819, Accuracy = 0.945574700832\n",
            "Iter #6692864:  Learning rate = 0.000338:   Batch Loss = 0.277320, Accuracy = 0.978515625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.374682128429, Accuracy = 0.943314194679\n",
            "Iter #6696960:  Learning rate = 0.000338:   Batch Loss = 0.320545, Accuracy = 0.962890625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.379165172577, Accuracy = 0.942618668079\n",
            "Iter #6701056:  Learning rate = 0.000324:   Batch Loss = 0.321398, Accuracy = 0.962890625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.382240712643, Accuracy = 0.941401481628\n",
            "Iter #6705152:  Learning rate = 0.000324:   Batch Loss = 0.293689, Accuracy = 0.96875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.385638177395, Accuracy = 0.941575407982\n",
            "Iter #6709248:  Learning rate = 0.000324:   Batch Loss = 0.311463, Accuracy = 0.958984375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.3787753582, Accuracy = 0.942618668079\n",
            "Iter #6713344:  Learning rate = 0.000324:   Batch Loss = 0.275798, Accuracy = 0.986328125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.377848774195, Accuracy = 0.945053040981\n",
            "Iter #6717440:  Learning rate = 0.000324:   Batch Loss = 0.290936, Accuracy = 0.9765625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.384742647409, Accuracy = 0.943661987782\n",
            "Iter #6721536:  Learning rate = 0.000324:   Batch Loss = 0.296413, Accuracy = 0.966796875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.388534933329, Accuracy = 0.938793241978\n",
            "Iter #6725632:  Learning rate = 0.000324:   Batch Loss = 0.284584, Accuracy = 0.97265625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.377777129412, Accuracy = 0.947139620781\n",
            "Iter #6729728:  Learning rate = 0.000324:   Batch Loss = 0.304441, Accuracy = 0.96484375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.369202166796, Accuracy = 0.946444094181\n",
            "Iter #6733824:  Learning rate = 0.000324:   Batch Loss = 0.297119, Accuracy = 0.96875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.379635065794, Accuracy = 0.942444801331\n",
            "Iter #6737920:  Learning rate = 0.000324:   Batch Loss = 0.278217, Accuracy = 0.978515625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.383231341839, Accuracy = 0.941923141479\n",
            "Iter #6742016:  Learning rate = 0.000324:   Batch Loss = 0.307269, Accuracy = 0.966796875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.383607506752, Accuracy = 0.943661987782\n",
            "Iter #6746112:  Learning rate = 0.000324:   Batch Loss = 0.284828, Accuracy = 0.97265625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.393266677856, Accuracy = 0.938097715378\n",
            "Iter #6750208:  Learning rate = 0.000324:   Batch Loss = 0.315011, Accuracy = 0.966796875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.367515325546, Accuracy = 0.947139620781\n",
            "Iter #6754304:  Learning rate = 0.000324:   Batch Loss = 0.289436, Accuracy = 0.96875\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.373575627804, Accuracy = 0.94314032793\n",
            "Iter #6758400:  Learning rate = 0.000324:   Batch Loss = 0.314772, Accuracy = 0.9609375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.374628126621, Accuracy = 0.943488061428\n",
            "Iter #6762496:  Learning rate = 0.000324:   Batch Loss = 0.279387, Accuracy = 0.970703125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.372528791428, Accuracy = 0.942966461182\n",
            "Iter #6766592:  Learning rate = 0.000324:   Batch Loss = 0.288340, Accuracy = 0.974609375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.376018822193, Accuracy = 0.944009721279\n",
            "Iter #6770688:  Learning rate = 0.000324:   Batch Loss = 0.291002, Accuracy = 0.9765625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.378601014614, Accuracy = 0.94122761488\n",
            "Iter #6774784:  Learning rate = 0.000324:   Batch Loss = 0.326746, Accuracy = 0.9609375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.38933712244, Accuracy = 0.941749274731\n",
            "Iter #6778880:  Learning rate = 0.000324:   Batch Loss = 0.276666, Accuracy = 0.974609375\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.374354302883, Accuracy = 0.944357514381\n",
            "Iter #6782976:  Learning rate = 0.000324:   Batch Loss = 0.320129, Accuracy = 0.962890625\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.377051115036, Accuracy = 0.944705247879\n",
            "Iter #6787072:  Learning rate = 0.000324:   Batch Loss = 0.294736, Accuracy = 0.970703125\n",
            "PERFORMANCE ON TEST SET:             Batch Loss = 0.382142692804, Accuracy = 0.941575407982\n",
            "Optimization Finished!\n",
            "FINAL RESULT: Batch Loss = 0.382142692804, Accuracy = 0.941575407982\n",
            "TOTAL TIME:  3052.13242102\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VTsuBLsKi9C3"
      },
      "source": [
        "## Results:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "HzEbnSsri9C3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "045ce5dc-65b7-4439-9cde-cccc00616ac4"
      },
      "source": [
        "# (Inline plots: )\n",
        "%matplotlib inline\n",
        "\n",
        "font = {\n",
        "    'family' : 'Bitstream Vera Sans',\n",
        "    'weight' : 'bold',\n",
        "    'size'   : 18\n",
        "}\n",
        "matplotlib.rc('font', **font)\n",
        "\n",
        "width = 12\n",
        "height = 12\n",
        "plt.figure(figsize=(width, height))\n",
        "\n",
        "indep_train_axis = np.array(range(batch_size, (len(train_losses)+1)*batch_size, batch_size))\n",
        "#plt.plot(indep_train_axis, np.array(train_losses),     \"b--\", label=\"Train losses\")\n",
        "plt.plot(indep_train_axis, np.array(train_accuracies), \"g--\", label=\"Train accuracies\")\n",
        "\n",
        "indep_test_axis = np.append(\n",
        "    np.array(range(batch_size, len(test_losses)*display_iter, display_iter)[:-1]),\n",
        "    [training_iters]\n",
        ")\n",
        "#plt.plot(indep_test_axis, np.array(test_losses), \"b-\", linewidth=2.0, label=\"Test losses\")\n",
        "plt.plot(indep_test_axis, np.array(test_accuracies), \"b-\", linewidth=2.0, label=\"Test accuracies\")\n",
        "print len(test_accuracies)\n",
        "print len(train_accuracies)\n",
        "\n",
        "plt.title(\"Training session's Accuracy over Iterations\")\n",
        "plt.legend(loc='lower right', shadow=True)\n",
        "plt.ylabel('Training Accuracy')\n",
        "plt.xlabel('Training Iteration')\n",
        "\n",
        "plt.show()\n",
        "\n",
        "# Results\n",
        "\n",
        "predictions = one_hot_predictions.argmax(1)\n",
        "\n",
        "print(\"Testing Accuracy: {}%\".format(100*accuracy))\n",
        "\n",
        "print(\"\")\n",
        "print(\"Precision: {}%\".format(100*metrics.precision_score(y_test, predictions, average=\"weighted\")))\n",
        "print(\"Recall: {}%\".format(100*metrics.recall_score(y_test, predictions, average=\"weighted\")))\n",
        "print(\"f1_score: {}%\".format(100*metrics.f1_score(y_test, predictions, average=\"weighted\")))\n",
        "\n",
        "print(\"\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(\"Created using test set of {} datapoints, normalised to % of each class in the test dataset\".format(len(y_test)))\n",
        "confusion_matrix = metrics.confusion_matrix(y_test, predictions)\n",
        "\n",
        "\n",
        "#print(confusion_matrix)\n",
        "normalised_confusion_matrix = np.array(confusion_matrix, dtype=np.float32)/np.sum(confusion_matrix)*100\n",
        "\n",
        "\n",
        "# Plot Results: \n",
        "width = 12\n",
        "height = 12\n",
        "plt.figure(figsize=(width, height))\n",
        "plt.imshow(\n",
        "    normalised_confusion_matrix, \n",
        "    interpolation='nearest', \n",
        "    cmap=plt.cm.Blues\n",
        ")\n",
        "plt.title(\"Confusion matrix \\n(normalised to % of total test data)\")\n",
        "plt.colorbar()\n",
        "tick_marks = np.arange(n_classes)\n",
        "plt.xticks(tick_marks, LABELS, rotation=90)\n",
        "plt.yticks(tick_marks, LABELS)\n",
        "plt.tight_layout()\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1659\n",
            "13256\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python2.7/dist-packages/matplotlib/font_manager.py:1331: UserWarning: findfont: Font family [u'Bitstream Vera Sans'] not found. Falling back to DejaVu Sans\n",
            "  (prop.get_family(), self.defaultFamily[fontext]))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x864 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Testing Accuracy: 94.1575407982%\n",
            "\n",
            "Precision: 94.2155323102%\n",
            "Recall: 94.1575378195%\n",
            "f1_score: 94.1630541057%\n",
            "\n",
            "Confusion Matrix:\n",
            "Created using test set of 5751 datapoints, normalised to % of each class in the test dataset\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x864 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7DUxvOyi9C4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fcc30712-b279-4a3d-c921-b93219226dc4"
      },
      "source": [
        "\n",
        "X_val_path = DATASET_PATH + \"X_val.txt\"\n",
        "X_val = load_X(X_val_path)\n",
        "print X_val\n",
        "\n",
        "preds = sess.run(\n",
        "   [pred],\n",
        "   feed_dict={\n",
        "       x: X_val\n",
        "  }\n",
        ")\n",
        "\n",
        "print preds"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[307.589 162.976 319.364 ...   0.    329.752 161.651]\n",
            "  [307.567 162.979 319.362 ...   0.    328.527 161.655]\n",
            "  [306.298 162.951 319.351 ...   0.    328.495 161.681]\n",
            "  ...\n",
            "  [293.291 122.534 307.676 ... 128.953 315.438 119.884]\n",
            "  [289.392 140.743 307.615 ...   0.    315.393 139.408]\n",
            "  [295.848 161.658 307.628 ... 160.331 314.112 160.264]]]\n",
            "[array([[ 5.134506  , -1.1705078 , -1.8194871 , -1.7360446 , -0.64688313,\n",
            "        -0.35537827]], dtype=float32)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0yUTQOji9C5"
      },
      "source": [
        "## Conclusion\n",
        "\n",
        "Given that training takes around 7 minutes, a final accuracy of >90% is rather impressive.\n",
        "\n",
        "There is reasonable confusion between the activities of Clapping Hands and Boxing, as well as Jumping Jacks and Waving Two Hands.\n"
      ]
    }
  ]
}